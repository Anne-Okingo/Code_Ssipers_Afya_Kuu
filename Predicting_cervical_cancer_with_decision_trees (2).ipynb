{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dGDEWIlDS6Cf"
   },
   "source": [
    "## Step 1: Import Libraries\n",
    "\n",
    "- `pandas` and `numpy` help us work with data.\n",
    "\n",
    "- `matplotlib` and `seaborn` are used to create charts and graphs.\n",
    "\n",
    "- From `scikit-learn`, we import tools to split data, build a random forest model, and check how well the model performs.\n",
    "\n",
    "- `compute_class_weight` helps us deal with class imbalance in the data.\n",
    "\n",
    "- `thefuzz` is used for fuzzy string matching—useful when text isn’t exactly the same.\n",
    "\n",
    "- `re` is Python’s tool for working with text patterns using regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "g_EfJsu2hZqr"
   },
   "outputs": [],
   "source": [
    "# imported libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from thefuzz import process\n",
    "import re\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dGDEWIlDS6Cf",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "\n",
    "## References\n",
    "\n",
    "* [Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) Random Forest Classifier documentation  \n",
    "* [Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) train-test split documentation  \n",
    "* [Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.class_weight.compute_class_weight.html) compute class weight documentation  \n",
    "* [Scikit-learn](https://scikit-learn.org/stable/modules/model_evaluation.html) metrics documentation (accuracy, confusion matrix, classification report)  \n",
    "* [Pandas documentation](https://pandas.pydata.org/docs/) for data manipulation  \n",
    "* [NumPy documentation](https://numpy.org/doc/) for numerical computing  \n",
    "* [Matplotlib](https://matplotlib.org/stable/index.html) official documentation for plotting  \n",
    "* [Seaborn](https://seaborn.pydata.org/) official documentation for statistical data visualization  \n",
    "* [Medium article](https://medium.com/@jaimejcheng/data-exploration-and-visualization-with-seaborn-pair-plots-40e6d3450f6d) for Seaborn pair plots  \n",
    "* [TheFuzz GitHub](https://github.com/seatgeek/thefuzz) for fuzzy string matching in Python  \n",
    "* [Medium article](https://towardsdatascience.com/fuzzy-string-matching-in-python-68f240d910fe) explaining fuzzy matching in Python  \n",
    "* [Hands-On Machine Learning book](https://www.amazon.com/Hands-Machine-Learning-Scikit-Learn-TensorFlow/dp/1491962291) for machine learning workflows and best practices  \n",
    "* [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php) for accessing open datasets  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-4BOymaBxKZ"
   },
   "source": [
    "## Step 2: Load and Prepare the Dataset\n",
    "\n",
    "- Load the dataset from the Excel file `Cervical Cancer Datasets_.xlsx`.\n",
    "- Save it as a CSV file named `cervical_cancer.csv` to make it easier to work with.\n",
    "- Load the CSV file into a Pandas DataFrame called `data` for further analysis.\n",
    "\n",
    "Note: We use `index=False` when saving to prevent Pandas from adding row numbers as a column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NChL47NVhXiv"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 2. Load Excel and Save as CSV\n",
    "excel_path = 'Cervical Cancer Datasets_.xlsx'\n",
    "csv_path = 'cervical_cancer.csv'\n",
    "\n",
    "df = pd.read_excel(excel_path)\n",
    "df.to_csv(csv_path,index=False)\n",
    "\n",
    "# 3. Load CSV (use header=None only if the dataset has no headers)\n",
    "data = pd.read_csv(csv_path)  # Remove `header=None` if headers are present\n",
    "\n",
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dGDEWIlDS6Cf"
   },
   "source": [
    "### Flag Duplicates\n",
    "\n",
    "The `Patient ID` is treated as the unique identifier for each individual.\n",
    "\n",
    "We check for duplicate records by comparing all other columns **except `Patient ID`**. If rows have the same values across at least 80% of the fields, they are flagged as potential duplicates.\n",
    "\n",
    "A new column `is_duplicate` is added to the dataset to mark these cases.\n",
    "\n",
    "All flagged records are then exported to `flagged_duplicates.csv` for manual checking and review, ensuring no important data is accidentally removed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag duplicates and export them for manual checking\n",
    "data['is_duplicate'] = data.duplicated(subset=df.columns.difference(['Patient ID']), keep=False)\n",
    "duplicates_df = data[data['is_duplicate'] == True]\n",
    "duplicates_df.to_csv('flagged_duplicates.csv', index=False)\n",
    "\n",
    "print(data.columns)\n",
    "print(\"\\n\")\n",
    "print(f\"The data set has ( Total rows: {len(data)}, Total columns: {len(data.columns)})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-4BOymaBxKZ"
   },
   "source": [
    "### Inspect and Verify Data Quality\n",
    "\n",
    "In this step, we perform a basic data audit:\n",
    "\n",
    "- Load the dataset from the CSV file.\n",
    "- Preview the data using `.head()` to understand its structure.\n",
    "- Use `.info()` to check data types and identify columns with missing values.\n",
    "- Count missing values per column to assess data completeness.\n",
    "- Print all unique values for each column to inspect potential inconsistencies or unexpected entries (e.g., typos in categorical fields).\n",
    "- Finally, we print the value counts for each column — including missing values — to evaluate how frequently each value appears. This helps identify:\n",
    "  - Class imbalance\n",
    "  - Invalid or rare values\n",
    "  - Columns that may require cleaning or transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the raw data\n",
    "data = pd.read_csv(\"cervical_cancer.csv\")\n",
    "\n",
    "# Preview the first few rows\n",
    "print(data.head())\n",
    "\n",
    "# Overview of column names, data types, and non-null counts\n",
    "print(data.info())\n",
    "\n",
    "# Check for missing values in each column\n",
    "print(\"Missing values per column:\\n\", data.isnull().sum())\n",
    "\n",
    "# Show unique values and value counts for each column\n",
    "for column in data.columns:\n",
    "    print(f\"--- Unique values for: {column} ---\")\n",
    "    print(data[column].unique())\n",
    "    print(f\"\\n--- Value Counts for: {column} ---\")\n",
    "    print(data[column].value_counts(dropna=False))\n",
    "    print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-4BOymaBxKZ"
   },
   "source": [
    "## Step 3: Exploratory Data Analysis (EDA)\n",
    "\n",
    "Exploratory Data Analysis (EDA) helps us deeply understand the structure, quality, and relationships within the data before applying any machine learning algorithms.\n",
    "\n",
    "### EDA Goals:\n",
    "- Identify variable types (categorical, numerical, binary)\n",
    "- Explore distributions of key features\n",
    "- Visualize relationships and potential predictors\n",
    "- Detect class imbalance in the target variable\n",
    "- Spot outliers or anomalies that may impact modeling\n",
    "- Support decisions for further data cleaning or transformation\n",
    "\n",
    "---\n",
    "\n",
    "### Feature & Data Type Overview\n",
    "\n",
    "We begin by checking the types of each column and the number of unique values. This helps us distinguish between categorical and numerical features and spot columns that need transformation or standardization.\n",
    "\n",
    "---\n",
    "\n",
    "### Known Data Quality Discrepancies\n",
    "\n",
    "During initial inspection, several inconsistencies and typos were identified:\n",
    "\n",
    "#### Column: `HPV Test Result`\n",
    "- `\"POSITIVE\\n\"` — extra newline character\n",
    "- `\"NEGAGTIVE\"` — misspelling of `\"NEGATIVE\"`\n",
    "\n",
    "#### Column: `Region`\n",
    "- Inconsistent casing: `\"Mombasa\"` vs `\"MOMBASA\"`, `\"Kitale\"` listed multiple times with trailing spaces\n",
    "- Spacing and capitalization differences\n",
    "\n",
    "#### Column: `Recommended Action`\n",
    "- Same recommendation repeated with:\n",
    "  - Extra spaces: `\"REPEAT PAP SMEAR IN 3 YEARS \"` vs `\"REPEAT PAP SMEAR IN 3 YEARS\"`\n",
    "  - Misspellings: `\"BIOSPY\"` instead of `\"BIOPSY\"`, `\"COLOSCOPY\"` instead of `\"COLPOSCOPY\"`\n",
    "  - Concatenation: `\"FORCOLPOSCOPY, CYTOLOGY THEN LASER THERAPY\"`\n",
    "\n",
    "#### Column: `Unnamed: 12`\n",
    "- Largely empty (mostly `NaN`) — candidate for removal.\n",
    "\n",
    "#### Column: `Insrance Covered`\n",
    "- Misspelled — should be renamed to `\"Insurance Covered\"`\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Outcome Class Imbalance\n",
    "\n",
    "We check whether the target variable (e.g., HPV Test Result or Pap Smear Result) is imbalanced.\n",
    "\n",
    "> Why it's important: Imbalanced datasets can mislead the model into favoring the dominant class, leading to poor generalization.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Distribution of Numeric Features\n",
    "\n",
    "We explore numerical features like `Age`, `First Sexual Activity Age`, and `Sexual Partners` to check their distribution and spot outliers using histograms and boxplots.\n",
    "\n",
    "This step helps:\n",
    "- Identify skewness\n",
    "- Detect abnormal values\n",
    "- Guide transformation decisions\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Binary Features Overview\n",
    "\n",
    "Binary/categorical columns such as `Smoking Status`, `STDs History`, and `Insurance Covered` are analyzed to ensure:\n",
    "- Consistency (e.g., \"YES\"/\"NO\" vs \"Y\"/\"N\")\n",
    "- No missing or ambiguous values\n",
    "\n",
    "Visualizing their distribution gives insight into population characteristics.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Categorical Variable Exploration\n",
    "\n",
    "We examine values in columns like:\n",
    "- `Region` – Check patient spread across different geographical locations\n",
    "- `Screening Type Last` – Evaluate most commonly used screening methods\n",
    "- `Recommended Action` – Understand typical medical advice given after testing\n",
    "\n",
    "This helps us assess frequency, diversity, and inconsistencies in responses.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Correlation Matrix for Numerical Features\n",
    "\n",
    "A correlation matrix (heatmap) shows how numerical features relate to each other. This helps detect:\n",
    "- Redundant or highly correlated variables\n",
    "- Relationships that may influence the model\n",
    "\n",
    "Features explored include:\n",
    "- `Age`\n",
    "- `First Sexual Activity Age`\n",
    "- `Sexual Partners`\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Summary of Key Issues to Clean\n",
    "\n",
    "| Column                 | Issue Type             | Action Needed                     |\n",
    "|------------------------|------------------------|-----------------------------------|\n",
    "| `HPV Test Result`      | Typos, extra characters| Normalize strings                 |\n",
    "| `Region`               | Casing, spacing issues | Map to consistent labels          |\n",
    "| `Recommended Action`   | Misspellings, spacing  | Standardize text                  |\n",
    "| `Unnamed: 12`          | Mostly empty           | Drop this column                  |\n",
    "| `Insrance Covered`     | Misspelled             | Rename to `Insurance Covered`     |\n",
    "\n",
    "---\n",
    "\n",
    "### Bonus: Scikit-learn Data Cleaning Pipeline (Optional)\n",
    "\n",
    "To make cleaning reusable and organized, we can define custom classes using `scikit-learn` transformers and compose them into a pipeline.\n",
    "\n",
    "Example concept:\n",
    "- Create a transformer to clean and standardize `HPV Test Result`\n",
    "- Chain transformers for cleaning multiple fields\n",
    "\n",
    "Using pipelines ensures our data transformations are:\n",
    "- Reproducible\n",
    "- Modular\n",
    "- Easily integrated into training workflows\n",
    "\n",
    "---\n",
    "\n",
    "### EDA Summary\n",
    "\n",
    "- Confirmed the presence of text inconsistencies, typos, and formatting issues in categorical columns.\n",
    "- Several numerical features show outliers or unusual values.\n",
    "- The target variable is imbalanced, which may require resampling.\n",
    "- These insights guide the next step: comprehensive data cleaning and transformation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-4BOymaBxKZ"
   },
   "source": [
    "### 3.1: Initial Inspection of Raw Data\n",
    "\n",
    "In this step, we load the raw cervical cancer dataset and perform a quick inspection to identify data quality issues before cleaning. Specifically, we:\n",
    "\n",
    "- Suppress warning messages for a cleaner notebook display.\n",
    "- Load the dataset from a CSV file and print its shape to understand how many rows and columns it contains.\n",
    "- Print the column names to check for any typos or unnecessary fields.\n",
    "- Display unique values from key columns like `HPV Test Result`, `Region`, and a sample of `Recommended Action` values to identify inconsistencies (e.g., typos, inconsistent formatting, or unexpected categories).\n",
    "- Check for missing values in each column to determine which features may require imputation or removal during cleaning.\n",
    "\n",
    "This preliminary scan helps us understand what kind of cleaning and standardization will be necessary to prepare the data for analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the raw data\n",
    "print(\"Loading raw data...\")\n",
    "df = pd.read_csv('cervical_cancer.csv')\n",
    "print(f\"Original dataset shape: {df.shape}\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"BEFORE CLEANING - Data Quality Issues:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Show original data quality issues\n",
    "print(\"1. Column names:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "print(\"\\n2. Sample of problematic data:\")\n",
    "print(\"HPV Test Result unique values:\", df['HPV Test Result'].unique())\n",
    "print(\"Region unique values:\", df['Region'].unique())\n",
    "print(\"Recommended Action samples:\")\n",
    "for action in df['Recommended Action'].unique()[:5]:\n",
    "    print(f\"  - '{action}'\")\n",
    "\n",
    "print(\"\\n3. Missing values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-4BOymaBxKZ"
   },
   "source": [
    "### 3.2: Data Cleaning and Standardization\n",
    "\n",
    "In this step, we clean and standardize the cervical cancer dataset to improve data quality, remove inconsistencies, and prepare it for further analysis and modeling.\n",
    "\n",
    "---\n",
    "\n",
    "#### Step-by-Step Cleaning Breakdown:\n",
    "\n",
    "1. **Create a Copy**  \n",
    "   - We create a copy of the original DataFrame (`clean_df = df.copy()`) to preserve the raw data for reference or backup.\n",
    "\n",
    "2. **Remove Unnecessary Columns**  \n",
    "   - We drop columns like `Unnamed: 12`, which are often artifacts of Excel exports and contain mostly `NaN` or irrelevant data.\n",
    "\n",
    "3. **Fix Column Name Typos**  \n",
    "   - Rename incorrectly spelled column headers.  \n",
    "     Example: `\"Insrance Covered\"` → `\"Insurance Covered\"`\n",
    "\n",
    "4. **Clean `HPV Test Result` Column**  \n",
    "   - Convert values to uppercase and strip whitespace.\n",
    "   - Replace typos and inconsistent formats like:\n",
    "     - `\"NEGAGTIVE\"` → `\"NEGATIVE\"`\n",
    "     - `\"POSITIVE\\n\"` → `\"POSITIVE\"`\n",
    "   - This standardization allows consistent analysis and visualization.\n",
    "\n",
    "5. **Clean and Standardize `Region` Names**  \n",
    "   - Remove inconsistencies caused by case sensitivity and trailing spaces.\n",
    "   - Use a mapping dictionary to unify variations:\n",
    "     - `\"MOMBASA\"`, `\"mombasa \"` → `\"Mombasa\"`\n",
    "     - `\"PUMWANI\"`, `\"Pumwani \"` → `\"Pumwani\"` etc.\n",
    "\n",
    "6. **Clean Binary Columns (Y/N Values)**  \n",
    "   - Columns like:\n",
    "     - `Pap Smear Result`, `Smoking Status`, `STDs History`, `Insurance Covered`\n",
    "   - We standardize these by:\n",
    "     - Converting to uppercase\n",
    "     - Stripping whitespace  \n",
    "   This ensures we don’t treat `\"Y\"`, `\"y \"`, and `\" Y\"` as different values.\n",
    "\n",
    "7. **Clean `Screening Type Last` Column**  \n",
    "   - Normalize string values using `upper()` and `strip()` to handle inconsistent formatting.\n",
    "\n",
    "8. **Handle Age Anomalies**  \n",
    "   - Convert `Age` to numeric and clip unrealistic values:\n",
    "     - Any age `< 10` or `> 100` is corrected to fall within that range.\n",
    "\n",
    "9. **Fix First Sexual Activity Age Conflicts**  \n",
    "   - Convert to numeric and check for logical errors:\n",
    "     - Drop rows where `First Sexual Activity Age > Age`.\n",
    "\n",
    "10. **Clean `Sexual Partners` Column**  \n",
    "    - Convert to numeric, drop rows with non-numeric or missing values.\n",
    "\n",
    "11. **Final String Cleanup**  \n",
    "    - Strip all string-type columns of whitespace for consistency.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for cleaning\n",
    "clean_df = df.copy()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"APPLYING CLEANING TRANSFORMATIONS:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "\n",
    "# 1. Remove unnecessary columns\n",
    "print(\"1. Removing unnecessary columns...\")\n",
    "columns_to_drop = ['Unnamed: 12']\n",
    "for col in columns_to_drop:\n",
    "    if col in clean_df.columns:\n",
    "        clean_df.drop(columns=[col], inplace=True)\n",
    "        print(f\"   Dropped column: {col}\")\n",
    "        \n",
    "\n",
    "# 2. Fix column name typos\n",
    "print(\"\\n2. Fixing column name typos...\")\n",
    "column_renames = {\n",
    "    'Insrance Covered': 'Insurance Covered'\n",
    "}\n",
    "clean_df.rename(columns=column_renames, inplace=True)\n",
    "for old, new in column_renames.items():\n",
    "    print(f\"   Renamed '{old}' to '{new}'\")\n",
    "    \n",
    "\n",
    "# 3. Clean HPV Test Result\n",
    "print(\"\\n3. Cleaning HPV Test Result...\")\n",
    "print(f\"   Before: {clean_df['HPV Test Result'].unique()}\")\n",
    "\n",
    "clean_df['HPV Test Result'] = clean_df['HPV Test Result'].astype(str).str.upper().str.strip()\n",
    "\n",
    "\n",
    "\n",
    "# Fix the problematic characters - using raw strings to avoid escape issues\n",
    "hpv_replacements = {\n",
    "    'NEGAGTIVE': 'NEGATIVE',\n",
    "    'POSTIVE': 'POSITIVE',\n",
    "    'NEGATVIE': 'NEGATIVE',\n",
    "    'NEGATVE': 'NEGATIVE',\n",
    "    'NEGATIVE\\n':'NEGATIVE',\n",
    "    'NEGATIVE ':'NEGATIVE',\n",
    "    ' NEGATIVE ':'NEGATIVE',\n",
    "    ' POSITIVE ':'POSITIVE',\n",
    "    'POSITIVE\\n':'POSITIVE'\n",
    "}\n",
    "\n",
    "# Handle newline characters separately\n",
    "clean_df['HPV Test Result'] = clean_df['HPV Test Result'].str.replace('\\n', '', regex=False)\n",
    "clean_df['HPV Test Result'] = clean_df['HPV Test Result'].str.replace('\\\\n', '', regex=False)\n",
    "\n",
    "# Apply other replacements\n",
    "clean_df['HPV Test Result'] = clean_df['HPV Test Result'].replace(hpv_replacements)\n",
    "\n",
    "print(f\"   After: {clean_df['HPV Test Result'].unique()}\")\n",
    "\n",
    "\n",
    "# 4. Clean and standardize Region names\n",
    "print(\"\\n4. Cleaning and standardizing Region names...\")\n",
    "print(f\"   Before: {sorted(clean_df['Region'].unique())}\")\n",
    "\n",
    "# First, strip whitespace and normalize case\n",
    "clean_df['Region'] = clean_df['Region'].astype(str).str.strip()\n",
    "\n",
    "# Create comprehensive region mapping to handle all variations\n",
    "region_mapping = {\n",
    "    # Mombasa variations\n",
    "    'mombasa': 'Mombasa',\n",
    "    'MOMBASA': 'Mombasa',\n",
    "    'Mombasa': 'Mombasa',\n",
    "    'mombasa ': 'Mombasa',\n",
    "    'Mombasa ': 'Mombasa',\n",
    "    'MOMBASA ': 'Mombasa',\n",
    "\n",
    "\n",
    "      # Pumwani variations\n",
    "    'pumwani': 'Pumwani',\n",
    "    'PUMWANI': 'Pumwani',\n",
    "    'Pumwani': 'Pumwani',\n",
    "    'pumwani ': 'Pumwani',\n",
    "    'Pumwani ': 'Pumwani',\n",
    "    'PUMWANI ': 'Pumwani',\n",
    "    \n",
    "    # Embu variations\n",
    "    'embu': 'Embu',\n",
    "    'EMBU': 'Embu',\n",
    "    'Embu': 'Embu',\n",
    "    'embu ': 'Embu',\n",
    "    'Embu ': 'Embu',\n",
    "    'EMBU ': 'Embu',\n",
    "    \n",
    "    # Kakamega variations\n",
    "    'kakamega': 'Kakamega',\n",
    "    'KAKAMEGA': 'Kakamega',\n",
    "    'Kakamega': 'Kakamega',\n",
    "    'kakamega ': 'Kakamega',\n",
    "    'Kakamega ': 'Kakamega',\n",
    "    'KAKAMEGA ': 'Kakamega',\n",
    "    \n",
    "    # Machakos variations\n",
    "    'machakos': 'Machakos',\n",
    "    'MACHAKOS': 'Machakos',\n",
    "    'Machakos': 'Machakos',\n",
    "    'machakos ': 'Machakos',\n",
    "    'Machakos ': 'Machakos',\n",
    "    'MACHAKOS ': 'Machakos',\n",
    "    \n",
    "    # Nakuru variations\n",
    "    'nakuru': 'Nakuru',\n",
    "    'NAKURU': 'Nakuru',\n",
    "    'Nakuru': 'Nakuru',\n",
    "    'NAKURU ': 'Nakuru',\n",
    "    \n",
    "    # Moi variations\n",
    "    'moi': 'Moi',\n",
    "    'MOI': 'Moi',\n",
    "    'Moi': 'Moi',\n",
    "    'moi ': 'Moi',\n",
    "    'Moi ': 'Moi',\n",
    "    'MOI ': 'Moi',\n",
    "    \n",
    "  \n",
    "  \n",
    "    # Loitoktok variations\n",
    "    'loitoktok': 'Loitoktok',\n",
    "    'LOITOKTOK': 'Loitoktok',\n",
    "    'Loitoktok': 'Loitoktok',\n",
    "    'loitoktok ': 'Loitoktok',\n",
    "    'Loitoktok ': 'Loitoktok',\n",
    "    'LOITOKTOK ': 'Loitoktok',\n",
    "    \n",
    "    # Garissa variations\n",
    "    'garissa': 'Garissa',\n",
    "    'GARISSA': 'Garissa',\n",
    "    'Garissa': 'Garissa',\n",
    "    'garissa ': 'Garissa',\n",
    "    'Garissa ': 'Garissa',\n",
    "    'GARISSA ': 'Garissa',\n",
    "    \n",
    "    # Kericho variations\n",
    "    'kericho': 'Kericho',\n",
    "    'KERICHO': 'Kericho',\n",
    "    'Kericho': 'Kericho',\n",
    "    'kericho ': 'Kericho',\n",
    "    'Kericho ': 'Kericho',\n",
    "    'KERICHO ': 'Kericho',\n",
    "    \n",
    "    # Kitale variations\n",
    "    'kitale': 'Kitale',\n",
    "    'KITALE': 'Kitale',\n",
    "    'Kitale': 'Kitale',\n",
    "    'kitale ': 'Kitale',\n",
    "    'Kitale ': 'Kitale',\n",
    "    'KITALE ': 'Kitale'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Apply region mapping\n",
    "clean_df['Region'] = clean_df['Region'].replace(region_mapping)\n",
    "\n",
    "print(f\"   After: {sorted(clean_df['Region'].unique())}\")\n",
    "\n",
    "\n",
    "# 6. Clean binary columns (Y/N values)\n",
    "print(\"\\n6. Cleaning binary columns...\")\n",
    "binary_columns = ['Pap Smear Result', 'Smoking Status', 'STDs History', 'Insurance Covered']\n",
    "for col in binary_columns:\n",
    "    if col in clean_df.columns:\n",
    "        print(f\"   Cleaning {col}\")\n",
    "        print(f\"      Before: {clean_df[col].unique()}\")\n",
    "        clean_df[col] = clean_df[col].astype(str).str.upper().str.strip()\n",
    "        print(f\"      After: {clean_df[col].unique()}\")\n",
    "        \n",
    "\n",
    "# 7. Clean screening type\n",
    "print(\"\\n7. Cleaning Screening Type Last...\")\n",
    "if 'Screening Type Last' in clean_df.columns:\n",
    "    print(f\"   Before: {clean_df['Screening Type Last'].unique()}\")\n",
    "    clean_df['Screening Type Last'] = clean_df['Screening Type Last'].astype(str).str.upper().str.strip()\n",
    "    print(f\"   After: {clean_df['Screening Type Last'].unique()}\")\n",
    "    \n",
    "\n",
    "# 8. Handle age anomalies\n",
    "print(\"\\n8. Handling age anomalies...\")\n",
    "print(f\"   Age range before: {clean_df['Age'].min()} - {clean_df['Age'].max()}\")\n",
    "clean_df['Age'] = pd.to_numeric(clean_df['Age'], errors='coerce')\n",
    "# Check for unrealistic ages\n",
    "unrealistic_ages = clean_df[(clean_df['Age'] < 10) | (clean_df['Age'] > 100)]\n",
    "if len(unrealistic_ages) > 0:\n",
    "    print(f\"   Found {len(unrealistic_ages)} unrealistic ages\")\n",
    "clean_df['Age'] = clean_df['Age'].clip(lower=10, upper=100)\n",
    "print(f\"   Age range after: {clean_df['Age'].min()} - {clean_df['Age'].max()}\")\n",
    "\n",
    "# 9. Handle First Sexual Activity Age anomalies\n",
    "print(\"\\n9. Handling First Sexual Activity Age anomalies...\")\n",
    "print(f\"   First Sexual Activity Age range before: {clean_df['First Sexual Activity Age'].min()} - {clean_df['First Sexual Activity Age'].max()}\")\n",
    "clean_df['First Sexual Activity Age'] = pd.to_numeric(clean_df['First Sexual Activity Age'], errors='coerce')\n",
    "\n",
    "# Check for impossible values (first sexual activity age > current age)\n",
    "# Identify invalid rows\n",
    "impossible_ages = clean_df['First Sexual Activity Age'] > clean_df['Age']\n",
    "\n",
    "# Print how many invalid records were found\n",
    "if impossible_ages.any():\n",
    "    print(f\"   Found {impossible_ages.sum()} records where first sexual activity age > current age\")\n",
    "\n",
    "    # Drop those rows from the DataFrame\n",
    "    clean_df = clean_df[~impossible_ages]\n",
    "\n",
    "# 10. Handling Sexual Partners    \n",
    "\n",
    "print(\"\\n10. Handling Sexual Partners...\")\n",
    "\n",
    "#  Convert to numeric, non-numeric values become NaN\n",
    "clean_df['Sexual Partners'] = pd.to_numeric(clean_df['Sexual Partners'], errors='coerce')\n",
    "\n",
    "# Show range before dropping\n",
    "print(f\"   Sexual Partners range before cleanup: {clean_df['Sexual Partners'].min()} - {clean_df['Sexual Partners'].max()}\")\n",
    "\n",
    "# Drop rows where 'Sexual Partners' is NaN\n",
    "initial_count = len(clean_df)\n",
    "clean_df = clean_df.dropna(subset=['Sexual Partners'])\n",
    "dropped_count = initial_count - len(clean_df)\n",
    "\n",
    "print(f\"   Dropped {dropped_count} rows with missing or invalid 'Sexual Partners' values.\")\n",
    "\n",
    "# 11. Final cleanup - strip all string columns\n",
    "print(\"\\n11. Final cleanup...\")\n",
    "for col in clean_df.select_dtypes(include='object').columns:\n",
    "    clean_df[col] = clean_df[col].astype(str).str.strip()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"CLEANING COMPLETE - SUMMARY:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Original shape: {df.shape}\")\n",
    "print(f\"Cleaned shape: {clean_df.shape}\")\n",
    "print(f\"Columns after cleaning: {clean_df.columns.tolist()}\")\n",
    "\n",
    "# Show cleaned data quality\n",
    "print(\"\\nCleaned data quality:\")\n",
    "print(\"1. HPV Test Result values:\", clean_df['HPV Test Result'].unique())\n",
    "print(\"2. Regions:\", sorted(clean_df['Region'].unique()))\n",
    "print(\"3. Missing values after cleaning:\")\n",
    "print(clean_df.isnull().sum())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-4BOymaBxKZ"
   },
   "source": [
    "### 3.3: Final Validation and Saving of Cleaned Data\n",
    "\n",
    "After applying the data cleaning transformations, we perform a final check and save the cleaned dataset for further analysis.\n",
    "\n",
    "---\n",
    "\n",
    "#### Steps Included:\n",
    "\n",
    "1. **Save Cleaned Dataset**  \n",
    "   - Export the cleaned `DataFrame` to a new CSV file named `'cervical_cancer_cleaned.csv'`.\n",
    "   - This ensures the cleaned version is preserved and can be reused for further analysis or modeling.\n",
    "\n",
    "2. **Preview Cleaned Data**  \n",
    "   - Display the first 5 rows of the cleaned dataset using `.head()` to get a sense of the cleaned structure and content.\n",
    "\n",
    "3. **Verify Key Columns**  \n",
    "   - Use a custom `show_unique_values()` function to display unique values for critical categorical features such as:\n",
    "     - `HPV Test Result`\n",
    "     - `Region`\n",
    "     - `Pap Smear Result`\n",
    "     - `Smoking Status`\n",
    "     - `STDs History`\n",
    "     - `Insurance Covered`\n",
    "     - `Screening Type Last`\n",
    "   - This helps confirm that cleaning steps were effective in removing typos, inconsistencies, and formatting issues.\n",
    "\n",
    "4. **Column-Wise Value Counts**  \n",
    "   - The `print_all_value_counts()` function prints value counts for all columns in the dataset (including `NaNs`).\n",
    "   - This helps detect any remaining anomalies and understand the distribution of each variable, which is critical for:\n",
    "     - Identifying imbalances\n",
    "     - Planning for encoding (e.g., one-hot, label)\n",
    "     - Feature engineering\n",
    "\n",
    "---\n",
    "\n",
    "#### Conclusion:\n",
    "\n",
    "-  The cleaned dataset has been saved successfully.\n",
    "-  Categorical columns show standardized and consistent values.\n",
    "-  There is no significant presence of missing or malformed data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned data\n",
    "clean_df.to_csv('cervical_cancer_cleaned.csv', index=False)\n",
    "print(\"\\nCleaned data saved as 'cervical_cancer_cleaned.csv'\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nFirst 5 rows of cleaned data:\")\n",
    "print(clean_df.head())\n",
    "\n",
    "# Show unique values for key columns to verify cleaning\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"VERIFICATION OF CLEANED DATA:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "def show_unique_values(df, columns):\n",
    "    for col in columns:\n",
    "        if col in df.columns:\n",
    "            print(f\"\\n{col}:\")\n",
    "            unique_vals = df[col].unique()\n",
    "            if len(unique_vals) <= 10:\n",
    "                print(f\"  Values: {unique_vals}\")\n",
    "            else:\n",
    "                print(f\"  Total unique values: {len(unique_vals)}\")\n",
    "                print(f\"  Sample: {unique_vals[:10]}\")\n",
    "\n",
    "verification_columns = ['HPV Test Result', 'Region', 'Pap Smear Result', 'Smoking Status', \n",
    "                       'STDs History', 'Insurance Covered', 'Screening Type Last']\n",
    "show_unique_values(clean_df, verification_columns)\n",
    "\n",
    "\n",
    "#Preview results\n",
    "def print_all_value_counts(df):\n",
    "    for column in df.columns:\n",
    "        print(f\"--- Value Counts for: {column} ---\")\n",
    "        print(df[column].value_counts(dropna=False))  # include NaNs in the count\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Print unique values to check validity & quality:\n",
    "print_all_value_counts(clean_df)\n",
    "\n",
    "print(\"\\n✅ Data cleaning completed successfully!\")\n",
    "print(\"✅ Ready for next step: Exploratory Data Analysis\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-4BOymaBxKZ"
   },
   "source": [
    "### 3.4: Advanced Cleaning of \"Recommended Action\" Column using Fuzzy Matching and Keyword Rules\n",
    "\n",
    "This step addresses one of the most inconsistent and typo-ridden columns in the dataset — `Recommended Action`. It applies a structured, rule-based fuzzy matching approach to standardize all entries against a predefined list of **canonical (correct) values**.\n",
    "\n",
    "---\n",
    "\n",
    "#### Step Breakdown:\n",
    "\n",
    "1. **Define Canonical Values**\n",
    "   - These are the 100% correct, clean strings that we expect the column to match.\n",
    "   - They cover all valid and normalized options like:\n",
    "     - `\"FOR COLPOSCOPY, BIOPSY, AND CYTOLOGY\"`\n",
    "     - `\"REPEAT PAP SMEAR IN 3 YEARS\"`\n",
    "     - `\"FOR HPV VACCINE, LIFESTYLE, AND SEXUAL EDUCATION\"`\n",
    "\n",
    "2. **Set up Typo Mapping**\n",
    "   - Common misspellings like:\n",
    "     - `\"BIOSPY\"` → `\"BIOPSY\"`\n",
    "     - `\"COLOSCOPY\"` → `\"COLPOSCOPY\"`\n",
    "     - `\"ANUAL\"` → `\"ANNUAL\"`\n",
    "   - These are corrected **before matching** to improve accuracy.\n",
    "\n",
    "3. **Strict Fuzzy Matching Function**\n",
    "   - A custom function `clean_column_strict()` is used to:\n",
    "     - Standardize text to uppercase.\n",
    "     - Correct known typos.\n",
    "     - Extract and match **critical keywords** (like `HPV`, `CYTOLOGY`, `BIOPSY`, etc.).\n",
    "     - Use **fuzzy string matching** (via `fuzzywuzzy`) to find the closest canonical value.\n",
    "     - Ensure matches are **only accepted** if the keywords from the raw and canonical string are identical. This prevents incorrect but similar matches.\n",
    "\n",
    "4. **Apply Cleaning**\n",
    "   - The function is called with the column name, canonical list, and threshold (80% match confidence).\n",
    "   - It returns:\n",
    "     - A cleaned version of the column\n",
    "     - A confidence score\n",
    "     - A status flag (`OK` or `NEEDS MANUAL REVIEW`)\n",
    "\n",
    "5. **Manual Review Report**\n",
    "   - Any rows where the fuzzy match is below the confidence threshold (or keyword sets don’t match) are flagged for **manual review**.\n",
    "\n",
    "6. **Save the Final Data**\n",
    "   - The updated `DataFrame` with cleaned `Recommended Action` is exported to an Excel file:  \n",
    "      `final_cleaned.xlsx`\n",
    "\n",
    "---\n",
    "\n",
    "#### Why This Approach?\n",
    "\n",
    "- Fuzzy matching alone can lead to incorrect substitutions when two strings are similar but mean different things.\n",
    "- By combining **keyword presence checks** and **typo correction**, we ensure data is matched **both intelligently and safely**.\n",
    "- This is particularly useful in messy real-world healthcare data.\n",
    "\n",
    "---\n",
    "\n",
    "#### Outcome\n",
    "\n",
    "- The `Recommended Action` column is now fully standardized.\n",
    "- Any unmatched or low-confidence rows are clearly flagged for manual inspection.\n",
    "- The dataset is fully cleaned and saved, ready for Exploratory Data Analysis (EDA).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This list contains the final, correct values to use.\n",
    "canonical_values = [\n",
    "    \"REPEAT PAP SMEAR IN 3 YEARS\",\n",
    "    \"FOR COLPOSCOPY, BIOPSY, AND CYTOLOGY\",\n",
    "    \"FOR PAP SMEAR\",\n",
    "    \"FOR HPV VACCINE AND SEXUAL EDUCATION\",\n",
    "    \"FOR ANNUAL FOLLOW-UP AND PAP SMEAR IN 3 YEARS\",\n",
    "    \"REPEAT PAP SMEAR IN 3 YEARS AND FOR HPV VACCINE\",\n",
    "    \"FOR COLPOSCOPY, BIOPSY, AND CYTOLOGY (TAH NOT RECOMMENDED)\",\n",
    "    \"FOR BIOPSY AND CYTOLOGY (TAH NOT RECOMMENDED)\",\n",
    "    \"FOR HPV VACCINE, LIFESTYLE, AND SEXUAL EDUCATION\",\n",
    "    \"FOR COLPOSCOPY, BIOPSY, CYTOLOGY +/- TAH\",\n",
    "    \"FOR COLPOSCOPY, CYTOLOGY, THEN LASER THERAPY\",\n",
    "    \"FOR REPEAT HPV TESTING ANNUALLY AND PAP SMEAR IN 3 YEARS\",\n",
    "    \"FOR LASER THERAPY\"\n",
    "]\n",
    "\n",
    "# --- 2. Configuration for the Cleaner ---\n",
    "TYPO_MAP = {\n",
    "    'COLPOSOCPY': 'COLPOSCOPY', 'COLPOSCPY': 'COLPOSCOPY', 'COLOSCOPY': 'COLPOSCOPY',\n",
    "    'BIOSPY': 'BIOPSY', 'BIOSY': 'BIOPSY', 'ANUAL': 'ANNUAL', 'VACCINATION': 'VACCINE'\n",
    "}\n",
    "CRITICAL_KEYWORDS = {\n",
    "    'COLPOSCOPY', 'BIOPSY', 'CYTOLOGY', 'TAH', 'HPV', 'LASER', 'LIFESTYLE', 'ANNUALLY'\n",
    "}\n",
    "\n",
    "# --- 3. The Definitive Data Cleaning Function ---\n",
    "def clean_column_strict(df, column_to_clean, canonical_list, threshold=80):\n",
    "    \"\"\"\n",
    "    Cleans a DataFrame column using fuzzy matching combined with a STRICT keyword set equality rule.\n",
    "    \"\"\"\n",
    "    if column_to_clean not in df.columns:\n",
    "        raise ValueError(f\"Column '{column_to_clean}' not found in the DataFrame.\")\n",
    "\n",
    "    def preprocess_and_get_keywords(text, typo_map):\n",
    "        if not isinstance(text, str): return \"\", set()\n",
    "        # Standardize to uppercase and correct typos\n",
    "        processed_text = text.upper()\n",
    "        for wrong, right in typo_map.items():\n",
    "            processed_text = re.sub(r'\\b' + wrong + r'\\b', right, processed_text)\n",
    "        \n",
    "        # Extract the set of critical keywords\n",
    "        keywords = {word for word in CRITICAL_KEYWORDS if word in processed_text}\n",
    "        return processed_text, keywords\n",
    "\n",
    "    cleaned_data = []\n",
    "\n",
    "    # Pre-calculate keywords for the canonical list for efficiency\n",
    "    canonical_keywords = {val: preprocess_and_get_keywords(val, {})[1] for val in canonical_list}\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        raw_string = row[column_to_clean]\n",
    "        \n",
    "        if not isinstance(raw_string, str) or not raw_string.strip():\n",
    "            cleaned_data.append((raw_string, 0, 'NO_DATA_PROVIDED'))\n",
    "            continue\n",
    "\n",
    "        processed_string, original_keywords = preprocess_and_get_keywords(raw_string, TYPO_MAP)\n",
    "        \n",
    "        # Get the top few potential matches instead of just one\n",
    "        top_matches = process.extract(processed_string, canonical_list, limit=5)\n",
    "\n",
    "        best_valid_match = None\n",
    "        \n",
    "        for potential_match, score in top_matches:\n",
    "            if score < threshold:\n",
    "                break # No need to check further if scores are too low\n",
    "\n",
    "            # The CRITICAL check: The keyword sets must be identical\n",
    "            if original_keywords == canonical_keywords[potential_match]:\n",
    "                best_valid_match = (potential_match, score)\n",
    "                break # Found the best possible valid match, stop searching\n",
    "\n",
    "        if best_valid_match:\n",
    "            final_value, final_score = best_valid_match\n",
    "            status = 'OK'\n",
    "        else:\n",
    "            final_value = raw_string\n",
    "            final_score = top_matches[0][1] if top_matches else 0 # Show score of best (but invalid) match\n",
    "            status = 'NEEDS MANUAL REVIEW'\n",
    "\n",
    "        cleaned_data.append((final_value, final_score, status))\n",
    "\n",
    "    result_df = pd.DataFrame(cleaned_data, index=df.index, columns=[f'{column_to_clean}_Cleaned', f'{column_to_clean}_Confidence', f'{column_to_clean}_Status'])\n",
    "    return df.join(result_df)\n",
    "\n",
    "# main_df = pd.DataFrame(data, columns=['Recommended Action'])\n",
    "\n",
    "\n",
    "# 2. Call the function to clean the specified column\n",
    "# You provide your DataFrame, the column name, the list of correct values, and the confidence threshold.\n",
    "final_df = clean_column_strict(\n",
    "    df=clean_df,\n",
    "    column_to_clean='Recommended Action',\n",
    "    canonical_list=canonical_values,\n",
    "    threshold=80\n",
    ")\n",
    "\n",
    "# 3. Display the results\n",
    "print(\"--- Full Data Cleaning Results ---\")\n",
    "# Use .to_string() to ensure all columns are displayed without truncation\n",
    "#print(final_df.to_string())\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# 4. Display only the rows that need human attention\n",
    "print(\"--- Actions Flagged for Manual Review (Confidence < 80%) ---\")\n",
    "manual_review_df = final_df[final_df['Recommended Action_Status'] == 'NEEDS MANUAL REVIEW']\n",
    "\n",
    "if manual_review_df.empty:\n",
    "    print(\"No actions require manual review. All items met the 80% confidence threshold.\")\n",
    "else:\n",
    "    print(manual_review_df[['Recommended Action', 'Recommended Action_Cleaned', 'Recommended Action_Confidence']].to_string())\n",
    "\n",
    "\n",
    "print(f\"   After: {final_df['Recommended Action_Cleaned'].unique()}\")\n",
    "final_df\n",
    "final_df.to_excel(\"final_cleaned.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-4BOymaBxKZ"
   },
   "source": [
    "###  3.5: Final Cleanup – Dropping Redundant Columns\n",
    "\n",
    "In this step, we perform a final cleanup to remove columns that are no longer needed for analysis or modeling. These include metadata and intermediate columns from previous cleaning stages.\n",
    "\n",
    "---\n",
    "\n",
    "####  Breakdown:\n",
    "\n",
    "1. **Load Final Cleaned Data**\n",
    "   - Reads the Excel file `final_cleaned.xlsx`, which contains the dataset with standardized `Recommended Action` and other cleaned columns.\n",
    "\n",
    "2. **Remove Redundant Columns**\n",
    "   - The following columns are dropped:\n",
    "     - `'Recommended Action'`: Original raw column (replaced by the cleaned version).\n",
    "     - `'Recommended Action_Confidence'`: Confidence score from the fuzzy matching process (used for diagnostics).\n",
    "     - `'Recommended Action_Status'`: Flag for manual review (used during cleaning).\n",
    "     - `'Patient ID'`: Identifier column not relevant to statistical or ML modeling.\n",
    "\n",
    "3. **Save the Resulting Dataset**\n",
    "   - Exports the trimmed dataset as `data_final.xlsx`, which now contains only relevant and clean features for **Exploratory Data Analysis (EDA)** or modeling.\n",
    "\n",
    "---\n",
    "\n",
    " This marks the completion of the data cleaning phase.  \n",
    " The next step is **Exploratory Data Analysis (EDA)_** to understand the structure, relationships, and patterns in the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the file\n",
    "file_path = 'final_cleaned.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "columns_to_drop = ['Recommended Action','Recommended Action_Confidence','Recommended Action_Status','Patient ID']\n",
    "for col in columns_to_drop:\n",
    "    if col in df.columns:\n",
    "        df.drop(columns=[col], inplace=True)\n",
    "df.to_excel('data_final.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. verify data quality\n",
    "def print_all_value_counts(df):\n",
    "    for column in df.columns:\n",
    "        print(f\"--- Value Counts for: {column} ---\")\n",
    "        print(df[column].value_counts(dropna=False))  # include NaNs in the count\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Print unique values to check validity & quality:\n",
    "print_all_value_counts(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDDBz22rCFSX"
   },
   "source": [
    "# Data Visualization\n",
    "In this section, we explore the dataset visually to understand distributions, relationships, and trends across various features. This is a crucial step in identifying:\n",
    "\n",
    "- Imbalanced classes\n",
    "- Outliers\n",
    "- Skewed data\n",
    "- Correlations between features\n",
    "\n",
    "We use common plotting tools like:\n",
    "- **Histograms** to explore the distribution of numeric values\n",
    "- **Box plots** to detect outliers\n",
    "- **Count plots** to analyze category frequency\n",
    "- **Heatmaps** to examine feature correlation\n",
    "\n",
    "These insights guide decisions for data preprocessing and feature selection before training the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load cleaned Excel file\n",
    "final_df = pd.read_excel(\"cleaned_data.xlsx\")\n",
    "\n",
    "# Preview the data\n",
    "print(\" Data Preview \")\n",
    "print(final_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get numerical columns (int or float)\n",
    "numerical_cols = final_df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Get categorical columns\n",
    "categorical_cols = final_df.select_dtypes(include=['object', 'bool']).columns.tolist()\n",
    "\n",
    "print(\"Numerical Columns:\", numerical_cols)\n",
    "print(\"Categorical Columns:\", categorical_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# Distribution of Recommended Actions (from original column name)\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.countplot(\n",
    "    data=final_df,\n",
    "    y='Recommended Action',\n",
    "    order=final_df['Recommended Action'].value_counts().index,\n",
    "    palette='Set1'\n",
    "    # palette='tab20'\n",
    ")\n",
    "plt.title(\"Distribution of Recommended Actions\")\n",
    "plt.xlabel(\"Number of Patients\")\n",
    "plt.ylabel(\"Recommended Action\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n Summary of Categorical Columns\")\n",
    "print(final_df[categorical_cols].describe())\n",
    "\n",
    "# for col in categorical_cols:\n",
    "#     print(f\"\\n--- {col} ---\")\n",
    "#     print(final_df[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-4BOymaBxKZ"
   },
   "source": [
    "### Inspect and Verify Data Quality\n",
    "\n",
    "In this step, we perform a basic data audit:\n",
    "\n",
    "- Load the dataset from the CSV file.\n",
    "- Preview the data using `.head()` to understand its structure.\n",
    "- Use `.info()` to check data types and identify columns with missing values.\n",
    "- Count missing values per column to assess data completeness.\n",
    "- Print all unique values for each column to inspect potential inconsistencies or unexpected entries (e.g., typos in categorical fields).\n",
    "- Finally, we print the value counts for each column — including missing values — to evaluate how frequently each value appears. This helps identify:\n",
    "  - Class imbalance\n",
    "  - Invalid or rare values\n",
    "  - Columns that may require cleaning or transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot each categorical column EXCEPT Recommended Action\n",
    "for col in categorical_cols:\n",
    "    if col != 'Recommended Action':\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        sns.countplot(data=final_df, x=col, order=final_df[col].value_counts().index, palette='Set1')\n",
    "        plt.title(f\"Distribution of {col}\")\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Handle 'Recommended Action' separately (horizontally)\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.countplot(\n",
    "    data=final_df,\n",
    "    y='Recommended Action',\n",
    "    order=final_df['Recommended Action'].value_counts().index,\n",
    "    palette='Set1'\n",
    ")\n",
    "plt.title(\"Distribution of Recommended Actions\")\n",
    "plt.xlabel(\"Number of Patients\")\n",
    "plt.ylabel(\"Recommended Action\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histograms for Numerical Features\n",
    "numerical_cols = ['Age', 'Sexual Partners', 'First Sexual Activity Age']\n",
    "\n",
    "for col in numerical_cols:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.histplot(data=final_df, x=col, kde=True, bins=30, color='dodgerblue')\n",
    "    plt.title(f\"Distribution of {col}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation Heatmap\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(final_df[numerical_cols].corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Between Numerical Features')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Summary Stats for Numeric Features\n",
    "print(\"\\n Summary of Numerical Columns \")\n",
    "print(final_df[numerical_cols].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDDBz22rCFSX"
   },
   "source": [
    "\n",
    "# STEP 1: STANDARDIZING TARGET COLUMN VALUES(RECOMMENDATION)\n",
    "## Goal: Balance the data on the target column so that the model is not biased to a certain recommendation.\n",
    "\n",
    "We'll do:\n",
    "\n",
    "* Define our cannonical values.\n",
    "\n",
    "* Using confidence score and fuzzy matching for the standardization.Values that do not meet confoidence score are flagged for manual checking\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDDBz22rCFSX"
   },
   "source": [
    "\n",
    "# STEP 1: DATA SPLITTING\n",
    "## Goal:  Split the dataset to get the portion that goes into training and the portion that goes into testing\n",
    "\n",
    "We'll do:\n",
    "\n",
    "* Pre-split Fix.We notice that in the dataset,some critical columns have only one instance of it.Here we will use simple oversampling by manually duplicating these classes with only one instance.\n",
    "* Post-Split Oversampling- We will also perform SMOTE, only to the training set\n",
    "* stratified splitting on the data to ensure equal amount of percentage goes into both training and testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This list contains the final, correct values to use.\n",
    "canonical_values = [\n",
    "    \"REPEAT PAP SMEAR IN 3 YEARS\",\n",
    "    \"FOR COLPOSCOPY, BIOPSY, AND CYTOLOGY\",\n",
    "    \"FOR PAP SMEAR\",\n",
    "    \"FOR HPV VACCINE AND SEXUAL EDUCATION\",\n",
    "    \"FOR ANNUAL FOLLOW-UP AND PAP SMEAR IN 3 YEARS\",\n",
    "    \"REPEAT PAP SMEAR IN 3 YEARS AND FOR HPV VACCINE\",\n",
    "    \"FOR COLPOSCOPY, BIOPSY, AND CYTOLOGY (TAH NOT RECOMMENDED)\",\n",
    "    \"FOR BIOPSY AND CYTOLOGY (TAH NOT RECOMMENDED)\",\n",
    "    \"FOR HPV VACCINE, LIFESTYLE, AND SEXUAL EDUCATION\",\n",
    "    \"FOR COLPOSCOPY, BIOPSY, CYTOLOGY +/- TAH\",\n",
    "    \"FOR COLPOSCOPY, CYTOLOGY, THEN LASER THERAPY\",\n",
    "    \"FOR REPEAT HPV TESTING ANNUALLY AND PAP SMEAR IN 3 YEARS\",\n",
    "    \"FOR LASER THERAPY\"\n",
    "]\n",
    "\n",
    "# --- 2. Configuration for the Cleaner ---\n",
    "TYPO_MAP = {\n",
    "    'COLPOSOCPY': 'COLPOSCOPY', 'COLPOSCPY': 'COLPOSCOPY', 'COLOSCOPY': 'COLPOSCOPY',\n",
    "    'BIOSPY': 'BIOPSY', 'BIOSY': 'BIOPSY', 'ANUAL': 'ANNUAL', 'VACCINATION': 'VACCINE'\n",
    "}\n",
    "CRITICAL_KEYWORDS = {\n",
    "    'COLPOSCOPY', 'BIOPSY', 'CYTOLOGY', 'TAH', 'HPV', 'LASER', 'LIFESTYLE', 'ANNUALLY'\n",
    "}\n",
    "\n",
    "# --- 3. The Definitive Data Cleaning Function ---\n",
    "def clean_column_strict(df, column_to_clean, canonical_list, threshold=80):\n",
    "    \"\"\"\n",
    "    Cleans a DataFrame column using fuzzy matching combined with a STRICT keyword set equality rule.\n",
    "    \"\"\"\n",
    "    if column_to_clean not in df.columns:\n",
    "        raise ValueError(f\"Column '{column_to_clean}' not found in the DataFrame.\")\n",
    "\n",
    "    def preprocess_and_get_keywords(text, typo_map):\n",
    "        if not isinstance(text, str): return \"\", set()\n",
    "        # Standardize to uppercase and correct typos\n",
    "        processed_text = text.upper()\n",
    "        for wrong, right in typo_map.items():\n",
    "            processed_text = re.sub(r'\\b' + wrong + r'\\b', right, processed_text)\n",
    "        \n",
    "        # Extract the set of critical keywords\n",
    "        keywords = {word for word in CRITICAL_KEYWORDS if word in processed_text}\n",
    "        return processed_text, keywords\n",
    "\n",
    "    cleaned_data = []\n",
    "\n",
    "    # Pre-calculate keywords for the canonical list for efficiency\n",
    "    canonical_keywords = {val: preprocess_and_get_keywords(val, {})[1] for val in canonical_list}\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        raw_string = row[column_to_clean]\n",
    "        \n",
    "        if not isinstance(raw_string, str) or not raw_string.strip():\n",
    "            cleaned_data.append((raw_string, 0, 'NO_DATA_PROVIDED'))\n",
    "            continue\n",
    "\n",
    "        processed_string, original_keywords = preprocess_and_get_keywords(raw_string, TYPO_MAP)\n",
    "        \n",
    "        # Get the top few potential matches instead of just one\n",
    "        top_matches = process.extract(processed_string, canonical_list, limit=5)\n",
    "\n",
    "        best_valid_match = None\n",
    "        \n",
    "        for potential_match, score in top_matches:\n",
    "            if score < threshold:\n",
    "                break # No need to check further if scores are too low\n",
    "\n",
    "            # The CRITICAL check: The keyword sets must be identical\n",
    "            if original_keywords == canonical_keywords[potential_match]:\n",
    "                best_valid_match = (potential_match, score)\n",
    "                break # Found the best possible valid match, stop searching\n",
    "\n",
    "        if best_valid_match:\n",
    "            final_value, final_score = best_valid_match\n",
    "            status = 'OK'\n",
    "        else:\n",
    "            final_value = raw_string\n",
    "            final_score = top_matches[0][1] if top_matches else 0 # Show score of best (but invalid) match\n",
    "            status = 'NEEDS MANUAL REVIEW'\n",
    "\n",
    "        cleaned_data.append((final_value, final_score, status))\n",
    "\n",
    "    result_df = pd.DataFrame(cleaned_data, index=df.index, columns=[f'{column_to_clean}_Cleaned', f'{column_to_clean}_Confidence', f'{column_to_clean}_Status'])\n",
    "    return df.join(result_df)\n",
    "\n",
    "# main_df = pd.DataFrame(data, columns=['Recommended Action'])\n",
    "\n",
    "\n",
    "# 2. Call the function to clean the specified column\n",
    "# You provide your DataFrame, the column name, the list of correct values, and the confidence threshold.\n",
    "final_df = clean_column_strict(\n",
    "    df=clean_df,\n",
    "    column_to_clean='Recommended Action',\n",
    "    canonical_list=canonical_values,\n",
    "    threshold=80\n",
    ")\n",
    "\n",
    "# 3. Display the results\n",
    "print(\"--- Full Data Cleaning Results ---\")\n",
    "# Use .to_string() to ensure all columns are displayed without truncation\n",
    "#print(final_df.to_string())\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# 4. Display only the rows that need human attention\n",
    "print(\"--- Actions Flagged for Manual Review (Confidence < 80%) ---\")\n",
    "manual_review_df = final_df[final_df['Recommended Action_Status'] == 'NEEDS MANUAL REVIEW']\n",
    "\n",
    "if manual_review_df.empty:\n",
    "    print(\"No actions require manual review. All items met the 80% confidence threshold.\")\n",
    "else:\n",
    "    print(manual_review_df[['Recommended Action', 'Recommended Action_Cleaned', 'Recommended Action_Confidence']].to_string())\n",
    "\n",
    "\n",
    "print(f\"   After: {final_df['Recommended Action_Cleaned'].unique()}\")\n",
    "final_df\n",
    "final_df.to_excel(\"final_cleaned.xlsx\",index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the file\n",
    "file_path = 'final_cleaned.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "print(\"1. Removing unnecessary columns...\")\n",
    "columns_to_drop = ['Recommended Action','Recommended Action_Confidence','Recommended Action_Status','Patient ID']\n",
    "for col in columns_to_drop:\n",
    "    if col in df.columns:\n",
    "        df.drop(columns=[col], inplace=True)\n",
    "df.to_excel('data_final.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDDBz22rCFSX"
   },
   "source": [
    "\n",
    "# STEP 2: DATA SPLITTING\n",
    "## Goal:  Split the dataset to get the portion that goes into training and the portion that goes into testing\n",
    "\n",
    "We'll do:\n",
    "\n",
    "* Pre-split Fix.We notice that in the dataset,some critical columns have only one instance of it.Here we will use simple oversampling by manually duplicating these classes with only one instance.\n",
    "* stratified splitting on the data to ensure equal amount of percentage goes into both training and testing.\n",
    "* hot-encode remaining columns\n",
    "  # STEP 2B\n",
    "  ## Goal :Define class weights based on domain knowledge(Medical) to be fed into the data for use during training .\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Load Your Data ---\n",
    "# Let's create a sample DataFrame that mimics your situation\n",
    "\n",
    "data = pd.read_excel('data_final.xlsx')\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# --- 2. DEFINE TARGET and SEPARATE X and y ---\n",
    "target_column = 'Recommended Action_Cleaned'\n",
    "y = df[target_column]\n",
    "X = df.drop(columns=[target_column])\n",
    "\n",
    "\n",
    "# --- 3. PRE-SPLIT STEP: LABEL ENCODE THE TARGET COLUMN ---\n",
    "# This is required so that the 'stratify' parameter can work with numeric labels.\n",
    "print(\"\\n--- 3. Label Encoding Target Column (y) ---\")\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "print(\"Target column converted to numeric labels.\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "\n",
    "# --- 4. PRE-SPLIT STEP: HANDLE SINGLE-INSTANCE CLASSES for STRATIFICATION ---\n",
    "# Stratify needs at least 2 members per class. We duplicate the singletons.\n",
    "print(\"\\n--- 4. Checking for and Fixing Single-Instance Classes ---\")\n",
    "class_counts = pd.Series(y_encoded).value_counts()\n",
    "single_instance_classes = class_counts[class_counts < 2].index\n",
    "\n",
    "X_fixed = X.copy()\n",
    "y_fixed = y_encoded.copy()\n",
    "\n",
    "if len(single_instance_classes) > 0:\n",
    "    print(f\"Found {len(single_instance_classes)} classes with only one sample. Duplicating them...\")\n",
    "    \n",
    "    indices_to_duplicate = pd.Series(y_encoded).isin(single_instance_classes)\n",
    "    \n",
    "    X_to_duplicate = X[indices_to_duplicate]\n",
    "    y_to_duplicate = y_encoded[indices_to_duplicate]\n",
    "    \n",
    "    X_fixed = pd.concat([X, X_to_duplicate], ignore_index=True)\n",
    "    y_fixed = pd.concat([pd.Series(y_encoded), pd.Series(y_to_duplicate)], ignore_index=True).values\n",
    "else:\n",
    "    print(\"No single-instance classes found that would break stratification.\")\n",
    "\n",
    "print(f\"Shape before fix: {X.shape}. Shape after fix: {X_fixed.shape}.\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "    \n",
    "# --- 5. SPLIT THE DATA (CRITICAL LEAKAGE-PREVENTION STEP) ---\n",
    "# We split the 'fixed' data. X_fixed STILL CONTAINS THE TEXT/CATEGORICAL COLUMNS.\n",
    "print(\"\\n--- 5. Splitting Data into Training and Testing Sets ---\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_fixed, y_fixed, \n",
    "    test_size=0.2,       # 20% for testing\n",
    "    random_state=42,     # For reproducibility\n",
    "    stratify=y_fixed     # Ensure class distribution is similar\n",
    ")\n",
    "print(\"Data successfully split.\")\n",
    "print(f\"Training set size: {len(X_train)} rows\")\n",
    "print(f\"Test set size: {len(X_test)} rows\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "\n",
    "# --- 6. ONE-HOT ENCODE THE FEATURE COLUMNS (POST-SPLIT) ---\n",
    "# We learn the encoding schema ONLY from the training data to prevent data leakage.\n",
    "print(\"\\n--- 6. One-Hot Encoding Categorical Features ---\")\n",
    "# Automatically identify which columns are numeric and which are categorical from the training set\n",
    "numeric_features = X_train.select_dtypes(include='number').columns\n",
    "categorical_features = X_train.select_dtypes(include='object').columns\n",
    "\n",
    "print(f\"Identified Numeric Features: {list(numeric_features)}\")\n",
    "print(f\"Identified Categorical Features: {list(categorical_features)}\")\n",
    "\n",
    "# Create the encoder\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "# FIT the encoder ONLY on the TRAINING data's categorical columns\n",
    "encoder.fit(X_train[categorical_features])\n",
    "\n",
    "# TRANSFORM both the training and testing data's categorical columns\n",
    "X_train_encoded = pd.DataFrame(\n",
    "    encoder.transform(X_train[categorical_features]),\n",
    "    columns=encoder.get_feature_names_out(categorical_features),\n",
    "    index=X_train.index\n",
    ")\n",
    "X_test_encoded = pd.DataFrame(\n",
    "    encoder.transform(X_test[categorical_features]),\n",
    "    columns=encoder.get_feature_names_out(categorical_features),\n",
    "    index=X_test.index\n",
    ")\n",
    "\n",
    "# Reset index on all parts to ensure clean concatenation\n",
    "X_train_numeric_reset = X_train[numeric_features].reset_index(drop=True)\n",
    "X_test_numeric_reset = X_test[numeric_features].reset_index(drop=True)\n",
    "X_train_encoded_reset = X_train_encoded.reset_index(drop=True)\n",
    "X_test_encoded_reset = X_test_encoded.reset_index(drop=True)\n",
    "\n",
    "# Combine encoded categorical columns with the original numeric columns\n",
    "X_train_processed = pd.concat([X_train_numeric_reset, X_train_encoded_reset], axis=1)\n",
    "X_test_processed = pd.concat([X_test_numeric_reset, X_test_encoded_reset], axis=1)\n",
    "\n",
    "print(\"\\nFeatures have been successfully encoded.\")\n",
    "print(f\"Shape of processed training features: {X_train_processed.shape}\")\n",
    "print(f\"Shape of processed testing features: {X_test_processed.shape}\")\n",
    "print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDDBz22rCFSX"
   },
   "source": [
    "\n",
    "# STEP 2: DATA SPLITTING\n",
    "  ## Goal :Define class weights based on domain knowledge(Medical) to be fed into the data for use during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- 5. Manually Defining Class Weights Based on Clinical Importance ---\")\n",
    "\n",
    "# First, let's create a mapping from class names to their encoded labels for clarity\n",
    "label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(\"Class Label Mapping:\")\n",
    "print(label_mapping)\n",
    "\n",
    "# ===================================================================================\n",
    "# THIS IS WHERE YOU APPLY YOUR DOMAIN KNOWLEDGE.\n",
    "# You create the dictionary from scratch. Higher weight = higher penalty for getting it wrong.\n",
    "# You MUST provide a weight for every class label present in y_train.\n",
    "# ===================================================================================\n",
    "manual_weights_dict = {\n",
    "    label_mapping['REPEAT PAP SMEAR IN 3 YEARS AND FOR HPV VACCINE']: 1.0, # Majority/common class\n",
    "    label_mapping['FOR HPV VACCINE AND SEXUAL EDUCATION']: 1.2, # Slightly less common\n",
    "    label_mapping['FOR COLPOSCOPY, BIOPSY, AND CYTOLOGY']: 20.0, # IMPORTANT - High penalty\n",
    "    label_mapping['FOR LASER THERAPY']: 30.0, # CRITICALLY IMPORTANT - Very high penalty\n",
    "    label_mapping['FOR COLPOSCOPY, BIOPSY, CYTOLOGY +/- TAH']: 25.0, # IMPORTANT - High penalty\n",
    "    label_mapping[\"REPEAT PAP SMEAR IN 3 YEARS\"]:10.0,\n",
    "    label_mapping[\"FOR PAP SMEAR\"]:5.0,\n",
    "    label_mapping[\"FOR ANNUAL FOLLOW-UP AND PAP SMEAR IN 3 YEARS\"]:20.0,\n",
    "    label_mapping[\"FOR HPV VACCINE, LIFESTYLE, AND SEXUAL EDUCATION\"]:1.5,\n",
    "    label_mapping[\"FOR COLPOSCOPY, CYTOLOGY, THEN LASER THERAPY\"] :30.0,\n",
    "    label_mapping[\"FOR REPEAT HPV TESTING ANNUALLY AND PAP SMEAR IN 3 YEARS\"]:25.0,\n",
    "    label_mapping['FOR COLPOSCOPY, BIOPSY, AND CYTOLOGY (TAH NOT RECOMMENDED)']: 20.0,\n",
    "    label_mapping['FOR BIOPSY AND CYTOLOGY (TAH NOT RECOMMENDED)']: 20.0\n",
    "}\n",
    "\n",
    "print(\"\\nCustom Weights Defined:\")\n",
    "print(manual_weights_dict)\n",
    "print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDDBz22rCFSX"
   },
   "source": [
    "\n",
    "# STEP 3: Random Forest Classifier\n",
    "## Goal: Understand the features which have more influence on the target column. The columns with the most correlation will then be used to train the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# --- Stage A: Calculate Feature Importance and Select Features (on training data) ---\n",
    "print(\"\\n--- A. Calculating Feature Importance on Training Data ONLY ---\")\n",
    "\n",
    "# We train a preliminary RandomForest model to get feature importances.\n",
    "# It's good practice to use the class weights here too so the importance calculation\n",
    "# is not biased towards features that are only useful for the majority class.\n",
    "feature_selector_model = RandomForestClassifier(\n",
    "    random_state=42,\n",
    "    class_weight=manual_weights_dict\n",
    ")\n",
    "feature_selector_model.fit(X_train_processed, y_train)\n",
    "\n",
    "# Get the importance scores\n",
    "importances = feature_selector_model.feature_importances_\n",
    "feature_names = X_train_processed.columns\n",
    "importance_df = pd.DataFrame({'feature': feature_names, 'importance': importances}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "print(\"Top 14 most important features (learned from training data):\")\n",
    "print(importance_df.head(14))\n",
    "\n",
    "# --- Stage B: Perform the Feature Selection ---\n",
    "print(\"\\n--- B. Selecting Features Based on Importance ---\")\n",
    "\n",
    "# We can use a threshold (e.g., select features with importance > 0.01)\n",
    "# Or we can use a helper like SelectFromModel to automatically select them.\n",
    "# 'threshold=\"median\"' will select all features with importance greater than the median.\n",
    "selector = SelectFromModel(feature_selector_model, threshold='median', prefit=True)\n",
    "\n",
    "# Use the selector to get the final versions of our datasets\n",
    "X_train_final = selector.transform(X_train_processed)\n",
    "X_test_final = selector.transform(X_test_processed) # Apply same transformation to test set\n",
    "\n",
    "print(f\"\\nOriginal number of features: {X_train_processed.shape[1]}\")\n",
    "print(f\"Number of features selected: {X_train_final.shape[1]}\")\n",
    "print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "uC_dGuzYnPax",
    "outputId": "bacf49e2-1b61-416d-9bc6-c1b22e7e921a"
   },
   "outputs": [],
   "source": [
    "# 1\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check class balance for HPV\n",
    "sns.countplot(data=clean_df, x='HPV Test Result')\n",
    "plt.title('HPV Test Result Distribution')\n",
    "plt.show()\n",
    "\n",
    "# Check class balance for Pap Smear\n",
    "sns.countplot(data=clean_df, x='Pap Smear Result')\n",
    "plt.title('Pap Smear Result Distribution')\n",
    "plt.show()\n",
    "\n",
    "# Age distribution\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.histplot(data=clean_df, x='Age', bins=20, kde=True)\n",
    "plt.title('Age Distribution')\n",
    "plt.show()\n",
    "\n",
    "# Correlation matrix for numeric columns\n",
    "numeric_cols = clean_df.select_dtypes(include=['int64', 'float64']).columns\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(clean_df[numeric_cols].corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JiGEIbeAo8gk"
   },
   "source": [
    "In Exploratory Data Analysis (EDA), We focus on key target variables.\n",
    "\n",
    "In cervical cancer prediction, we treat this as a binary classification:\n",
    "\n",
    "Does this patient show signs that are likely to lead to cervical cancer?\n",
    "\n",
    "We use:\n",
    "\n",
    "Recommended Action → Could be used as proxy for diagnosis\n",
    "HPV Test Result\n",
    "Pap Smear Result\n",
    "Screening Type Last\n",
    "\n",
    "We’ll use these to understand who’s at risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 884
    },
    "id": "JA5KE39WlKeh",
    "outputId": "91ed067d-b1a8-4aa4-a643-4625f1be3d71"
   },
   "outputs": [],
   "source": [
    "# 2.Show distributions of key category values defined above\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set visual style\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# HPV Test Result distribution\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(data=clean_df, x='HPV Test Result', palette='Set2')\n",
    "plt.title('Distribution of HPV Test Results')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Pap Smear Result distribution\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(data=clean_df, x='Pap Smear Result', palette='Set3')\n",
    "plt.title('Distribution of Pap Smear Results')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Recommended Action distribution (top 10)\n",
    "plt.figure(figsize=(10,6))\n",
    "top_actions = clean_df['Recommended Action'].value_counts().nlargest(10)\n",
    "sns.barplot(y=top_actions.index, x=top_actions.values, palette='coolwarm')\n",
    "plt.title('Top 10 Recommended Actions')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Recommended Action')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 672
    },
    "id": "mjaeT-M4o50m",
    "outputId": "35bc3a21-4ff1-4f5e-e519-495854655d80"
   },
   "outputs": [],
   "source": [
    "# List of important numerical features\n",
    "num_features = ['Age', 'Sexual Partners', 'First Sexual Activity Age']\n",
    "\n",
    "# Plot histograms\n",
    "clean_df[num_features].hist(bins=20, figsize=(12, 6), color='skyblue')\n",
    "plt.suptitle('Distribution of Key Numeric Features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Heatmap to check which features are correlated with others.\n",
    "\n",
    "# only numerical columns\n",
    "numeric_cols = clean_df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(clean_df[numeric_cols].corr(), annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Between Numerical Features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6SmiHmNpBsXX"
   },
   "source": [
    "# STEP 3: Modeling and Pre-Training Phase\n",
    "\n",
    "##  Goal:\n",
    "Build and evaluate a predictive model using your **cleaned**, **preprocessed** dataset.  \n",
    "This phase helps us learn patterns from the data and **predict High Risk patients** based on clinical features.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary Table of Key Steps\n",
    "\n",
    "| Step                        | What it Means                                                                 | What You Do                                                   |\n",
    "|-----------------------------|-------------------------------------------------------------------------------|---------------------------------------------------------------|\n",
    "| 1. Feature & Target Selection | Choose what we want to predict (target) and the data used to predict it (features). | `X = datav_clean[features]` <br> `y = datav_clean['High Risk']` |\n",
    "| 2. Train-Test Splitting    | Split the dataset into training and test sets for fair model evaluation.    | `train_test_split(X, y, test_size=0.2, random_state=0)`       |\n",
    "| 3. Scaling / Encoding (if needed) | Standardize numeric values to a common scale (important for some models like logistic regression). | `StandardScaler()` or `MinMaxScaler()` if model needs it      |\n",
    "| 4. Model Selection         | Choose a model suitable for classification.                                 | `DecisionTreeClassifier()`, `LogisticRegression()`, etc.      |\n",
    "| 5. Model Training         | Feed the training data into the model so it can learn patterns.            | `model.fit(X_train, y_train)`                                 |\n",
    "| 6. Evaluation              | Check the model’s accuracy, precision, recall, etc. using test data.        | `confusion_matrix`, `classification_report`, `accuracy_score` |\n",
    "| 7. Interpretation          | Understand feature importance and model behavior.                          | `model.feature_importances_` or tree plots                    |\n",
    "\n",
    "---\n",
    "\n",
    "## Output of This Phase:\n",
    "- A trained and evaluated model that can predict if a patient is **High Risk** for cervical cancer.\n",
    "- Metrics to judge how well the model performs.\n",
    "- A ranked list of which features are most important in making predictions (e.g., age, smoking, screening type).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Clean messy strings (e.g., \" yes \" → \"YES\")\n",
    "\n",
    "#Maps them to numbers\n",
    "#Prepares the dataframe to work seamlessly with your existing risk-flagging logic.\n",
    "\n",
    "# Ensure all relevant columns in clean_df are encoded before making a copy\n",
    "clean_df\n",
    "\n",
    "clean_df['Pap Smear Result'] = clean_df['Pap Smear Result'].astype(str).str.upper().str.strip().replace({\n",
    "    'N': 0, 'Y': 1\n",
    "})\n",
    "\n",
    "clean_df['Smoking Status'] = clean_df['Smoking Status'].astype(str).str.upper().str.strip().replace({\n",
    "    'N': 0, 'Y': 1, 'TRUE': 1, 'FALSE': 0\n",
    "})\n",
    "\n",
    "clean_df['STDs History'] = clean_df['STDs History'].astype(str).str.upper().str.strip().replace({\n",
    "    'N': 0, 'Y': 1, 'TRUE': 1, 'FALSE': 0\n",
    "})\n",
    "\n",
    "clean_df['Insurance Covered'] = clean_df['Insurance Covered'].astype(str).str.upper().str.strip().replace({\n",
    "    'N': 0, 'Y': 1\n",
    "})\n",
    "\n",
    "clean_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Because the cervical cancer dataset doesn’t contain a direct diagnosis column like \"has cancer = yes/no\", \n",
    "#we are creating a new feature called High Risk. \n",
    "# we use real clinical clues (like positive test results or medical recommendations) to determine whether a patient is high risk.\n",
    "# This new High Risk column becomes your true target — better than using only HPV Test Result\n",
    "\n",
    "# 1. Make a fresh copy\n",
    "datav = clean_df.copy()\n",
    "\n",
    "# 2. Encode relevant binary columns. 'YES' = 1 (indicating presence)'NO' = 0 (indicating absence)\n",
    "datav['HPV Test Result'] = datav['HPV Test Result'].map({'NEGATIVE': 0, 'POSITIVE': 1})\n",
    "\n",
    "# 3. Handle Screening Type Last → create new binary feature: Screening Type Suspicious, first clean this column:\n",
    "# Replace missing values (NaN) with 'UNKNOWN'\n",
    "# Standardize capitalization (so 'hpv', 'HPV ', 'Hpv' all become 'HPV')\n",
    "\n",
    "#Remove leading/trailing spaces\n",
    "datav['Screening Type Last'] = datav['Screening Type Last'].fillna('UNKNOWN').str.upper().str.strip()\n",
    "datav['Screening Type Suspicious'] = datav['Screening Type Last'].apply(\n",
    "    lambda x: 1 if any(word in x for word in ['COLPOSCOPY', 'PAP', 'HPV']) else 0\n",
    ")\n",
    "\n",
    "# 4. Create HIGH RISK target variable ie\n",
    "# We are flagging a patient as high risk if any of these are true:\n",
    "\n",
    "# Their HPV test is positive\n",
    "# Their Pap smear is abnormal\n",
    "# Their last screening type was serious (like HPV or Colposcopy)\n",
    "# Their doctor recommended a follow-up action like biopsy or colposcopy\n",
    "\n",
    "datav['High Risk'] = 0  # default\n",
    "\n",
    "# High risk if HPV positive AND Pap Smear positive\n",
    "datav.loc[(datav['HPV Test Result'] == 1) & (datav['Pap Smear Result'] == 1), 'High Risk'] = 1\n",
    "\n",
    "# OR if Recommended Action includes serious follow-up\n",
    "datav['High Risk'] = datav.apply(\n",
    "    lambda row: 1 if 'BIOPSY' in row['Recommended Action'].upper() or 'COLPOSCOPY' in row['Recommended Action'].upper() else row['High Risk'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# OR if Screening Type is suspicious\n",
    "datav.loc[datav['Screening Type Suspicious'] == 1, 'High Risk'] = 1\n",
    "\n",
    "# ✅ Done\n",
    "print(\"High Risk class distribution:\")\n",
    "print(datav['High Risk'].value_counts())\n",
    "\n",
    "print(datav['Screening Type Suspicious'].value_counts())\n",
    "\n",
    "datav\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding.\n",
    "#Here we encode the Region,screening Type Last to binary. \n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Screening Type Last': ['Pap Smear', 'HPV DNA Test', 'Co-testing', 'Pap Smear'],\n",
    "    'Region': ['Nairobi', 'Kisumu', 'Mombasa', 'Nairobi'],\n",
    "    'Screening Type Last':['PAP SMEAR','HPV DNA'],\n",
    "    'Recommended Action',\n",
    "})\n",
    "\n",
    "# Apply one-hot encoding\n",
    "df_encoded = pd.get_dummies(df, columns=['Screening Type Last', 'Region'])\n",
    "print(df_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop some columns\n",
    "#Region\n",
    "#Reason to drop:\n",
    "#This column is likely categorical geographic data (e.g., \"Central\", \"Nairobi\", \"Unknown\") and:\n",
    "#It doesn’t directly indicate a person’s biological or clinical risk\n",
    "#Might introduce location-based bias (e.g., model predicts higher risk just because someone is from a certain place)\n",
    "#Can skew the model especially with small or uneven sample sizes per region\n",
    "\n",
    "#Screening Type Last\n",
    "#Reason to drop:\n",
    "#You already extracted useful info from this column into a binary feature called:Screening Type Suspicious\n",
    "\n",
    "#This feature captures whether the last screening method was highly diagnostic (e.g., HPV test, Pap smear, or Colposcopy). Keeping both would introduce redundancy.\n",
    "#Drop to avoid duplication and multicollinearity\n",
    "\n",
    "#Recommended Action\n",
    "#Reason to drop:\n",
    "#You already used this column to build your target variable High Risk, based on whether the action was “biopsy” or “colposcopy”.\n",
    "#Keeping this column in the features would leak information that was already used to define the target — this is called data leakage in machine learning.\n",
    "#Drop to prevent data leakage\n",
    "\n",
    "#Insurance Covered\n",
    "#Reason to drop:\n",
    "#While important socially, it:\n",
    "#Doesn’t represent actual clinical or biological risk\n",
    "#Could lead the model to predict based on financial access rather than medical condition\n",
    "#Introduces ethical concerns (e.g., model assumes uninsured = low risk, which is false)\n",
    "#Drop for ethical, clinical, and fairness reasons\n",
    "\n",
    "# List of columns to drop\n",
    "cols_to_drop = [\n",
    "    'Region',\n",
    "    'Screening Type Last',\n",
    "    'Recommended Action',\n",
    "    'Insurance Covered'\n",
    "]\n",
    "\n",
    "# Drop them from the cleaned dataset\n",
    "datav_clean = datav.drop(columns=cols_to_drop)\n",
    "\n",
    "# Optional: confirm the updated columns\n",
    "print(\"Remaining columns after drop:\")\n",
    "print(datav_clean.columns)\n",
    "datav_clean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6SmiHmNpBsXX"
   },
   "source": [
    "# STEP 4 Modeling Phase-Decision Tree Classifier\n",
    "\n",
    "## Why Decision Tree?\n",
    "We're using a Decision Tree model (CART) to classify patients as **High Risk** or **Not High Risk** based on medical and behavioral features.\n",
    "\n",
    "---\n",
    "\n",
    "## Advantages of Decision Trees\n",
    "- **Low computational cost**: Trees are logarithmic in complexity, making them scalable for large datasets.\n",
    "- **White-box model**: Easy to interpret and visualize. We can trace how decisions are made.\n",
    "- **Minimal data preparation**: No need to normalize, scale, or encode dummy variables for numerical trees.\n",
    "\n",
    "---\n",
    "\n",
    "## Disadvantages of Decision Trees\n",
    "- **Overfitting**: Trees may perfectly fit training data but perform poorly on new data. (We can use pruning or switch to Random Forests.)\n",
    "- **Instability**: Small data changes can lead to completely different trees.\n",
    "- **Class ambiguity**: Trees struggle if many examples have identical features but different labels (noisy/conflicting data).\n",
    "\n",
    "---\n",
    "\n",
    "##  Data Check Before Modeling\n",
    "To verify if identical inputs have different outputs (inconsistent cases), we can run this loop:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w1P4plxo3eJm"
   },
   "outputs": [],
   "source": [
    "# Train & Evaluate a Decision Tree Classifier 1. Splitting the data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define features and target\n",
    "features = [\n",
    "    'Age', \n",
    "    'Sexual Partners', \n",
    "    'First Sexual Activity Age',\n",
    "    'Smoking Status',\n",
    "    'STDs History',\n",
    "    'Screening Type Suspicious'\n",
    "]\n",
    "\n",
    "X = datav_clean[features]\n",
    "y = datav_clean['High Risk']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "97jI8hdKMZqR"
   },
   "outputs": [],
   "source": [
    "#Train, Evaluate, and Interpret a Decision Tree Model\n",
    "# 1. Train the Model\n",
    "#Now that you've split your data into training and testing sets, you're ready to train a DecisionTreeClassifier.\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize the model\n",
    "dtree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train (fit) the model on training data\n",
    "dtree.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mDvoOWXLGgcF"
   },
   "outputs": [],
   "source": [
    "#Make Predictions\n",
    "# Once trained, predict on the test data and evaluate performance.\n",
    "# Predict on the test set\n",
    "y_pred = dtree.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_RHs07-bPYFe"
   },
   "source": [
    "## Model from ScikitLearn\n",
    "\n",
    "\n",
    "*   Uses CART algorithm, meaning that each leaf can only have two children. aka binary trees\n",
    "*   ID3 algorithm could produce nodes with more than 2 children\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s3YhzKY737GH"
   },
   "outputs": [],
   "source": [
    "#Evaluate the Model\n",
    "#We'll use accuracy, confusion matrix, and classification report to assess how well your model performs.\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Accuracy\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\n Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Precision, Recall, F1-score\n",
    "print(\"\\n Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Not High Risk\", \"High Risk\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning (Grid Search)\n",
    "#  Train using GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "# Define model and grid\n",
    "param_grid = {\n",
    "    'max_depth': [4, 5, 6, 7, 8, 9, 10, 11],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=DecisionTreeClassifier(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    scoring=make_scorer(f1_score),\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Extract best model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the Best Model, this is after the grid search and prediction:\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Not High Risk\", \"High Risk\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IUcAIkyBfjlz"
   },
   "outputs": [],
   "source": [
    "# Visualize the Tree \n",
    "# This helps you understand the decision logic your model has learned.\n",
    "\n",
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plot_tree(\n",
    "    best_model,\n",
    "    feature_names=features,\n",
    "    class_names=['Not High Risk', 'High Risk'],\n",
    "    filled=True,\n",
    "    rounded=True\n",
    ")\n",
    "plt.title(\"First Decision Tree\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wnfzkNelQR73",
    "outputId": "048274f5-0594-4116-848b-20e71ce0ca5f"
   },
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "# See which features the tree considered most useful in classification.\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use best_model, not dtree\n",
    "feature_importances = pd.Series(best_model.feature_importances_, index=features)\n",
    "\n",
    "# Sort and plot\n",
    "feature_importances.sort_values(ascending=True).plot(\n",
    "    kind='barh',\n",
    "    title='Feature Importances',\n",
    "    figsize=(8, 5),\n",
    "    color='skyblue'\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Importance Score\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "567VG4dkRCkz"
   },
   "outputs": [],
   "source": [
    "#Pruning (To Prevent Overfitting)\n",
    "#(to do limit tree depth, minimum samples, etc.)\n",
    "\n",
    "# Create a pruned version of the tree\n",
    "dtree_pruned = DecisionTreeClassifier(\n",
    "    max_depth=3,               # limit depth to 3 levels (simpler tree)\n",
    "    min_samples_split=10,      # at least 10 samples to consider a split\n",
    "    random_state=42            # reproducibility\n",
    ")\n",
    "\n",
    "dtree_pruned.fit(X_train, y_train)  # Train on training set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with the pruned tree\n",
    "y_pred_pruned = dtree_pruned.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the pruned model\n",
    "print(\"Pruned Tree Accuracy:\", accuracy_score(y_test, y_pred_pruned))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred_pruned))\n",
    "print(classification_report(y_test, y_pred_pruned))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_RHs07-bPYFe"
   },
   "source": [
    "# Compare: Grid Search Model vs Pruned Tree\n",
    "* Evaluate both models on the same test data\n",
    "* Show accuracy, F1, confusion matrix, and classification report\n",
    "* Output the better final decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "# -------------------------------\n",
    "# Evaluate Best Grid Search Model\n",
    "# -------------------------------\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "print(\"Grid Search Model Evaluation\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_best))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_best))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_best))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_best))\n",
    "\n",
    "\n",
    "# ---------------------\n",
    "# Evaluate Pruned Model\n",
    "# ---------------------\n",
    "y_pred_pruned = dtree_pruned.predict(X_test)\n",
    "\n",
    "print(\"\\n Pruned Model Evaluation\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_pruned))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_pruned))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_pruned))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_pruned))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_RHs07-bPYFe"
   },
   "source": [
    "# Summary of Results\n",
    "\n",
    "| **Metric**           | **Grid Search Model**           | **Pruned Decision Tree**       |\n",
    "|----------------------|----------------------------------|---------------------------------|\n",
    "| **Accuracy**         | 0.95                             |    1.00                         |\n",
    "| **F1 Score**         | 0.9677                           |    1.00                         |\n",
    "| **Confusion Matrix** | 1 FN (missed class 0)            |    Perfect                      |\n",
    "| **Interpretability** | Moderate (depth may vary)        |    Simple (you control depth)   |\n",
    "| **Overfitting Risk** | Medium                           |    High (check generalizability) |\n",
    "\n",
    "---\n",
    "\n",
    "# Interpretation\n",
    "\n",
    "##  Why the Pruned Model is Better (for Now):\n",
    "\n",
    "* **Perfect performance on test set**: 100% accuracy and F1 score — no false positives or negatives.\n",
    "* **Simpler model**: Easier to interpret and explain.\n",
    "* **Faster**: Less computational load.\n",
    "\n",
    "---\n",
    "\n",
    "# Disadvantage: Overfitting Risk\n",
    "\n",
    "Even though the pruned tree scores perfectly, keep in mind:\n",
    "\n",
    "* It may be **memorizing the training data**.\n",
    "* With a small test set (only 20 samples), this result may **not generalize** well to unseen patients.\n",
    "\n",
    "---\n",
    "\n",
    "# Final Steps\n",
    "\n",
    "**stick with the pruned tree**, because:\n",
    "\n",
    "* The **dataset is small**.\n",
    "* We need a **quick, interpretable model**.\n",
    "* Need a proof of concept**explain it to doctors or healthcare decision-makers**.\n",
    "\n",
    "---\n",
    "\n",
    "We compared a hyperparameter-tuned Decision Tree via Grid Search with a manually pruned version. Although both performed well, the pruned tree achieved perfect performance on our test set with fewer parameters and more interpretability. Due to our small dataset and the importance of explainability in medical predictions, we select the pruned model as our final classifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QfhcZWLnCoiH"
   },
   "source": [
    "## Final decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the Final Tree-pruned tree\n",
    "# imports are included first\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "#  Visualize the pruned decision tree\n",
    "dot_data = export_graphviz(\n",
    "    dtree_pruned,  # Make sure this is the correct pruned model variable\n",
    "    out_file=None,\n",
    "    feature_names=features,\n",
    "    class_names=[\"Not High Risk\", \"High Risk\"],\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    special_characters=True\n",
    ")\n",
    "\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"final_decision_tree_pruned\", format='png', cleanup=True)\n",
    "graph  # This will display the tree in Jupyter Notebook\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XLUQAuspRCoB"
   },
   "outputs": [],
   "source": [
    "# Save Your Model (Optional for deployment)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(dtree_pruned, 'final_cervical_risk_model.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZLLERVD2iYK"
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "After building, tuning, and evaluating our Decision Tree Classifier, here is the summary of our results:\n",
    "\n",
    "---\n",
    "\n",
    "## Optimal Model Parameters (from Grid Search)\n",
    "- **Criterion**: `entropy`\n",
    "- **Max Depth**: `4`\n",
    "- **Min Samples Leaf**: `2`\n",
    "- **Min Samples Split**: `6`\n",
    "\n",
    "These parameters were found using GridSearchCV and 5-fold cross-validation with F1 score as the evaluation metric.\n",
    "\n",
    "---\n",
    "\n",
    "## Final Model Performance\n",
    "- **Accuracy**: ~96%\n",
    "- **F1 Score**: ~0.97\n",
    "- **Confusion Matrix**: Very few false positives/negatives\n",
    "- **Interpretability**: High, due to controlled depth and pruned tree structure\n",
    "\n",
    "---\n",
    "\n",
    "##  Why This Model Works Well\n",
    "- Balances accuracy and generalizability.\n",
    "- Performs well on both training and test data.\n",
    "- Easy to interpret for healthcare professionals and stakeholders.\n",
    "- Ideal for small to medium medical datasets.\n",
    "\n",
    "---\n",
    "\n",
    "## Final Notes\n",
    "- While performance is excellent on this dataset, further evaluation on **larger or external datasets** is advised before clinical use.\n",
    "- Always ensure models are validated across populations and reviewed with domain experts before deployment.\n",
    "\n",
    "---\n",
    "\n",
    " **Next Steps for more interactive interface:**\n",
    "- Deploy the model for interactive predictions.\n",
    "- Integrate with a simple web app or API.\n",
    "- Explore ensemble methods (Random Forest, XGBoost) for more robustness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "car15kHwLxB9"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
