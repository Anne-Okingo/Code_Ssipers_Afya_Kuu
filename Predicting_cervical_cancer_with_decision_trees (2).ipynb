{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "g_EfJsu2hZqr"
   },
   "outputs": [],
   "source": [
    "# 1. Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dGDEWIlDS6Cf"
   },
   "source": [
    "## References\n",
    "\n",
    "\n",
    "*    [Scikit Learn](https://scikit-learn.org/stable/modules/tree.html) decision tree documentation\n",
    "*   [Breast Cancer dataset](https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/) - UCI Machine learning database\n",
    "*   [Medium article ](https://medium.com/@chyun55555/decision-tree-classifier-with-scikit-learn-from-python-e83f38079fea) for modeling decision trees\n",
    "*  [Hands-On Machine Learning book](https://www.amazon.com/Hands-Machine-Learning-Scikit-Learn-TensorFlow/dp/1491962291) for decision trees and random forests\n",
    "* [ Medium article](https://medium.com/@jaimejcheng/data-exploration-and-visualization-with-seaborn-pair-plots-40e6d3450f6d) for Seaborn pair plots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-4BOymaBxKZ"
   },
   "source": [
    "# step 1 Data Loading and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "NChL47NVhXiv"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sexual Partners</th>\n",
       "      <th>First Sexual Activity Age</th>\n",
       "      <th>HPV Test Result</th>\n",
       "      <th>Pap Smear Result</th>\n",
       "      <th>Smoking Status</th>\n",
       "      <th>STDs History</th>\n",
       "      <th>Region</th>\n",
       "      <th>Insrance Covered</th>\n",
       "      <th>Screening Type Last</th>\n",
       "      <th>Recommended Action</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P0001</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Pumwani</td>\n",
       "      <td>Y</td>\n",
       "      <td>PAP SMEAR</td>\n",
       "      <td>REPEAT PAP SMEAR IN 3 YEARS AND FOR HPV VACCINE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P0002</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Kakamega</td>\n",
       "      <td>N</td>\n",
       "      <td>HPV DNA</td>\n",
       "      <td>FOR HPV VACCINE AND SEXUAL EDUCATION</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P0003</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Machakos</td>\n",
       "      <td>N</td>\n",
       "      <td>HPV DNA</td>\n",
       "      <td>FOR HPV VACCINE AND SEXUAL EDUCATION</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P0004</td>\n",
       "      <td>52</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Embu</td>\n",
       "      <td>Y</td>\n",
       "      <td>HPV DNA</td>\n",
       "      <td>FOR HPV VACCINE, LIFESTYLE AND SEXUAL EDUCATION</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P0005</td>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Mombasa</td>\n",
       "      <td>N</td>\n",
       "      <td>HPV DNA</td>\n",
       "      <td>FOR HPV VACCINE AND SEXUAL EDUCATION</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>P0096</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Machakos</td>\n",
       "      <td>N</td>\n",
       "      <td>PAP SMEAR</td>\n",
       "      <td>FOR COLPOSCOPY BIOPSY, CYTOLOGY</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>P0097</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Mombasa</td>\n",
       "      <td>N</td>\n",
       "      <td>PAP SMEAR</td>\n",
       "      <td>REPEAT PAP SMEAR IN 3 YEARS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>P0098</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Kericho</td>\n",
       "      <td>N</td>\n",
       "      <td>HPV DNA</td>\n",
       "      <td>FOR ANUAL FOLLOW UP AND PAP SMEAR IN 3 YEARS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>P0099</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Embu</td>\n",
       "      <td>Y</td>\n",
       "      <td>HPV DNA</td>\n",
       "      <td>FOR COLPOSCOPY BIOPSY, CYTOLOGY</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>P0100</td>\n",
       "      <td>59</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Kitale</td>\n",
       "      <td>Y</td>\n",
       "      <td>HPV DNA</td>\n",
       "      <td>FOR COLPOSCOPY BIOPSY, CYTOLOGY +/-TAH</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient ID  Age  Sexual Partners  First Sexual Activity Age  \\\n",
       "0       P0001   18                4                         15   \n",
       "1       P0002   15                1                         14   \n",
       "2       P0003   34                1                          9   \n",
       "3       P0004   52                5                         16   \n",
       "4       P0005   46                3                         21   \n",
       "..        ...  ...              ...                        ...   \n",
       "95      P0096   31                4                         16   \n",
       "96      P0097   35                5                         11   \n",
       "97      P0098   35                1                         18   \n",
       "98      P0099   31                1                         20   \n",
       "99      P0100   59                6                         22   \n",
       "\n",
       "   HPV Test Result Pap Smear Result Smoking Status STDs History     Region  \\\n",
       "0         NEGATIVE                N              N            Y   Pumwani    \n",
       "1         POSITIVE                N              Y            Y  Kakamega    \n",
       "2         POSITIVE                N              N            Y   Machakos   \n",
       "3         POSITIVE                N              Y            N      Embu    \n",
       "4         POSITIVE                N              N            N    Mombasa   \n",
       "..             ...              ...            ...          ...        ...   \n",
       "95        POSITIVE                Y              Y            N   Machakos   \n",
       "96        NEGATIVE                N              Y            N    Mombasa   \n",
       "97        POSITIVE                N              Y            N    Kericho   \n",
       "98        POSITIVE                Y              Y            N      Embu    \n",
       "99        POSITIVE                Y              N            Y    Kitale    \n",
       "\n",
       "   Insrance Covered Screening Type Last  \\\n",
       "0                 Y           PAP SMEAR   \n",
       "1                 N             HPV DNA   \n",
       "2                 N             HPV DNA   \n",
       "3                 Y             HPV DNA   \n",
       "4                 N             HPV DNA   \n",
       "..              ...                 ...   \n",
       "95                N           PAP SMEAR   \n",
       "96                N           PAP SMEAR   \n",
       "97                N             HPV DNA   \n",
       "98                Y             HPV DNA   \n",
       "99                Y             HPV DNA   \n",
       "\n",
       "                                 Recommended Action Unnamed: 12  \n",
       "0   REPEAT PAP SMEAR IN 3 YEARS AND FOR HPV VACCINE         NaN  \n",
       "1              FOR HPV VACCINE AND SEXUAL EDUCATION         NaN  \n",
       "2              FOR HPV VACCINE AND SEXUAL EDUCATION         NaN  \n",
       "3   FOR HPV VACCINE, LIFESTYLE AND SEXUAL EDUCATION         NaN  \n",
       "4              FOR HPV VACCINE AND SEXUAL EDUCATION         NaN  \n",
       "..                                              ...         ...  \n",
       "95                  FOR COLPOSCOPY BIOPSY, CYTOLOGY         NaN  \n",
       "96                      REPEAT PAP SMEAR IN 3 YEARS         NaN  \n",
       "97     FOR ANUAL FOLLOW UP AND PAP SMEAR IN 3 YEARS         NaN  \n",
       "98                 FOR COLPOSCOPY BIOPSY, CYTOLOGY          NaN  \n",
       "99           FOR COLPOSCOPY BIOPSY, CYTOLOGY +/-TAH         NaN  \n",
       "\n",
       "[100 rows x 13 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 2. Load Excel and Save as CSV\n",
    "excel_path = 'Cervical Cancer Datasets_.xlsx'\n",
    "csv_path = 'cervical_cancer.csv'\n",
    "\n",
    "df = pd.read_excel(excel_path)\n",
    "df.to_csv(csv_path,index=False)\n",
    "\n",
    "# 3. Load CSV (use header=None only if the dataset has no headers)\n",
    "data = pd.read_csv(csv_path)  # Remove `header=None` if headers are present\n",
    "\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data= data.drop_duplicates(subset='Patient ID', keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dGDEWIlDS6Cf"
   },
   "source": [
    "## Duplicate data\n",
    "\n",
    "The code below considers the patient ID as the unique identifier and checks if 80%  of the rows  has similar values,it is flagged for checking.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag duplicates and export them for manual checking\n",
    "data['is_duplicate'] = data.duplicated(subset=df.columns.difference(['Patient ID']), keep=False)\n",
    "duplicates_df = data[data['is_duplicate'] == True]\n",
    "duplicates_df.to_csv('flagged_duplicates.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Patient ID', 'Age', 'Sexual Partners', 'First Sexual Activity Age',\n",
      "       'HPV Test Result', 'Pap Smear Result', 'Smoking Status', 'STDs History',\n",
      "       'Region', 'Insrance Covered', 'Screening Type Last',\n",
      "       'Recommended Action', 'Unnamed: 12', 'is_duplicate'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "The data set has ( Total rows: 100, Total columns: 14)\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)\n",
    "print(\"\\n\")\n",
    "print(f\"The data set has ( Total rows: {len(data)}, Total columns: {len(data.columns)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Patient ID  Age  Sexual Partners  First Sexual Activity Age HPV Test Result  \\\n",
      "0      P0001   18                4                         15        NEGATIVE   \n",
      "1      P0002   15                1                         14        POSITIVE   \n",
      "2      P0003   34                1                          9        POSITIVE   \n",
      "3      P0004   52                5                         16        POSITIVE   \n",
      "4      P0005   46                3                         21        POSITIVE   \n",
      "\n",
      "  Pap Smear Result Smoking Status STDs History     Region Insrance Covered  \\\n",
      "0                N              N            Y   Pumwani                 Y   \n",
      "1                N              Y            Y  Kakamega                 N   \n",
      "2                N              N            Y   Machakos                N   \n",
      "3                N              Y            N      Embu                 Y   \n",
      "4                N              N            N    Mombasa                N   \n",
      "\n",
      "  Screening Type Last                               Recommended Action  \\\n",
      "0           PAP SMEAR  REPEAT PAP SMEAR IN 3 YEARS AND FOR HPV VACCINE   \n",
      "1             HPV DNA             FOR HPV VACCINE AND SEXUAL EDUCATION   \n",
      "2             HPV DNA             FOR HPV VACCINE AND SEXUAL EDUCATION   \n",
      "3             HPV DNA  FOR HPV VACCINE, LIFESTYLE AND SEXUAL EDUCATION   \n",
      "4             HPV DNA             FOR HPV VACCINE AND SEXUAL EDUCATION   \n",
      "\n",
      "  Unnamed: 12  \n",
      "0         NaN  \n",
      "1         NaN  \n",
      "2         NaN  \n",
      "3         NaN  \n",
      "4         NaN  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 13 columns):\n",
      " #   Column                     Non-Null Count  Dtype \n",
      "---  ------                     --------------  ----- \n",
      " 0   Patient ID                 100 non-null    object\n",
      " 1   Age                        100 non-null    int64 \n",
      " 2   Sexual Partners            100 non-null    int64 \n",
      " 3   First Sexual Activity Age  100 non-null    int64 \n",
      " 4   HPV Test Result            100 non-null    object\n",
      " 5   Pap Smear Result           100 non-null    object\n",
      " 6   Smoking Status             100 non-null    object\n",
      " 7   STDs History               100 non-null    object\n",
      " 8   Region                     100 non-null    object\n",
      " 9   Insrance Covered           100 non-null    object\n",
      " 10  Screening Type Last        100 non-null    object\n",
      " 11  Recommended Action         100 non-null    object\n",
      " 12  Unnamed: 12                1 non-null      object\n",
      "dtypes: int64(3), object(10)\n",
      "memory usage: 10.3+ KB\n",
      "None\n",
      "Missing values per column:\n",
      " Patient ID                    0\n",
      "Age                           0\n",
      "Sexual Partners               0\n",
      "First Sexual Activity Age     0\n",
      "HPV Test Result               0\n",
      "Pap Smear Result              0\n",
      "Smoking Status                0\n",
      "STDs History                  0\n",
      "Region                        0\n",
      "Insrance Covered              0\n",
      "Screening Type Last           0\n",
      "Recommended Action            0\n",
      "Unnamed: 12                  99\n",
      "dtype: int64\n",
      "Number of duplicate rows: 0\n",
      "--- Unique values for: Patient ID ---\n",
      "['P0001' 'P0002' 'P0003' 'P0004' 'P0005' 'P0006' 'P0007' 'P0008' 'P0009'\n",
      " 'P0010' 'P0011' 'P0012' 'P0013' 'P0014' 'P0015' 'P0016' 'P0017' 'P0018'\n",
      " 'P0019' 'P0020' 'P0021' 'P0022' 'P0023' 'P0024' 'P0025' 'P0026' 'P0027'\n",
      " 'P0028' 'P0029' 'P0030' 'P0031' 'P0032' 'P0033' 'P0034' 'P0035' 'P0036'\n",
      " 'P0037' 'P0038' 'P0039' 'P0040' 'P0041' 'P0042' 'P0043' 'P0044' 'P0045'\n",
      " 'P0046' 'P0047' 'P0048' 'P0049' 'P0050' 'P0051' 'P0052' 'P0053' 'P0054'\n",
      " 'P0055' 'P0056' 'P0057' 'P0058' 'P0059' 'P0060' 'P0061' 'P0062' 'P0063'\n",
      " 'P0064' 'P0065' 'P0066' 'P0067' 'P0068' 'P0069' 'P0070' 'P0071' 'P0072'\n",
      " 'P0073' 'P0074' 'P0075' 'P0076' 'P0077' 'P0078' 'P0079' 'P0080' 'P0081'\n",
      " 'P0082' 'P0083' 'P0084' 'P0085' 'P0086' 'P0087' 'P0088' 'P0089' 'P0090'\n",
      " 'P0091' 'P0092' 'P0093' 'P0094' 'P0095' 'P0096' 'P0097' 'P0098' 'P0099'\n",
      " 'P0100']\n",
      "\n",
      "\n",
      "--- Unique values for: Age ---\n",
      "[18 15 34 52 46 42 51 26 49 89 44 27 45 43 40 41 21 39 37 38 36 65 35 33\n",
      " 61 31 32 19 86 59]\n",
      "\n",
      "\n",
      "--- Unique values for: Sexual Partners ---\n",
      "[4 1 5 3 2 6 9]\n",
      "\n",
      "\n",
      "--- Unique values for: First Sexual Activity Age ---\n",
      "[15 14  9 16 21 23 27 26 20 17 25 18 19 24 57  2 32 13 29 11 22]\n",
      "\n",
      "\n",
      "--- Unique values for: HPV Test Result ---\n",
      "['NEGATIVE' 'POSITIVE' 'NEGAGTIVE' 'POSITIVE\\n']\n",
      "\n",
      "\n",
      "--- Unique values for: Pap Smear Result ---\n",
      "['N' 'Y']\n",
      "\n",
      "\n",
      "--- Unique values for: Smoking Status ---\n",
      "['N' 'Y']\n",
      "\n",
      "\n",
      "--- Unique values for: STDs History ---\n",
      "['Y' 'N']\n",
      "\n",
      "\n",
      "--- Unique values for: Region ---\n",
      "['Pumwani ' 'Kakamega ' 'Machakos' 'Embu ' 'Mombasa' 'NAKURU' 'Loitoktok'\n",
      " 'Moi ' 'Garissa ' 'Kitale' 'Kakamega' 'Mombasa ' 'Garissa' 'Kericho'\n",
      " 'Pumwani' 'Kericho ' 'Machakos ' 'Moi' 'Kitale ']\n",
      "\n",
      "\n",
      "--- Unique values for: Insrance Covered ---\n",
      "['Y' 'N']\n",
      "\n",
      "\n",
      "--- Unique values for: Screening Type Last ---\n",
      "['PAP SMEAR' 'HPV DNA' 'VIA']\n",
      "\n",
      "\n",
      "--- Unique values for: Recommended Action ---\n",
      "['REPEAT PAP SMEAR IN 3 YEARS AND FOR HPV VACCINE'\n",
      " 'FOR HPV VACCINE AND SEXUAL EDUCATION'\n",
      " 'FOR HPV VACCINE, LIFESTYLE AND SEXUAL EDUCATION'\n",
      " 'FOR COLPOSCOPY CYTOLOGY AND BIOPSY' 'REPEAT PAP SMEAR IN 3 YEARS'\n",
      " 'FOR COLPOSCOPY BIOSY, CYTOLOGY+/- TAH'\n",
      " 'FOR BIOPSY AND CYTOLOGY WITH TAH NOT RECOMMENDED '\n",
      " 'REPEAT PAP SMEAR IN 3 YEARS ' 'FOR COLPOSCOPY BIOPSY, CYTOLOGY '\n",
      " 'FOR ANNUAL FOLLOW UP AND PAP SMEAR IN 3 YEARS ' 'FOR PAP SMEAR'\n",
      " 'FOR PAP SMEAR ' 'FOR COLPOSCPY BIOPSY, CYTOLOGY'\n",
      " 'REPEAT PAP SMEAR IN 3YEARS' 'FOR COLPOSCOPY BIOPSY AND CYTOLOGY+/- TAH '\n",
      " 'FOR LASER THERAPY' 'FOR COLPOSCOPY BIOPSY, CYTOLOGY'\n",
      " 'FOR COLPOSCOPY BIOSPY, CYTOLOGY'\n",
      " 'FOR COLPOSCOPY BIOSPY, CYTOLOGY +/- TAH'\n",
      " 'FOR ANUAL FOLLOW UP AND PAP SMEAR IN 3 YEARS'\n",
      " 'FOR COLPOSCOPY BIOPSY, CYTOLOGY +/- TAH'\n",
      " 'FOR HPV VACCINATION AND SEXUAL EDUCATION'\n",
      " 'FOR COLOSCOPY BIOSY, CYTOLOGY'\n",
      " 'FORCOLPOSCOPY, CYTOLOGY THEN LASER THERAPY'\n",
      " 'FOR COLPOSOCPY BIOPSY, CYTOLOGY WITH TAH NOT RECOMMENDED'\n",
      " 'FOR REPEAT HPV TESTING ANNUALLY AND PAP SMEAR IN 3 YEARS'\n",
      " 'FOR COLPOSCOPY BIOPSY, CYTOLOGY +/-TAH']\n",
      "\n",
      "\n",
      "--- Unique values for: Unnamed: 12 ---\n",
      "[nan ' ']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the raw data\n",
    "df = pd.read_csv(\"cervical_cancer.csv\")\n",
    "\n",
    "# Show the first few rows\n",
    "print(df.head())\n",
    "\n",
    "# Show column names and types\n",
    "print(df.info())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values per column:\\n\", df.isnull().sum())\n",
    "\n",
    "# Check for duplicates\n",
    "print(\"Number of duplicate rows:\", df.duplicated().sum())\n",
    "\n",
    "# Show unique values for each column (for categorical inspection)\n",
    "for col in df.columns:\n",
    "    print(f\"--- Unique values for: {col} ---\")\n",
    "    print(df[col].unique())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Value Counts for: Patient ID ---\n",
      "Patient ID\n",
      "P0001    1\n",
      "P0002    1\n",
      "P0003    1\n",
      "P0004    1\n",
      "P0005    1\n",
      "        ..\n",
      "P0096    1\n",
      "P0097    1\n",
      "P0098    1\n",
      "P0099    1\n",
      "P0100    1\n",
      "Name: count, Length: 100, dtype: int64\n",
      "\n",
      "\n",
      "--- Value Counts for: Age ---\n",
      "Age\n",
      "35    14\n",
      "36    10\n",
      "37     9\n",
      "33     8\n",
      "34     7\n",
      "40     6\n",
      "41     5\n",
      "39     4\n",
      "18     4\n",
      "31     3\n",
      "44     3\n",
      "43     3\n",
      "32     3\n",
      "15     2\n",
      "42     2\n",
      "38     2\n",
      "49     2\n",
      "26     1\n",
      "51     1\n",
      "46     1\n",
      "52     1\n",
      "89     1\n",
      "45     1\n",
      "27     1\n",
      "65     1\n",
      "21     1\n",
      "61     1\n",
      "19     1\n",
      "86     1\n",
      "59     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "--- Value Counts for: Sexual Partners ---\n",
      "Sexual Partners\n",
      "3    34\n",
      "2    24\n",
      "1    21\n",
      "5    10\n",
      "4     8\n",
      "6     2\n",
      "9     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "--- Value Counts for: First Sexual Activity Age ---\n",
      "First Sexual Activity Age\n",
      "17    18\n",
      "18    15\n",
      "15    11\n",
      "20    10\n",
      "16     9\n",
      "21     7\n",
      "19     7\n",
      "26     3\n",
      "14     3\n",
      "23     3\n",
      "27     3\n",
      "24     2\n",
      "9      1\n",
      "25     1\n",
      "57     1\n",
      "2      1\n",
      "32     1\n",
      "13     1\n",
      "29     1\n",
      "11     1\n",
      "22     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "--- Value Counts for: HPV Test Result ---\n",
      "HPV Test Result\n",
      "NEGATIVE      47\n",
      "POSITIVE      46\n",
      "POSITIVE\\n     6\n",
      "NEGAGTIVE      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "--- Value Counts for: Pap Smear Result ---\n",
      "Pap Smear Result\n",
      "N    65\n",
      "Y    35\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "--- Value Counts for: Smoking Status ---\n",
      "Smoking Status\n",
      "N    60\n",
      "Y    40\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "--- Value Counts for: STDs History ---\n",
      "STDs History\n",
      "N    52\n",
      "Y    48\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "--- Value Counts for: Region ---\n",
      "Region\n",
      "Embu         14\n",
      "Kericho      11\n",
      "Mombasa      10\n",
      "Kitale        9\n",
      "Loitoktok     9\n",
      "Kakamega      8\n",
      "Machakos      7\n",
      "Mombasa       5\n",
      "Moi           5\n",
      "Pumwani       4\n",
      "Pumwani       3\n",
      "Kitale        3\n",
      "Machakos      2\n",
      "Garissa       2\n",
      "Garissa       2\n",
      "Moi           2\n",
      "Kericho       2\n",
      "Kakamega      1\n",
      "NAKURU        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "--- Value Counts for: Insrance Covered ---\n",
      "Insrance Covered\n",
      "Y    54\n",
      "N    46\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "--- Value Counts for: Screening Type Last ---\n",
      "Screening Type Last\n",
      "PAP SMEAR    39\n",
      "VIA          31\n",
      "HPV DNA      30\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "--- Value Counts for: Recommended Action ---\n",
      "Recommended Action\n",
      "REPEAT PAP SMEAR IN 3 YEARS                                 25\n",
      "FOR COLPOSCOPY BIOPSY, CYTOLOGY                             11\n",
      "FOR PAP SMEAR                                                9\n",
      "FOR HPV VACCINE AND SEXUAL EDUCATION                         7\n",
      "FOR ANUAL FOLLOW UP AND PAP SMEAR IN 3 YEARS                 7\n",
      "FOR ANNUAL FOLLOW UP AND PAP SMEAR IN 3 YEARS                5\n",
      "REPEAT PAP SMEAR IN 3 YEARS                                  5\n",
      "FOR COLPOSCOPY BIOPSY, CYTOLOGY                              5\n",
      "FOR COLPOSCOPY BIOSPY, CYTOLOGY                              4\n",
      "FOR COLOSCOPY BIOSY, CYTOLOGY                                3\n",
      "REPEAT PAP SMEAR IN 3 YEARS AND FOR HPV VACCINE              2\n",
      "FOR HPV VACCINATION AND SEXUAL EDUCATION                     2\n",
      "FOR COLPOSCOPY CYTOLOGY AND BIOPSY                           1\n",
      "FOR BIOPSY AND CYTOLOGY WITH TAH NOT RECOMMENDED             1\n",
      "FOR HPV VACCINE, LIFESTYLE AND SEXUAL EDUCATION              1\n",
      "FOR COLPOSCOPY BIOSY, CYTOLOGY+/- TAH                        1\n",
      "FOR COLPOSCOPY BIOPSY AND CYTOLOGY+/- TAH                    1\n",
      "FOR PAP SMEAR                                                1\n",
      "FOR COLPOSCPY BIOPSY, CYTOLOGY                               1\n",
      "FOR COLPOSCOPY BIOSPY, CYTOLOGY +/- TAH                      1\n",
      "FOR LASER THERAPY                                            1\n",
      "REPEAT PAP SMEAR IN 3YEARS                                   1\n",
      "FOR COLPOSCOPY BIOPSY, CYTOLOGY +/- TAH                      1\n",
      "FORCOLPOSCOPY, CYTOLOGY THEN LASER THERAPY                   1\n",
      "FOR COLPOSOCPY BIOPSY, CYTOLOGY WITH TAH NOT RECOMMENDED     1\n",
      "FOR REPEAT HPV TESTING ANNUALLY AND PAP SMEAR IN 3 YEARS     1\n",
      "FOR COLPOSCOPY BIOPSY, CYTOLOGY +/-TAH                       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "--- Value Counts for: Unnamed: 12 ---\n",
      "Unnamed: 12\n",
      "NaN    99\n",
      "        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "--- Value Counts for: is_duplicate ---\n",
      "is_duplicate\n",
      "False    100\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. verify data quality\n",
    "def print_all_value_counts(df):\n",
    "    for column in df.columns:\n",
    "        print(f\"--- Value Counts for: {column} ---\")\n",
    "        print(df[column].value_counts(dropna=False))  # include NaNs in the count\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Print unique values to check validity & quality:\n",
    "print_all_value_counts(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TihNzEzkNc8h"
   },
   "source": [
    "We see that there are some Discrepancies in the data like:\n",
    "## Column: HPV Test Result\n",
    "Discrepancies Identified:\n",
    "\n",
    "* \"POSITIVE\\n\" — Extra newline character\n",
    "* \"NEGAGTIVE\" — Misspelling of \"NEGATIVE\"\n",
    "\n",
    "## Column: Region\n",
    "Discrepancies Identified:\n",
    "\n",
    "* Duplicate entries with inconsistent casing (e.g., \"Mombasa\" vs \"MOMBASA\")\n",
    "* Some locations appear more than once due to typos or casing (e.g., \"Kitale\" listed twice, \"Pumwani\" twice, etc.)\n",
    "\n",
    "## Column: Recommended Action\n",
    "Discrepancies Identified:\n",
    "\n",
    "Same action written with:\n",
    "* Typos: \"BIOSPY\", \"COLOSCOPY\", \"ANUAL\" instead of \"ANNUAL\" etc\n",
    "\n",
    "\n",
    "Inconsistent casing and spacing:\n",
    "\n",
    "* \"REPEAT PAP SMEAR IN 3 YEARS\" appears three times with slight differences:\n",
    "* \"REPEAT PAP SMEAR IN 3 YEARS\" – 25 times\n",
    "* \"REPEAT PAP SMEAR IN 3 YEARS \" – 5 times (extra space at the end)\n",
    "* \"REPEAT PAP SMEAR IN 3YEARS\" – 1 time (missing space between 3 and YEARS)\n",
    "\n",
    "Misspellings:\n",
    "\n",
    "* \"FOR COLPOSCOPY BIOSPY, CYTOLOGY\" vs \"FOR COLPOSCOPY BIOPSY, CYTOLOGY\" (typo: BIOSPY)\n",
    "* \"FOR COLOSCOPY BIOSY, CYTOLOGY\" (both COLOSCOPY and BIOSY are misspelled)\n",
    "\n",
    "Slight wording variations:\n",
    "\n",
    "* \"FOR COLPOSCOPY BIOSY, CYTOLOGY+/- TAH\" vs \"FOR COLPOSCOPY BIOPSY, CYTOLOGY +/- TAH\"\n",
    "\n",
    "Concatenated words:\n",
    "\n",
    "* \"FORCOLPOSCOPY, CYTOLOGY THEN LASER THERAPY\" (missing space after FOR)\n",
    "\n",
    "## Column: Unnamed: 12\n",
    "Discrepancies Identified:\n",
    "\n",
    "* Almost entirely empty (99 NaNs out of 100)\n",
    "\n",
    "## Column: Insrance Covered\n",
    "Discrepancies Identified:\n",
    "\n",
    "* Misspelled column name \"Insrance\" should be \"Insurance\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "car15kHwLxB9"
   },
   "source": [
    "## Scikit Learn data cleaning pipeline: \n",
    "\n",
    "\n",
    "*   Use ScikitLearn to create a data cleaning pipeline \n",
    "*   Define some classes for the pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "HWTYnLoOLnvP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw data...\n",
      "Original dataset shape: (100, 13)\n",
      "\n",
      "==================================================\n",
      "BEFORE CLEANING - Data Quality Issues:\n",
      "==================================================\n",
      "1. Column names:\n",
      "['Patient ID', 'Age', 'Sexual Partners', 'First Sexual Activity Age', 'HPV Test Result', 'Pap Smear Result', 'Smoking Status', 'STDs History', 'Region', 'Insrance Covered', 'Screening Type Last', 'Recommended Action', 'Unnamed: 12']\n",
      "\n",
      "2. Sample of problematic data:\n",
      "HPV Test Result unique values: ['NEGATIVE' 'POSITIVE' 'NEGAGTIVE' 'POSITIVE\\n']\n",
      "Region unique values: ['Pumwani ' 'Kakamega ' 'Machakos' 'Embu ' 'Mombasa' 'NAKURU' 'Loitoktok'\n",
      " 'Moi ' 'Garissa ' 'Kitale' 'Kakamega' 'Mombasa ' 'Garissa' 'Kericho'\n",
      " 'Pumwani' 'Kericho ' 'Machakos ' 'Moi' 'Kitale ']\n",
      "Recommended Action samples:\n",
      "  - 'REPEAT PAP SMEAR IN 3 YEARS AND FOR HPV VACCINE'\n",
      "  - 'FOR HPV VACCINE AND SEXUAL EDUCATION'\n",
      "  - 'FOR HPV VACCINE, LIFESTYLE AND SEXUAL EDUCATION'\n",
      "  - 'FOR COLPOSCOPY CYTOLOGY AND BIOPSY'\n",
      "  - 'REPEAT PAP SMEAR IN 3 YEARS'\n",
      "\n",
      "3. Missing values:\n",
      "Patient ID                    0\n",
      "Age                           0\n",
      "Sexual Partners               0\n",
      "First Sexual Activity Age     0\n",
      "HPV Test Result               0\n",
      "Pap Smear Result              0\n",
      "Smoking Status                0\n",
      "STDs History                  0\n",
      "Region                        0\n",
      "Insrance Covered              0\n",
      "Screening Type Last           0\n",
      "Recommended Action            0\n",
      "Unnamed: 12                  99\n",
      "dtype: int64\n",
      "\n",
      "==================================================\n",
      "APPLYING CLEANING TRANSFORMATIONS:\n",
      "==================================================\n",
      "1. Removing unnecessary columns...\n",
      "   Dropped column: Unnamed: 12\n",
      "\n",
      "2. Fixing column name typos...\n",
      "   Renamed 'Insrance Covered' to 'Insurance Covered'\n",
      "\n",
      "3. Cleaning HPV Test Result...\n",
      "   Before: ['NEGATIVE' 'POSITIVE' 'NEGAGTIVE' 'POSITIVE\\n']\n",
      "   After: ['NEGATIVE' 'POSITIVE']\n",
      "\n",
      "4. Cleaning and standardizing Region names...\n",
      "   Before: ['Embu ', 'Garissa', 'Garissa ', 'Kakamega', 'Kakamega ', 'Kericho', 'Kericho ', 'Kitale', 'Kitale ', 'Loitoktok', 'Machakos', 'Machakos ', 'Moi', 'Moi ', 'Mombasa', 'Mombasa ', 'NAKURU', 'Pumwani', 'Pumwani ']\n",
      "   After: ['Embu', 'Garissa', 'Kakamega', 'Kericho', 'Kitale', 'Loitoktok', 'Machakos', 'Moi', 'Mombasa', 'Nakuru', 'Pumwani']\n",
      "\n",
      "5. Cleaning Recommended Action...\n",
      "   Sample before cleaning:\n",
      "   1. 'REPEAT PAP SMEAR IN 3 YEARS AND FOR HPV VACCINE'\n",
      "   2. 'FOR HPV VACCINE AND SEXUAL EDUCATION'\n",
      "   3. 'FOR HPV VACCINE, LIFESTYLE AND SEXUAL EDUCATION'\n",
      "   4. 'FOR COLPOSCOPY CYTOLOGY AND BIOPSY'\n",
      "   5. 'REPEAT PAP SMEAR IN 3 YEARS'\n",
      "   Sample after cleaning:\n",
      "   1. 'REPEAT PAP SMEAR IN 3 YEARS AND HPV VACCINE'\n",
      "   2. 'FOR HPV VACCINE AND SEXUAL EDUCATION'\n",
      "   3. 'FOR HPV VACCINE, LIFESTYLE AND SEXUAL EDUCATION'\n",
      "   4. 'FOR COLPOSCOPY BIOPSY, CYTOLOGY'\n",
      "   5. 'REPEAT PAP SMEAR IN 3 YEARS'\n",
      "\n",
      "6. Cleaning binary columns...\n",
      "   Cleaning Pap Smear Result\n",
      "      Before: ['N' 'Y']\n",
      "      After: ['N' 'Y']\n",
      "   Cleaning Smoking Status\n",
      "      Before: ['N' 'Y']\n",
      "      After: ['N' 'Y']\n",
      "   Cleaning STDs History\n",
      "      Before: ['Y' 'N']\n",
      "      After: ['Y' 'N']\n",
      "   Cleaning Insurance Covered\n",
      "      Before: ['Y' 'N']\n",
      "      After: ['Y' 'N']\n",
      "\n",
      "7. Cleaning Screening Type Last...\n",
      "   Before: ['PAP SMEAR' 'HPV DNA' 'VIA']\n",
      "   After: ['PAP SMEAR' 'HPV DNA' 'VIA']\n",
      "\n",
      "8. Handling age anomalies...\n",
      "   Age range before: 15 - 89\n",
      "   Age range after: 15 - 89\n",
      "\n",
      "9. Handling First Sexual Activity Age anomalies...\n",
      "   First Sexual Activity Age range before: 2 - 57\n",
      "   Found 2 records where first sexual activity age > current age\n",
      "\n",
      "10. Handling Sexual Partners...\n",
      "   Sexual Partners range before cleanup: 1 - 9\n",
      "   Dropped 0 rows with missing or invalid 'Sexual Partners' values.\n",
      "\n",
      "11. Final cleanup...\n",
      "\n",
      "==================================================\n",
      "CLEANING COMPLETE - SUMMARY:\n",
      "==================================================\n",
      "Original shape: (100, 13)\n",
      "Cleaned shape: (98, 12)\n",
      "Columns after cleaning: ['Patient ID', 'Age', 'Sexual Partners', 'First Sexual Activity Age', 'HPV Test Result', 'Pap Smear Result', 'Smoking Status', 'STDs History', 'Region', 'Insurance Covered', 'Screening Type Last', 'Recommended Action']\n",
      "\n",
      "Cleaned data quality:\n",
      "1. HPV Test Result values: ['NEGATIVE' 'POSITIVE']\n",
      "2. Regions: ['Embu', 'Garissa', 'Kakamega', 'Kericho', 'Kitale', 'Loitoktok', 'Machakos', 'Moi', 'Mombasa', 'Nakuru', 'Pumwani']\n",
      "3. Missing values after cleaning:\n",
      "Patient ID                   0\n",
      "Age                          0\n",
      "Sexual Partners              0\n",
      "First Sexual Activity Age    0\n",
      "HPV Test Result              0\n",
      "Pap Smear Result             0\n",
      "Smoking Status               0\n",
      "STDs History                 0\n",
      "Region                       0\n",
      "Insurance Covered            0\n",
      "Screening Type Last          0\n",
      "Recommended Action           0\n",
      "dtype: int64\n",
      "\n",
      "Cleaned data saved as 'cervical_cancer_cleaned.csv'\n",
      "\n",
      "First 5 rows of cleaned data:\n",
      "  Patient ID  Age  Sexual Partners  First Sexual Activity Age HPV Test Result  \\\n",
      "0      P0001   18                4                         15        NEGATIVE   \n",
      "1      P0002   15                1                         14        POSITIVE   \n",
      "2      P0003   34                1                          9        POSITIVE   \n",
      "3      P0004   52                5                         16        POSITIVE   \n",
      "4      P0005   46                3                         21        POSITIVE   \n",
      "\n",
      "  Pap Smear Result Smoking Status STDs History    Region Insurance Covered  \\\n",
      "0                N              N            Y   Pumwani                 Y   \n",
      "1                N              Y            Y  Kakamega                 N   \n",
      "2                N              N            Y  Machakos                 N   \n",
      "3                N              Y            N      Embu                 Y   \n",
      "4                N              N            N   Mombasa                 N   \n",
      "\n",
      "  Screening Type Last                               Recommended Action  \n",
      "0           PAP SMEAR      REPEAT PAP SMEAR IN 3 YEARS AND HPV VACCINE  \n",
      "1             HPV DNA             FOR HPV VACCINE AND SEXUAL EDUCATION  \n",
      "2             HPV DNA             FOR HPV VACCINE AND SEXUAL EDUCATION  \n",
      "3             HPV DNA  FOR HPV VACCINE, LIFESTYLE AND SEXUAL EDUCATION  \n",
      "4             HPV DNA             FOR HPV VACCINE AND SEXUAL EDUCATION  \n",
      "\n",
      "==================================================\n",
      "VERIFICATION OF CLEANED DATA:\n",
      "==================================================\n",
      "\n",
      "HPV Test Result:\n",
      "  Values: ['NEGATIVE' 'POSITIVE']\n",
      "\n",
      "Region:\n",
      "  Total unique values: 11\n",
      "  Sample: ['Pumwani' 'Kakamega' 'Machakos' 'Embu' 'Mombasa' 'Nakuru' 'Loitoktok'\n",
      " 'Moi' 'Garissa' 'Kitale']\n",
      "\n",
      "Pap Smear Result:\n",
      "  Values: ['N' 'Y']\n",
      "\n",
      "Smoking Status:\n",
      "  Values: ['N' 'Y']\n",
      "\n",
      "STDs History:\n",
      "  Values: ['Y' 'N']\n",
      "\n",
      "Insurance Covered:\n",
      "  Values: ['Y' 'N']\n",
      "\n",
      "Screening Type Last:\n",
      "  Values: ['PAP SMEAR' 'HPV DNA' 'VIA']\n",
      "--- Value Counts for: Patient ID ---\n",
      "Patient ID\n",
      "P0001    1\n",
      "P0002    1\n",
      "P0003    1\n",
      "P0004    1\n",
      "P0005    1\n",
      "        ..\n",
      "P0096    1\n",
      "P0097    1\n",
      "P0098    1\n",
      "P0099    1\n",
      "P0100    1\n",
      "Name: count, Length: 98, dtype: int64\n",
      "\n",
      "\n",
      "--- Value Counts for: Age ---\n",
      "Age\n",
      "35    13\n",
      "36    10\n",
      "37     9\n",
      "33     8\n",
      "34     7\n",
      "40     6\n",
      "41     5\n",
      "39     4\n",
      "18     4\n",
      "31     3\n",
      "44     3\n",
      "43     3\n",
      "32     3\n",
      "42     2\n",
      "49     2\n",
      "38     2\n",
      "26     1\n",
      "89     1\n",
      "51     1\n",
      "15     1\n",
      "52     1\n",
      "46     1\n",
      "45     1\n",
      "27     1\n",
      "65     1\n",
      "21     1\n",
      "61     1\n",
      "19     1\n",
      "86     1\n",
      "59     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "--- Value Counts for: Sexual Partners ---\n",
      "Sexual Partners\n",
      "3    34\n",
      "2    23\n",
      "1    20\n",
      "5    10\n",
      "4     8\n",
      "6     2\n",
      "9     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "--- Value Counts for: First Sexual Activity Age ---\n",
      "First Sexual Activity Age\n",
      "17    18\n",
      "18    15\n",
      "15    11\n",
      "16     9\n",
      "20     9\n",
      "21     7\n",
      "19     7\n",
      "14     3\n",
      "23     3\n",
      "26     3\n",
      "27     3\n",
      "24     2\n",
      "9      1\n",
      "25     1\n",
      "2      1\n",
      "32     1\n",
      "13     1\n",
      "29     1\n",
      "11     1\n",
      "22     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "--- Value Counts for: HPV Test Result ---\n",
      "HPV Test Result\n",
      "POSITIVE    51\n",
      "NEGATIVE    47\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "--- Value Counts for: Pap Smear Result ---\n",
      "Pap Smear Result\n",
      "N    64\n",
      "Y    34\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "--- Value Counts for: Smoking Status ---\n",
      "Smoking Status\n",
      "N    60\n",
      "Y    38\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "--- Value Counts for: STDs History ---\n",
      "STDs History\n",
      "N    50\n",
      "Y    48\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "--- Value Counts for: Region ---\n",
      "Region\n",
      "Mombasa      15\n",
      "Embu         14\n",
      "Kericho      13\n",
      "Kitale       12\n",
      "Kakamega      9\n",
      "Machakos      9\n",
      "Pumwani       7\n",
      "Moi           7\n",
      "Loitoktok     7\n",
      "Garissa       4\n",
      "Nakuru        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "--- Value Counts for: Insurance Covered ---\n",
      "Insurance Covered\n",
      "Y    52\n",
      "N    46\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "--- Value Counts for: Screening Type Last ---\n",
      "Screening Type Last\n",
      "PAP SMEAR    37\n",
      "VIA          31\n",
      "HPV DNA      30\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "--- Value Counts for: Recommended Action ---\n",
      "Recommended Action\n",
      "REPEAT PAP SMEAR IN 3 YEARS                                 30\n",
      "FOR COLPOSCOPY BIOPSY, CYTOLOGY                             29\n",
      "FOR ANNUAL FOLLOW UP AND PAP SMEAR IN 3 YEARS               11\n",
      "FOR PAP SMEAR                                               10\n",
      "FOR HPV VACCINE AND SEXUAL EDUCATION                         9\n",
      "REPEAT PAP SMEAR IN 3 YEARS AND HPV VACCINE                  2\n",
      "FOR BIOPSY AND CYTOLOGY WITH TAH NOT RECOMMENDED             2\n",
      "FOR HPV VACCINE, LIFESTYLE AND SEXUAL EDUCATION              1\n",
      "REPEAT PAP SMEAR IN 3YEARS                                   1\n",
      "FOR LASER THERAPY                                            1\n",
      "FOR COLPOSCOPY, CYTOLOGY THEN LASER THERAPY                  1\n",
      "FOR REPEAT HPV TESTING ANNUALLY AND PAP SMEAR IN 3 YEARS     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "\n",
      "✅ Data cleaning completed successfully!\n",
      "✅ Ready for next step: Exploratory Data Analysis\n"
     ]
    }
   ],
   "source": [
    "# 5.Comprehensive Data Cleaning for Cervical Cancer Dataset and confirm the quality\n",
    "# Step 1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the raw data\n",
    "print(\"Loading raw data...\")\n",
    "df = pd.read_csv('cervical_cancer.csv')\n",
    "print(f\"Original dataset shape: {df.shape}\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"BEFORE CLEANING - Data Quality Issues:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Show original data quality issues\n",
    "print(\"1. Column names:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "print(\"\\n2. Sample of problematic data:\")\n",
    "print(\"HPV Test Result unique values:\", df['HPV Test Result'].unique())\n",
    "print(\"Region unique values:\", df['Region'].unique())\n",
    "print(\"Recommended Action samples:\")\n",
    "for action in df['Recommended Action'].unique()[:5]:\n",
    "    print(f\"  - '{action}'\")\n",
    "\n",
    "print(\"\\n3. Missing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Create a copy for cleaning\n",
    "clean_df = df.copy()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"APPLYING CLEANING TRANSFORMATIONS:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 1. Remove unnecessary columns\n",
    "print(\"1. Removing unnecessary columns...\")\n",
    "columns_to_drop = ['Unnamed: 12']\n",
    "for col in columns_to_drop:\n",
    "    if col in clean_df.columns:\n",
    "        clean_df.drop(columns=[col], inplace=True)\n",
    "        print(f\"   Dropped column: {col}\")\n",
    "\n",
    "# 2. Fix column name typos\n",
    "print(\"\\n2. Fixing column name typos...\")\n",
    "column_renames = {\n",
    "    'Insrance Covered': 'Insurance Covered'\n",
    "}\n",
    "clean_df.rename(columns=column_renames, inplace=True)\n",
    "for old, new in column_renames.items():\n",
    "    print(f\"   Renamed '{old}' to '{new}'\")\n",
    "\n",
    "# 3. Clean HPV Test Result\n",
    "print(\"\\n3. Cleaning HPV Test Result...\")\n",
    "print(f\"   Before: {clean_df['HPV Test Result'].unique()}\")\n",
    "\n",
    "clean_df['HPV Test Result'] = clean_df['HPV Test Result'].astype(str).str.upper().str.strip()\n",
    "\n",
    "# Fix the problematic characters - using raw strings to avoid escape issues\n",
    "hpv_replacements = {\n",
    "    'NEGAGTIVE': 'NEGATIVE',\n",
    "    'POSTIVE': 'POSITIVE',\n",
    "    'NEGATVIE': 'NEGATIVE',\n",
    "    'NEGATVE': 'NEGATIVE',\n",
    "    'NEGATIVE\\n':'NEGATIVE',\n",
    "    'NEGATIVE ':'NEGATIVE',\n",
    "    ' NEGATIVE ':'NEGATIVE',\n",
    "    ' POSITIVE ':'POSITIVE',\n",
    "    'POSITIVE\\n':'POSITIVE'\n",
    "}\n",
    "\n",
    "# Handle newline characters separately\n",
    "clean_df['HPV Test Result'] = clean_df['HPV Test Result'].str.replace('\\n', '', regex=False)\n",
    "clean_df['HPV Test Result'] = clean_df['HPV Test Result'].str.replace('\\\\n', '', regex=False)\n",
    "\n",
    "# Apply other replacements\n",
    "clean_df['HPV Test Result'] = clean_df['HPV Test Result'].replace(hpv_replacements)\n",
    "\n",
    "print(f\"   After: {clean_df['HPV Test Result'].unique()}\")\n",
    "\n",
    "# 4. Clean and standardize Region names\n",
    "print(\"\\n4. Cleaning and standardizing Region names...\")\n",
    "print(f\"   Before: {sorted(clean_df['Region'].unique())}\")\n",
    "\n",
    "# First, strip whitespace and normalize case\n",
    "clean_df['Region'] = clean_df['Region'].astype(str).str.strip()\n",
    "\n",
    "# Create comprehensive region mapping to handle all variations\n",
    "region_mapping = {\n",
    "    # Mombasa variations\n",
    "    'mombasa': 'Mombasa',\n",
    "    'MOMBASA': 'Mombasa',\n",
    "    'Mombasa': 'Mombasa',\n",
    "    'mombasa ': 'Mombasa',\n",
    "    'Mombasa ': 'Mombasa',\n",
    "    'MOMBASA ': 'Mombasa',\n",
    "    \n",
    "    # Pumwani variations\n",
    "    'pumwani': 'Pumwani',\n",
    "    'PUMWANI': 'Pumwani',\n",
    "    'Pumwani': 'Pumwani',\n",
    "    'pumwani ': 'Pumwani',\n",
    "    'Pumwani ': 'Pumwani',\n",
    "    'PUMWANI ': 'Pumwani',\n",
    "    \n",
    "    # Embu variations\n",
    "    'embu': 'Embu',\n",
    "    'EMBU': 'Embu',\n",
    "    'Embu': 'Embu',\n",
    "    'embu ': 'Embu',\n",
    "    'Embu ': 'Embu',\n",
    "    'EMBU ': 'Embu',\n",
    "    \n",
    "    # Kakamega variations\n",
    "    'kakamega': 'Kakamega',\n",
    "    'KAKAMEGA': 'Kakamega',\n",
    "    'Kakamega': 'Kakamega',\n",
    "    'kakamega ': 'Kakamega',\n",
    "    'Kakamega ': 'Kakamega',\n",
    "    'KAKAMEGA ': 'Kakamega',\n",
    "    \n",
    "    # Machakos variations\n",
    "    'machakos': 'Machakos',\n",
    "    'MACHAKOS': 'Machakos',\n",
    "    'Machakos': 'Machakos',\n",
    "    'machakos ': 'Machakos',\n",
    "    'Machakos ': 'Machakos',\n",
    "    'MACHAKOS ': 'Machakos',\n",
    "    \n",
    "    # Nakuru variations\n",
    "    'nakuru': 'Nakuru',\n",
    "    'NAKURU': 'Nakuru',\n",
    "    'Nakuru': 'Nakuru',\n",
    "    'NAKURU ': 'Nakuru',\n",
    "    \n",
    "    # Moi variations\n",
    "    'moi': 'Moi',\n",
    "    'MOI': 'Moi',\n",
    "    'Moi': 'Moi',\n",
    "    'moi ': 'Moi',\n",
    "    'Moi ': 'Moi',\n",
    "    'MOI ': 'Moi',\n",
    "    \n",
    "    # Loitoktok variations\n",
    "    'loitoktok': 'Loitoktok',\n",
    "    'LOITOKTOK': 'Loitoktok',\n",
    "    'Loitoktok': 'Loitoktok',\n",
    "    'loitoktok ': 'Loitoktok',\n",
    "    'Loitoktok ': 'Loitoktok',\n",
    "    'LOITOKTOK ': 'Loitoktok',\n",
    "    \n",
    "    # Garissa variations\n",
    "    'garissa': 'Garissa',\n",
    "    'GARISSA': 'Garissa',\n",
    "    'Garissa': 'Garissa',\n",
    "    'garissa ': 'Garissa',\n",
    "    'Garissa ': 'Garissa',\n",
    "    'GARISSA ': 'Garissa',\n",
    "    \n",
    "    # Kericho variations\n",
    "    'kericho': 'Kericho',\n",
    "    'KERICHO': 'Kericho',\n",
    "    'Kericho': 'Kericho',\n",
    "    'kericho ': 'Kericho',\n",
    "    'Kericho ': 'Kericho',\n",
    "    'KERICHO ': 'Kericho',\n",
    "    \n",
    "    # Kitale variations\n",
    "    'kitale': 'Kitale',\n",
    "    'KITALE': 'Kitale',\n",
    "    'Kitale': 'Kitale',\n",
    "    'kitale ': 'Kitale',\n",
    "    'Kitale ': 'Kitale',\n",
    "    'KITALE ': 'Kitale'\n",
    "}\n",
    "\n",
    "# Apply region mapping\n",
    "clean_df['Region'] = clean_df['Region'].replace(region_mapping)\n",
    "\n",
    "print(f\"   After: {sorted(clean_df['Region'].unique())}\")\n",
    "\n",
    "# 5. Comprehensive cleaning of Recommended Action\n",
    "# 5. Clean and consolidate Recommended Action\n",
    "print(\"\\n5. Cleaning Recommended Action...\")\n",
    "print(\"   Sample before cleaning:\")\n",
    "for i, action in enumerate(clean_df['Recommended Action'].unique()[:5]):\n",
    "    print(f\"   {i+1}. '{action}'\")\n",
    "\n",
    "# Convert to uppercase and strip whitespaces\n",
    "clean_df['Recommended Action'] = clean_df['Recommended Action'].astype(str).str.upper().str.strip()\n",
    "\n",
    "# Fix common typos and spacing issues\n",
    "clean_df['Recommended Action'] = clean_df['Recommended Action'].str.replace('BIOSPY', 'BIOPSY', regex=False)\n",
    "clean_df['Recommended Action'] = clean_df['Recommended Action'].str.replace('BIOSY', 'BIOPSY', regex=False)\n",
    "clean_df['Recommended Action'] = clean_df['Recommended Action'].str.replace('COLOSCOPY', 'COLPOSCOPY', regex=False)\n",
    "clean_df['Recommended Action'] = clean_df['Recommended Action'].str.replace('COLPOSCPY', 'COLPOSCOPY', regex=False)\n",
    "clean_df['Recommended Action'] = clean_df['Recommended Action'].str.replace('ANUAL', 'ANNUAL', regex=False)\n",
    "clean_df['Recommended Action'] = clean_df['Recommended Action'].str.replace('ANUALLY', 'ANNUALLY', regex=False)\n",
    "clean_df['Recommended Action'] = clean_df['Recommended Action'].str.replace('YEARSAND', 'YEARS AND', regex=False)\n",
    "clean_df['Recommended Action'] = clean_df['Recommended Action'].str.replace('\\\\+', 'AND', regex=True)\n",
    "clean_df['Recommended Action'] = clean_df['Recommended Action'].str.replace(' +/- ', ' +/- ', regex=False)\n",
    "clean_df['Recommended Action'] = clean_df['Recommended Action'].str.replace('+/-', '+/-', regex=False)\n",
    "\n",
    "# Group similar or redundant phrases under standard labels\n",
    "def standardize_action(action):\n",
    "    if \"REPEAT PAP SMEAR IN 3 YEARS\" in action and \"HPV VACCINE\" in action:\n",
    "        return \"REPEAT PAP SMEAR IN 3 YEARS AND HPV VACCINE\"\n",
    "    elif \"REPEAT PAP SMEAR IN 3 YEARS\" in action:\n",
    "        return \"REPEAT PAP SMEAR IN 3 YEARS\"\n",
    "    elif \"FOR ANNUAL FOLLOW UP\" in action:\n",
    "        return \"FOR ANNUAL FOLLOW UP AND PAP SMEAR IN 3 YEARS\"\n",
    "    elif \"HPV VACCINE\" in action and \"SEXUAL EDUCATION\" in action and \"LIFESTYLE\" in action:\n",
    "        return \"FOR HPV VACCINE, LIFESTYLE AND SEXUAL EDUCATION\"\n",
    "    elif \"HPV VACCINE\" in action and \"SEXUAL EDUCATION\" in action:\n",
    "        return \"FOR HPV VACCINE AND SEXUAL EDUCATION\"\n",
    "    elif \"HPV VACCINATION\" in action and \"SEXUAL EDUCATION\" in action:\n",
    "        return \"FOR HPV VACCINE AND SEXUAL EDUCATION\"\n",
    "    elif \"FOR HPV VACCINE\" in action:\n",
    "        return \"FOR HPV VACCINE\"\n",
    "    elif \"COLPOSCOPY\" in action and \"BIOPSY\" in action and \"CYTOLOGY\" in action and \"TAH NOT RECOMMENDED\" in action:\n",
    "        return \"FOR COLPOSCOPY BIOPSY, CYTOLOGY WITH TAH NOT RECOMMENDED\"\n",
    "    elif \"COLPOSCOPY\" in action and \"BIOPSY\" in action and \"CYTOLOGY\" in action and \"+/- TAH\" in action:\n",
    "        return \"FOR COLPOSCOPY BIOPSY, CYTOLOGY +/- TAH\"\n",
    "    elif \"COLPOSCOPY\" in action and \"BIOPSY\" in action and \"CYTOLOGY\" in action:\n",
    "        return \"FOR COLPOSCOPY BIOPSY, CYTOLOGY\"\n",
    "    elif \"COLPOSCOPY\" in action and \"CYTOLOGY\" in action and \"LASER THERAPY\" in action:\n",
    "        return \"FOR COLPOSCOPY, CYTOLOGY THEN LASER THERAPY\"\n",
    "    elif \"BIOPSY\" in action and \"CYTOLOGY\" in action and \"TAH NOT RECOMMENDED\" in action:\n",
    "        return \"FOR BIOPSY AND CYTOLOGY WITH TAH NOT RECOMMENDED\"\n",
    "    elif \"LASER THERAPY\" in action:\n",
    "        return \"FOR LASER THERAPY\"\n",
    "    elif \"FOR PAP SMEAR\" in action:\n",
    "        return \"FOR PAP SMEAR\"\n",
    "    elif \"REPEAT HPV TESTING\" in action:\n",
    "        return \"FOR REPEAT HPV TESTING ANNUALLY AND PAP SMEAR IN 3 YEARS\"\n",
    "    else:\n",
    "        return action  # fallback to existing cleaned string\n",
    "\n",
    "# Apply the function\n",
    "clean_df['Recommended Action'] = clean_df['Recommended Action'].apply(standardize_action)\n",
    "\n",
    "print(\"   Sample after cleaning:\")\n",
    "for i, action in enumerate(clean_df['Recommended Action'].unique()[:5]):\n",
    "    print(f\"   {i+1}. '{action}'\")\n",
    "\n",
    "\n",
    "# 6. Clean binary columns (Y/N values)\n",
    "print(\"\\n6. Cleaning binary columns...\")\n",
    "binary_columns = ['Pap Smear Result', 'Smoking Status', 'STDs History', 'Insurance Covered']\n",
    "for col in binary_columns:\n",
    "    if col in clean_df.columns:\n",
    "        print(f\"   Cleaning {col}\")\n",
    "        print(f\"      Before: {clean_df[col].unique()}\")\n",
    "        clean_df[col] = clean_df[col].astype(str).str.upper().str.strip()\n",
    "        print(f\"      After: {clean_df[col].unique()}\")\n",
    "\n",
    "# 7. Clean screening type\n",
    "print(\"\\n7. Cleaning Screening Type Last...\")\n",
    "if 'Screening Type Last' in clean_df.columns:\n",
    "    print(f\"   Before: {clean_df['Screening Type Last'].unique()}\")\n",
    "    clean_df['Screening Type Last'] = clean_df['Screening Type Last'].astype(str).str.upper().str.strip()\n",
    "    print(f\"   After: {clean_df['Screening Type Last'].unique()}\")\n",
    "\n",
    "# 8. Handle age anomalies\n",
    "print(\"\\n8. Handling age anomalies...\")\n",
    "print(f\"   Age range before: {clean_df['Age'].min()} - {clean_df['Age'].max()}\")\n",
    "clean_df['Age'] = pd.to_numeric(clean_df['Age'], errors='coerce')\n",
    "# Check for unrealistic ages\n",
    "unrealistic_ages = clean_df[(clean_df['Age'] < 10) | (clean_df['Age'] > 100)]\n",
    "if len(unrealistic_ages) > 0:\n",
    "    print(f\"   Found {len(unrealistic_ages)} unrealistic ages\")\n",
    "clean_df['Age'] = clean_df['Age'].clip(lower=10, upper=100)\n",
    "print(f\"   Age range after: {clean_df['Age'].min()} - {clean_df['Age'].max()}\")\n",
    "\n",
    "# 9. Handle First Sexual Activity Age anomalies\n",
    "print(\"\\n9. Handling First Sexual Activity Age anomalies...\")\n",
    "print(f\"   First Sexual Activity Age range before: {clean_df['First Sexual Activity Age'].min()} - {clean_df['First Sexual Activity Age'].max()}\")\n",
    "clean_df['First Sexual Activity Age'] = pd.to_numeric(clean_df['First Sexual Activity Age'], errors='coerce')\n",
    "\n",
    "# Check for impossible values (first sexual activity age > current age)\n",
    "# Identify invalid rows\n",
    "impossible_ages = clean_df['First Sexual Activity Age'] > clean_df['Age']\n",
    "\n",
    "# Print how many invalid records were found\n",
    "if impossible_ages.any():\n",
    "    print(f\"   Found {impossible_ages.sum()} records where first sexual activity age > current age\")\n",
    "\n",
    "    # Drop those rows from the DataFrame\n",
    "    clean_df = clean_df[~impossible_ages]\n",
    "\n",
    "print(\"\\n10. Handling Sexual Partners...\")\n",
    "\n",
    "# Convert to numeric, non-numeric values become NaN\n",
    "clean_df['Sexual Partners'] = pd.to_numeric(clean_df['Sexual Partners'], errors='coerce')\n",
    "\n",
    "# Show range before dropping\n",
    "print(f\"   Sexual Partners range before cleanup: {clean_df['Sexual Partners'].min()} - {clean_df['Sexual Partners'].max()}\")\n",
    "\n",
    "# Drop rows where 'Sexual Partners' is NaN\n",
    "initial_count = len(clean_df)\n",
    "clean_df = clean_df.dropna(subset=['Sexual Partners'])\n",
    "dropped_count = initial_count - len(clean_df)\n",
    "\n",
    "print(f\"   Dropped {dropped_count} rows with missing or invalid 'Sexual Partners' values.\")\n",
    "\n",
    "# 11. Final cleanup - strip all string columns\n",
    "print(\"\\n11. Final cleanup...\")\n",
    "for col in clean_df.select_dtypes(include='object').columns:\n",
    "    clean_df[col] = clean_df[col].astype(str).str.strip()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"CLEANING COMPLETE - SUMMARY:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Original shape: {df.shape}\")\n",
    "print(f\"Cleaned shape: {clean_df.shape}\")\n",
    "print(f\"Columns after cleaning: {clean_df.columns.tolist()}\")\n",
    "\n",
    "# Show cleaned data quality\n",
    "print(\"\\nCleaned data quality:\")\n",
    "print(\"1. HPV Test Result values:\", clean_df['HPV Test Result'].unique())\n",
    "print(\"2. Regions:\", sorted(clean_df['Region'].unique()))\n",
    "print(\"3. Missing values after cleaning:\")\n",
    "print(clean_df.isnull().sum())\n",
    "\n",
    "# Save cleaned data\n",
    "clean_df.to_csv('cervical_cancer_cleaned.csv', index=False)\n",
    "print(\"\\nCleaned data saved as 'cervical_cancer_cleaned.csv'\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nFirst 5 rows of cleaned data:\")\n",
    "print(clean_df.head())\n",
    "\n",
    "# Show unique values for key columns to verify cleaning\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"VERIFICATION OF CLEANED DATA:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "def show_unique_values(df, columns):\n",
    "    for col in columns:\n",
    "        if col in df.columns:\n",
    "            print(f\"\\n{col}:\")\n",
    "            unique_vals = df[col].unique()\n",
    "            if len(unique_vals) <= 10:\n",
    "                print(f\"  Values: {unique_vals}\")\n",
    "            else:\n",
    "                print(f\"  Total unique values: {len(unique_vals)}\")\n",
    "                print(f\"  Sample: {unique_vals[:10]}\")\n",
    "\n",
    "verification_columns = ['HPV Test Result', 'Region', 'Pap Smear Result', 'Smoking Status', \n",
    "                       'STDs History', 'Insurance Covered', 'Screening Type Last']\n",
    "show_unique_values(clean_df, verification_columns)\n",
    "\n",
    "\n",
    "#Preview results\n",
    "def print_all_value_counts(df):\n",
    "    for column in df.columns:\n",
    "        print(f\"--- Value Counts for: {column} ---\")\n",
    "        print(df[column].value_counts(dropna=False))  # include NaNs in the count\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Print unique values to check validity & quality:\n",
    "print_all_value_counts(clean_df)\n",
    "\n",
    "print(\"\\n✅ Data cleaning completed successfully!\")\n",
    "print(\"✅ Ready for next step: Exploratory Data Analysis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "bntg1u54kvok",
    "jupyter": {
     "source_hidden": true
    },
    "outputId": "b356c3b6-2062-4c11-867d-69e7b5faee07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 'Patient ID' column.\n"
     ]
    }
   ],
   "source": [
    "# Drop the patient id: Keeping it may confuse clustering, bias correlation, or lead to overfitting in machine learning.\n",
    "# We're not doing patient-level tracking (like repeat visits, longitudinal analysis, etc.)\n",
    "\n",
    "# Drop 'Patient ID' if it exists\n",
    "if 'Patient ID' in clean_df.columns:\n",
    "    clean_df.drop(columns=['Patient ID'], inplace=True)\n",
    "    print(\"Dropped 'Patient ID' column.\")\n",
    "\n",
    "# Create the final data variable\n",
    "data = clean_df\n",
    "\n",
    "# Display the DataFrame\n",
    "data\n",
    "clean_df.to_excel('cleaned_data.xlsx', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDDBz22rCFSX"
   },
   "source": [
    "\n",
    "# STEP 2: Exploratory Data Analysis (EDA)\n",
    "## Goal: Understand distributions, correlations, and how variables relate to risk.\n",
    "\n",
    "We'll do:\n",
    "\n",
    "* Visualizations (bar plots, histograms, boxplots)\n",
    "\n",
    "* Correlation heatmaps\n",
    "\n",
    "* Outcome imbalance checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDDBz22rCFSX"
   },
   "source": [
    "\n",
    "# STEP 3: Random Forest Classifier\n",
    "## Goal: Understand the features which have more influence on the target column. The columns with the most correlation will then be used to train the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LabelEncoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[109]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      8\u001b[39m categorical_cols = [\u001b[33m'\u001b[39m\u001b[33mHPV Test Result\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mPap Smear Result\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mSmoking Status\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      9\u001b[39m                     \u001b[33m'\u001b[39m\u001b[33mSTDs History\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mRegion\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mInsurance Covered\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mScreening Type Last\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# 4. Encode categorical columns using LabelEncoder\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m le = \u001b[43mLabelEncoder\u001b[49m()\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m categorical_cols:\n\u001b[32m     14\u001b[39m     data[col] = le.fit_transform(data[col])\n",
      "\u001b[31mNameError\u001b[39m: name 'LabelEncoder' is not defined"
     ]
    }
   ],
   "source": [
    "# 1. Load the dataset\n",
    "df = pd.read_excel(\"cleaned_data.xlsx\")\n",
    "\n",
    "# 2. Make a copy to work on\n",
    "data = df.copy()\n",
    "\n",
    "# 3. List of categorical columns to encode\n",
    "categorical_cols = ['HPV Test Result', 'Pap Smear Result', 'Smoking Status',\n",
    "                    'STDs History', 'Region', 'Insurance Covered', 'Screening Type Last']\n",
    "\n",
    "# 4. Encode categorical columns using LabelEncoder\n",
    "le = LabelEncoder()\n",
    "for col in categorical_cols:\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "\n",
    "# 5. Encode the target variable (Recommended Action)\n",
    "data['Recommended Action'] = le.fit_transform(data['Recommended Action'])\n",
    "\n",
    "# 6. Define features (X) and target (y)\n",
    "X = data.drop(columns=['Recommended Action'])\n",
    "y = data['Recommended Action']\n",
    "\n",
    "# 7. Train a Random Forest Classifier\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X, y)\n",
    "\n",
    "# 8. Get feature importances\n",
    "feature_importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "# 9. Plot feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=feature_importances.values, y=feature_importances.index, palette='viridis')\n",
    "plt.title('Feature Importance for Predicting Recommended Action')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.tight_layout()\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.show()\n",
    "\n",
    "# 10. Print importance scores\n",
    "print(feature_importances)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "uC_dGuzYnPax",
    "outputId": "bacf49e2-1b61-416d-9bc6-c1b22e7e921a"
   },
   "outputs": [],
   "source": [
    "# 1\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check class balance for HPV\n",
    "sns.countplot(data=clean_df, x='HPV Test Result')\n",
    "plt.title('HPV Test Result Distribution')\n",
    "plt.show()\n",
    "\n",
    "# Check class balance for Pap Smear\n",
    "sns.countplot(data=clean_df, x='Pap Smear Result')\n",
    "plt.title('Pap Smear Result Distribution')\n",
    "plt.show()\n",
    "\n",
    "# Age distribution\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.histplot(data=clean_df, x='Age', bins=20, kde=True)\n",
    "plt.title('Age Distribution')\n",
    "plt.show()\n",
    "\n",
    "# Correlation matrix for numeric columns\n",
    "numeric_cols = clean_df.select_dtypes(include=['int64', 'float64']).columns\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(clean_df[numeric_cols].corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JiGEIbeAo8gk"
   },
   "source": [
    "In Exploratory Data Analysis (EDA), We focus on key target variables.\n",
    "\n",
    "In cervical cancer prediction, we treat this as a binary classification:\n",
    "\n",
    "Does this patient show signs that are likely to lead to cervical cancer?\n",
    "\n",
    "We use:\n",
    "\n",
    "Recommended Action → Could be used as proxy for diagnosis\n",
    "HPV Test Result\n",
    "Pap Smear Result\n",
    "Screening Type Last\n",
    "\n",
    "We’ll use these to understand who’s at risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 884
    },
    "id": "JA5KE39WlKeh",
    "outputId": "91ed067d-b1a8-4aa4-a643-4625f1be3d71"
   },
   "outputs": [],
   "source": [
    "# 2.Show distributions of key category values defined above\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set visual style\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# HPV Test Result distribution\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(data=clean_df, x='HPV Test Result', palette='Set2')\n",
    "plt.title('Distribution of HPV Test Results')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Pap Smear Result distribution\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(data=clean_df, x='Pap Smear Result', palette='Set3')\n",
    "plt.title('Distribution of Pap Smear Results')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Recommended Action distribution (top 10)\n",
    "plt.figure(figsize=(10,6))\n",
    "top_actions = clean_df['Recommended Action'].value_counts().nlargest(10)\n",
    "sns.barplot(y=top_actions.index, x=top_actions.values, palette='coolwarm')\n",
    "plt.title('Top 10 Recommended Actions')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Recommended Action')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 672
    },
    "id": "mjaeT-M4o50m",
    "outputId": "35bc3a21-4ff1-4f5e-e519-495854655d80"
   },
   "outputs": [],
   "source": [
    "# List of important numerical features\n",
    "num_features = ['Age', 'Sexual Partners', 'First Sexual Activity Age']\n",
    "\n",
    "# Plot histograms\n",
    "clean_df[num_features].hist(bins=20, figsize=(12, 6), color='skyblue')\n",
    "plt.suptitle('Distribution of Key Numeric Features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Heatmap to check which features are correlated with others.\n",
    "\n",
    "# only numerical columns\n",
    "numeric_cols = clean_df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(clean_df[numeric_cols].corr(), annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Between Numerical Features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6SmiHmNpBsXX"
   },
   "source": [
    "# STEP 3: Modeling and Pre-Training Phase\n",
    "\n",
    "##  Goal:\n",
    "Build and evaluate a predictive model using your **cleaned**, **preprocessed** dataset.  \n",
    "This phase helps us learn patterns from the data and **predict High Risk patients** based on clinical features.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary Table of Key Steps\n",
    "\n",
    "| Step                        | What it Means                                                                 | What You Do                                                   |\n",
    "|-----------------------------|-------------------------------------------------------------------------------|---------------------------------------------------------------|\n",
    "| 1. Feature & Target Selection | Choose what we want to predict (target) and the data used to predict it (features). | `X = datav_clean[features]` <br> `y = datav_clean['High Risk']` |\n",
    "| 2. Train-Test Splitting    | Split the dataset into training and test sets for fair model evaluation.    | `train_test_split(X, y, test_size=0.2, random_state=0)`       |\n",
    "| 3. Scaling / Encoding (if needed) | Standardize numeric values to a common scale (important for some models like logistic regression). | `StandardScaler()` or `MinMaxScaler()` if model needs it      |\n",
    "| 4. Model Selection         | Choose a model suitable for classification.                                 | `DecisionTreeClassifier()`, `LogisticRegression()`, etc.      |\n",
    "| 5. Model Training         | Feed the training data into the model so it can learn patterns.            | `model.fit(X_train, y_train)`                                 |\n",
    "| 6. Evaluation              | Check the model’s accuracy, precision, recall, etc. using test data.        | `confusion_matrix`, `classification_report`, `accuracy_score` |\n",
    "| 7. Interpretation          | Understand feature importance and model behavior.                          | `model.feature_importances_` or tree plots                    |\n",
    "\n",
    "---\n",
    "\n",
    "## Output of This Phase:\n",
    "- A trained and evaluated model that can predict if a patient is **High Risk** for cervical cancer.\n",
    "- Metrics to judge how well the model performs.\n",
    "- A ranked list of which features are most important in making predictions (e.g., age, smoking, screening type).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Clean messy strings (e.g., \" yes \" → \"YES\")\n",
    "\n",
    "#Maps them to numbers\n",
    "#Prepares the dataframe to work seamlessly with your existing risk-flagging logic.\n",
    "\n",
    "# Ensure all relevant columns in clean_df are encoded before making a copy\n",
    "clean_df\n",
    "\n",
    "clean_df['Pap Smear Result'] = clean_df['Pap Smear Result'].astype(str).str.upper().str.strip().replace({\n",
    "    'N': 0, 'Y': 1\n",
    "})\n",
    "\n",
    "clean_df['Smoking Status'] = clean_df['Smoking Status'].astype(str).str.upper().str.strip().replace({\n",
    "    'N': 0, 'Y': 1, 'TRUE': 1, 'FALSE': 0\n",
    "})\n",
    "\n",
    "clean_df['STDs History'] = clean_df['STDs History'].astype(str).str.upper().str.strip().replace({\n",
    "    'N': 0, 'Y': 1, 'TRUE': 1, 'FALSE': 0\n",
    "})\n",
    "\n",
    "clean_df['Insurance Covered'] = clean_df['Insurance Covered'].astype(str).str.upper().str.strip().replace({\n",
    "    'N': 0, 'Y': 1\n",
    "})\n",
    "\n",
    "clean_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Because the cervical cancer dataset doesn’t contain a direct diagnosis column like \"has cancer = yes/no\", \n",
    "#we are creating a new feature called High Risk. \n",
    "# we use real clinical clues (like positive test results or medical recommendations) to determine whether a patient is high risk.\n",
    "# This new High Risk column becomes your true target — better than using only HPV Test Result\n",
    "\n",
    "# 1. Make a fresh copy\n",
    "datav = clean_df.copy()\n",
    "\n",
    "# 2. Encode relevant binary columns. 'YES' = 1 (indicating presence)'NO' = 0 (indicating absence)\n",
    "datav['HPV Test Result'] = datav['HPV Test Result'].map({'NEGATIVE': 0, 'POSITIVE': 1})\n",
    "\n",
    "# 3. Handle Screening Type Last → create new binary feature: Screening Type Suspicious, first clean this column:\n",
    "# Replace missing values (NaN) with 'UNKNOWN'\n",
    "# Standardize capitalization (so 'hpv', 'HPV ', 'Hpv' all become 'HPV')\n",
    "\n",
    "#Remove leading/trailing spaces\n",
    "datav['Screening Type Last'] = datav['Screening Type Last'].fillna('UNKNOWN').str.upper().str.strip()\n",
    "datav['Screening Type Suspicious'] = datav['Screening Type Last'].apply(\n",
    "    lambda x: 1 if any(word in x for word in ['COLPOSCOPY', 'PAP', 'HPV']) else 0\n",
    ")\n",
    "\n",
    "# 4. Create HIGH RISK target variable ie\n",
    "# We are flagging a patient as high risk if any of these are true:\n",
    "\n",
    "# Their HPV test is positive\n",
    "# Their Pap smear is abnormal\n",
    "# Their last screening type was serious (like HPV or Colposcopy)\n",
    "# Their doctor recommended a follow-up action like biopsy or colposcopy\n",
    "\n",
    "datav['High Risk'] = 0  # default\n",
    "\n",
    "# High risk if HPV positive AND Pap Smear positive\n",
    "datav.loc[(datav['HPV Test Result'] == 1) & (datav['Pap Smear Result'] == 1), 'High Risk'] = 1\n",
    "\n",
    "# OR if Recommended Action includes serious follow-up\n",
    "datav['High Risk'] = datav.apply(\n",
    "    lambda row: 1 if 'BIOPSY' in row['Recommended Action'].upper() or 'COLPOSCOPY' in row['Recommended Action'].upper() else row['High Risk'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# OR if Screening Type is suspicious\n",
    "datav.loc[datav['Screening Type Suspicious'] == 1, 'High Risk'] = 1\n",
    "\n",
    "# ✅ Done\n",
    "print(\"High Risk class distribution:\")\n",
    "print(datav['High Risk'].value_counts())\n",
    "\n",
    "print(datav['Screening Type Suspicious'].value_counts())\n",
    "\n",
    "datav\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding.\n",
    "#Here we encode the Region,screening Type Last to binary. \n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Screening Type Last': ['Pap Smear', 'HPV DNA Test', 'Co-testing', 'Pap Smear'],\n",
    "    'Region': ['Nairobi', 'Kisumu', 'Mombasa', 'Nairobi'],\n",
    "    'Screening Type Last':['PAP SMEAR','HPV DNA'],\n",
    "    'Recommended Action':\n",
    "})\n",
    "\n",
    "# Apply one-hot encoding\n",
    "df_encoded = pd.get_dummies(df, columns=['Screening Type Last', 'Region'])\n",
    "print(df_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop some columns\n",
    "#Region\n",
    "#Reason to drop:\n",
    "#This column is likely categorical geographic data (e.g., \"Central\", \"Nairobi\", \"Unknown\") and:\n",
    "#It doesn’t directly indicate a person’s biological or clinical risk\n",
    "#Might introduce location-based bias (e.g., model predicts higher risk just because someone is from a certain place)\n",
    "#Can skew the model especially with small or uneven sample sizes per region\n",
    "\n",
    "#Screening Type Last\n",
    "#Reason to drop:\n",
    "#You already extracted useful info from this column into a binary feature called:Screening Type Suspicious\n",
    "\n",
    "#This feature captures whether the last screening method was highly diagnostic (e.g., HPV test, Pap smear, or Colposcopy). Keeping both would introduce redundancy.\n",
    "#Drop to avoid duplication and multicollinearity\n",
    "\n",
    "#Recommended Action\n",
    "#Reason to drop:\n",
    "#You already used this column to build your target variable High Risk, based on whether the action was “biopsy” or “colposcopy”.\n",
    "#Keeping this column in the features would leak information that was already used to define the target — this is called data leakage in machine learning.\n",
    "#Drop to prevent data leakage\n",
    "\n",
    "#Insurance Covered\n",
    "#Reason to drop:\n",
    "#While important socially, it:\n",
    "#Doesn’t represent actual clinical or biological risk\n",
    "#Could lead the model to predict based on financial access rather than medical condition\n",
    "#Introduces ethical concerns (e.g., model assumes uninsured = low risk, which is false)\n",
    "#Drop for ethical, clinical, and fairness reasons\n",
    "\n",
    "# List of columns to drop\n",
    "cols_to_drop = [\n",
    "    'Region',\n",
    "    'Screening Type Last',\n",
    "    'Recommended Action',\n",
    "    'Insurance Covered'\n",
    "]\n",
    "\n",
    "# Drop them from the cleaned dataset\n",
    "datav_clean = datav.drop(columns=cols_to_drop)\n",
    "\n",
    "# Optional: confirm the updated columns\n",
    "print(\"Remaining columns after drop:\")\n",
    "print(datav_clean.columns)\n",
    "datav_clean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6SmiHmNpBsXX"
   },
   "source": [
    "# STEP 4 Modeling Phase-Decision Tree Classifier\n",
    "\n",
    "## Why Decision Tree?\n",
    "We're using a Decision Tree model (CART) to classify patients as **High Risk** or **Not High Risk** based on medical and behavioral features.\n",
    "\n",
    "---\n",
    "\n",
    "## Advantages of Decision Trees\n",
    "- **Low computational cost**: Trees are logarithmic in complexity, making them scalable for large datasets.\n",
    "- **White-box model**: Easy to interpret and visualize. We can trace how decisions are made.\n",
    "- **Minimal data preparation**: No need to normalize, scale, or encode dummy variables for numerical trees.\n",
    "\n",
    "---\n",
    "\n",
    "## Disadvantages of Decision Trees\n",
    "- **Overfitting**: Trees may perfectly fit training data but perform poorly on new data. (We can use pruning or switch to Random Forests.)\n",
    "- **Instability**: Small data changes can lead to completely different trees.\n",
    "- **Class ambiguity**: Trees struggle if many examples have identical features but different labels (noisy/conflicting data).\n",
    "\n",
    "---\n",
    "\n",
    "##  Data Check Before Modeling\n",
    "To verify if identical inputs have different outputs (inconsistent cases), we can run this loop:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w1P4plxo3eJm"
   },
   "outputs": [],
   "source": [
    "# Train & Evaluate a Decision Tree Classifier 1. Splitting the data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define features and target\n",
    "features = [\n",
    "    'Age', \n",
    "    'Sexual Partners', \n",
    "    'First Sexual Activity Age',\n",
    "    'Smoking Status',\n",
    "    'STDs History',\n",
    "    'Screening Type Suspicious'\n",
    "]\n",
    "\n",
    "X = datav_clean[features]\n",
    "y = datav_clean['High Risk']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "97jI8hdKMZqR"
   },
   "outputs": [],
   "source": [
    "#Train, Evaluate, and Interpret a Decision Tree Model\n",
    "# 1. Train the Model\n",
    "#Now that you've split your data into training and testing sets, you're ready to train a DecisionTreeClassifier.\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize the model\n",
    "dtree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train (fit) the model on training data\n",
    "dtree.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mDvoOWXLGgcF"
   },
   "outputs": [],
   "source": [
    "#Make Predictions\n",
    "# Once trained, predict on the test data and evaluate performance.\n",
    "# Predict on the test set\n",
    "y_pred = dtree.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_RHs07-bPYFe"
   },
   "source": [
    "## Model from ScikitLearn\n",
    "\n",
    "\n",
    "*   Uses CART algorithm, meaning that each leaf can only have two children. aka binary trees\n",
    "*   ID3 algorithm could produce nodes with more than 2 children\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s3YhzKY737GH"
   },
   "outputs": [],
   "source": [
    "#Evaluate the Model\n",
    "#We'll use accuracy, confusion matrix, and classification report to assess how well your model performs.\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Accuracy\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\n Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Precision, Recall, F1-score\n",
    "print(\"\\n Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Not High Risk\", \"High Risk\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning (Grid Search)\n",
    "#  Train using GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "# Define model and grid\n",
    "param_grid = {\n",
    "    'max_depth': [4, 5, 6, 7, 8, 9, 10, 11],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=DecisionTreeClassifier(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    scoring=make_scorer(f1_score),\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Extract best model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the Best Model, this is after the grid search and prediction:\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Not High Risk\", \"High Risk\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IUcAIkyBfjlz"
   },
   "outputs": [],
   "source": [
    "# Visualize the Tree \n",
    "# This helps you understand the decision logic your model has learned.\n",
    "\n",
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plot_tree(\n",
    "    best_model,\n",
    "    feature_names=features,\n",
    "    class_names=['Not High Risk', 'High Risk'],\n",
    "    filled=True,\n",
    "    rounded=True\n",
    ")\n",
    "plt.title(\"First Decision Tree\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wnfzkNelQR73",
    "outputId": "048274f5-0594-4116-848b-20e71ce0ca5f"
   },
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "# See which features the tree considered most useful in classification.\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use best_model, not dtree\n",
    "feature_importances = pd.Series(best_model.feature_importances_, index=features)\n",
    "\n",
    "# Sort and plot\n",
    "feature_importances.sort_values(ascending=True).plot(\n",
    "    kind='barh',\n",
    "    title='Feature Importances',\n",
    "    figsize=(8, 5),\n",
    "    color='skyblue'\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Importance Score\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "567VG4dkRCkz"
   },
   "outputs": [],
   "source": [
    "#Pruning (To Prevent Overfitting)\n",
    "#(to do limit tree depth, minimum samples, etc.)\n",
    "\n",
    "# Create a pruned version of the tree\n",
    "dtree_pruned = DecisionTreeClassifier(\n",
    "    max_depth=3,               # limit depth to 3 levels (simpler tree)\n",
    "    min_samples_split=10,      # at least 10 samples to consider a split\n",
    "    random_state=42            # reproducibility\n",
    ")\n",
    "\n",
    "dtree_pruned.fit(X_train, y_train)  # Train on training set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with the pruned tree\n",
    "y_pred_pruned = dtree_pruned.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the pruned model\n",
    "print(\"Pruned Tree Accuracy:\", accuracy_score(y_test, y_pred_pruned))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred_pruned))\n",
    "print(classification_report(y_test, y_pred_pruned))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_RHs07-bPYFe"
   },
   "source": [
    "# Compare: Grid Search Model vs Pruned Tree\n",
    "* Evaluate both models on the same test data\n",
    "* Show accuracy, F1, confusion matrix, and classification report\n",
    "* Output the better final decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "# -------------------------------\n",
    "# Evaluate Best Grid Search Model\n",
    "# -------------------------------\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "print(\"Grid Search Model Evaluation\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_best))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_best))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_best))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_best))\n",
    "\n",
    "\n",
    "# ---------------------\n",
    "# Evaluate Pruned Model\n",
    "# ---------------------\n",
    "y_pred_pruned = dtree_pruned.predict(X_test)\n",
    "\n",
    "print(\"\\n Pruned Model Evaluation\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_pruned))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_pruned))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_pruned))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_pruned))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_RHs07-bPYFe"
   },
   "source": [
    "# Summary of Results\n",
    "\n",
    "| **Metric**           | **Grid Search Model**           | **Pruned Decision Tree**       |\n",
    "|----------------------|----------------------------------|---------------------------------|\n",
    "| **Accuracy**         | 0.95                             |    1.00                         |\n",
    "| **F1 Score**         | 0.9677                           |    1.00                         |\n",
    "| **Confusion Matrix** | 1 FN (missed class 0)            |    Perfect                      |\n",
    "| **Interpretability** | Moderate (depth may vary)        |    Simple (you control depth)   |\n",
    "| **Overfitting Risk** | Medium                           |    High (check generalizability) |\n",
    "\n",
    "---\n",
    "\n",
    "# Interpretation\n",
    "\n",
    "##  Why the Pruned Model is Better (for Now):\n",
    "\n",
    "* **Perfect performance on test set**: 100% accuracy and F1 score — no false positives or negatives.\n",
    "* **Simpler model**: Easier to interpret and explain.\n",
    "* **Faster**: Less computational load.\n",
    "\n",
    "---\n",
    "\n",
    "# Disadvantage: Overfitting Risk\n",
    "\n",
    "Even though the pruned tree scores perfectly, keep in mind:\n",
    "\n",
    "* It may be **memorizing the training data**.\n",
    "* With a small test set (only 20 samples), this result may **not generalize** well to unseen patients.\n",
    "\n",
    "---\n",
    "\n",
    "# Final Steps\n",
    "\n",
    "**stick with the pruned tree**, because:\n",
    "\n",
    "* The **dataset is small**.\n",
    "* We need a **quick, interpretable model**.\n",
    "* Need a proof of concept**explain it to doctors or healthcare decision-makers**.\n",
    "\n",
    "---\n",
    "\n",
    "We compared a hyperparameter-tuned Decision Tree via Grid Search with a manually pruned version. Although both performed well, the pruned tree achieved perfect performance on our test set with fewer parameters and more interpretability. Due to our small dataset and the importance of explainability in medical predictions, we select the pruned model as our final classifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QfhcZWLnCoiH"
   },
   "source": [
    "## Final decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the Final Tree-pruned tree\n",
    "# imports are included first\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "#  Visualize the pruned decision tree\n",
    "dot_data = export_graphviz(\n",
    "    dtree_pruned,  # Make sure this is the correct pruned model variable\n",
    "    out_file=None,\n",
    "    feature_names=features,\n",
    "    class_names=[\"Not High Risk\", \"High Risk\"],\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    special_characters=True\n",
    ")\n",
    "\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"final_decision_tree_pruned\", format='png', cleanup=True)\n",
    "graph  # This will display the tree in Jupyter Notebook\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XLUQAuspRCoB"
   },
   "outputs": [],
   "source": [
    "# Save Your Model (Optional for deployment)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(dtree_pruned, 'final_cervical_risk_model.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZLLERVD2iYK"
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "After building, tuning, and evaluating our Decision Tree Classifier, here is the summary of our results:\n",
    "\n",
    "---\n",
    "\n",
    "## Optimal Model Parameters (from Grid Search)\n",
    "- **Criterion**: `entropy`\n",
    "- **Max Depth**: `4`\n",
    "- **Min Samples Leaf**: `2`\n",
    "- **Min Samples Split**: `6`\n",
    "\n",
    "These parameters were found using GridSearchCV and 5-fold cross-validation with F1 score as the evaluation metric.\n",
    "\n",
    "---\n",
    "\n",
    "## Final Model Performance\n",
    "- **Accuracy**: ~96%\n",
    "- **F1 Score**: ~0.97\n",
    "- **Confusion Matrix**: Very few false positives/negatives\n",
    "- **Interpretability**: High, due to controlled depth and pruned tree structure\n",
    "\n",
    "---\n",
    "\n",
    "##  Why This Model Works Well\n",
    "- Balances accuracy and generalizability.\n",
    "- Performs well on both training and test data.\n",
    "- Easy to interpret for healthcare professionals and stakeholders.\n",
    "- Ideal for small to medium medical datasets.\n",
    "\n",
    "---\n",
    "\n",
    "## Final Notes\n",
    "- While performance is excellent on this dataset, further evaluation on **larger or external datasets** is advised before clinical use.\n",
    "- Always ensure models are validated across populations and reviewed with domain experts before deployment.\n",
    "\n",
    "---\n",
    "\n",
    " **Next Steps for more interactive interface:**\n",
    "- Deploy the model for interactive predictions.\n",
    "- Integrate with a simple web app or API.\n",
    "- Explore ensemble methods (Random Forest, XGBoost) for more robustness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "car15kHwLxB9"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
