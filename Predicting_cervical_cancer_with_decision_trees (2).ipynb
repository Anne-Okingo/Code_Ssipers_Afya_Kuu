{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dGDEWIlDS6Cf"
   },
   "source": [
    "## Step 1: Import Libraries\n",
    "\n",
    "- `pandas` and `numpy` help us work with data.\n",
    "\n",
    "- `matplotlib` and `seaborn` are used to create charts and graphs.\n",
    "\n",
    "- From `scikit-learn`, we import tools to split data, build a random forest model, and check how well the model performs.\n",
    "\n",
    "- `compute_class_weight` helps us deal with class imbalance in the data.\n",
    "\n",
    "- `thefuzz` is used for fuzzy string matching‚Äîuseful when text isn‚Äôt exactly the same.\n",
    "\n",
    "- `re` is Python‚Äôs tool for working with text patterns using regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g_EfJsu2hZqr"
   },
   "outputs": [],
   "source": [
    "# imported libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from thefuzz import process\n",
    "import re\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dGDEWIlDS6Cf",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "\n",
    "## References\n",
    "\n",
    "* [Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) Random Forest Classifier documentation  \n",
    "* [Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) train-test split documentation  \n",
    "* [Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.class_weight.compute_class_weight.html) compute class weight documentation  \n",
    "* [Scikit-learn](https://scikit-learn.org/stable/modules/model_evaluation.html) metrics documentation (accuracy, confusion matrix, classification report)  \n",
    "* [Pandas documentation](https://pandas.pydata.org/docs/) for data manipulation  \n",
    "* [NumPy documentation](https://numpy.org/doc/) for numerical computing  \n",
    "* [Matplotlib](https://matplotlib.org/stable/index.html) official documentation for plotting  \n",
    "* [Seaborn](https://seaborn.pydata.org/) official documentation for statistical data visualization  \n",
    "* [Medium article](https://medium.com/@jaimejcheng/data-exploration-and-visualization-with-seaborn-pair-plots-40e6d3450f6d) for Seaborn pair plots  \n",
    "* [TheFuzz GitHub](https://github.com/seatgeek/thefuzz) for fuzzy string matching in Python  \n",
    "* [Medium article](https://towardsdatascience.com/fuzzy-string-matching-in-python-68f240d910fe) explaining fuzzy matching in Python  \n",
    "* [Hands-On Machine Learning book](https://www.amazon.com/Hands-Machine-Learning-Scikit-Learn-TensorFlow/dp/1491962291) for machine learning workflows and best practices  \n",
    "* [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php) for accessing open datasets  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-4BOymaBxKZ"
   },
   "source": [
    "## Step 2: Load and Prepare the Dataset\n",
    "\n",
    "- Load the dataset from the Excel file `Cervical Cancer Datasets_.xlsx`.\n",
    "- Save it as a CSV file named `cervical_cancer.csv` to make it easier to work with.\n",
    "- Load the CSV file into a Pandas DataFrame called `data` for further analysis.\n",
    "\n",
    "Note: We use `index=False` when saving to prevent Pandas from adding row numbers as a column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NChL47NVhXiv"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sexual Partners</th>\n",
       "      <th>First Sexual Activity Age</th>\n",
       "      <th>HPV Test Result</th>\n",
       "      <th>Pap Smear Result</th>\n",
       "      <th>Smoking Status</th>\n",
       "      <th>STDs History</th>\n",
       "      <th>Region</th>\n",
       "      <th>Insrance Covered</th>\n",
       "      <th>Screening Type Last</th>\n",
       "      <th>Recommended Action</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P0001</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Pumwani</td>\n",
       "      <td>Y</td>\n",
       "      <td>PAP SMEAR</td>\n",
       "      <td>REPEAT PAP SMEAR IN 3 YEARS AND FOR HPV VACCINE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P0002</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Kakamega</td>\n",
       "      <td>N</td>\n",
       "      <td>HPV DNA</td>\n",
       "      <td>FOR HPV VACCINE AND SEXUAL EDUCATION</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P0003</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Machakos</td>\n",
       "      <td>N</td>\n",
       "      <td>HPV DNA</td>\n",
       "      <td>FOR HPV VACCINE AND SEXUAL EDUCATION</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P0004</td>\n",
       "      <td>52</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Embu</td>\n",
       "      <td>Y</td>\n",
       "      <td>HPV DNA</td>\n",
       "      <td>FOR HPV VACCINE, LIFESTYLE AND SEXUAL EDUCATION</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P0005</td>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Mombasa</td>\n",
       "      <td>N</td>\n",
       "      <td>HPV DNA</td>\n",
       "      <td>FOR HPV VACCINE AND SEXUAL EDUCATION</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>P0096</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Machakos</td>\n",
       "      <td>N</td>\n",
       "      <td>PAP SMEAR</td>\n",
       "      <td>FOR COLPOSCOPY BIOPSY, CYTOLOGY</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>P0097</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Mombasa</td>\n",
       "      <td>N</td>\n",
       "      <td>PAP SMEAR</td>\n",
       "      <td>REPEAT PAP SMEAR IN 3 YEARS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>P0098</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Kericho</td>\n",
       "      <td>N</td>\n",
       "      <td>HPV DNA</td>\n",
       "      <td>FOR ANUAL FOLLOW UP AND PAP SMEAR IN 3 YEARS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>P0099</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Embu</td>\n",
       "      <td>Y</td>\n",
       "      <td>HPV DNA</td>\n",
       "      <td>FOR COLPOSCOPY BIOPSY, CYTOLOGY</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>P0100</td>\n",
       "      <td>59</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Kitale</td>\n",
       "      <td>Y</td>\n",
       "      <td>HPV DNA</td>\n",
       "      <td>FOR COLPOSCOPY BIOPSY, CYTOLOGY +/-TAH</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient ID  Age  Sexual Partners  First Sexual Activity Age  \\\n",
       "0       P0001   18                4                         15   \n",
       "1       P0002   15                1                         14   \n",
       "2       P0003   34                1                          9   \n",
       "3       P0004   52                5                         16   \n",
       "4       P0005   46                3                         21   \n",
       "..        ...  ...              ...                        ...   \n",
       "95      P0096   31                4                         16   \n",
       "96      P0097   35                5                         11   \n",
       "97      P0098   35                1                         18   \n",
       "98      P0099   31                1                         20   \n",
       "99      P0100   59                6                         22   \n",
       "\n",
       "   HPV Test Result Pap Smear Result Smoking Status STDs History     Region  \\\n",
       "0         NEGATIVE                N              N            Y   Pumwani    \n",
       "1         POSITIVE                N              Y            Y  Kakamega    \n",
       "2         POSITIVE                N              N            Y   Machakos   \n",
       "3         POSITIVE                N              Y            N      Embu    \n",
       "4         POSITIVE                N              N            N    Mombasa   \n",
       "..             ...              ...            ...          ...        ...   \n",
       "95        POSITIVE                Y              Y            N   Machakos   \n",
       "96        NEGATIVE                N              Y            N    Mombasa   \n",
       "97        POSITIVE                N              Y            N    Kericho   \n",
       "98        POSITIVE                Y              Y            N      Embu    \n",
       "99        POSITIVE                Y              N            Y    Kitale    \n",
       "\n",
       "   Insrance Covered Screening Type Last  \\\n",
       "0                 Y           PAP SMEAR   \n",
       "1                 N             HPV DNA   \n",
       "2                 N             HPV DNA   \n",
       "3                 Y             HPV DNA   \n",
       "4                 N             HPV DNA   \n",
       "..              ...                 ...   \n",
       "95                N           PAP SMEAR   \n",
       "96                N           PAP SMEAR   \n",
       "97                N             HPV DNA   \n",
       "98                Y             HPV DNA   \n",
       "99                Y             HPV DNA   \n",
       "\n",
       "                                 Recommended Action Unnamed: 12  \n",
       "0   REPEAT PAP SMEAR IN 3 YEARS AND FOR HPV VACCINE         NaN  \n",
       "1              FOR HPV VACCINE AND SEXUAL EDUCATION         NaN  \n",
       "2              FOR HPV VACCINE AND SEXUAL EDUCATION         NaN  \n",
       "3   FOR HPV VACCINE, LIFESTYLE AND SEXUAL EDUCATION         NaN  \n",
       "4              FOR HPV VACCINE AND SEXUAL EDUCATION         NaN  \n",
       "..                                              ...         ...  \n",
       "95                  FOR COLPOSCOPY BIOPSY, CYTOLOGY         NaN  \n",
       "96                      REPEAT PAP SMEAR IN 3 YEARS         NaN  \n",
       "97     FOR ANUAL FOLLOW UP AND PAP SMEAR IN 3 YEARS         NaN  \n",
       "98                 FOR COLPOSCOPY BIOPSY, CYTOLOGY          NaN  \n",
       "99           FOR COLPOSCOPY BIOPSY, CYTOLOGY +/-TAH         NaN  \n",
       "\n",
       "[100 rows x 13 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load Excel and Save as CSV\n",
    "excel_path = 'Cervical Cancer Datasets_.xlsx'\n",
    "csv_path = 'cervical_cancer.csv'\n",
    "\n",
    "df = pd.read_excel(excel_path)\n",
    "df.to_csv(csv_path,index=False)\n",
    "\n",
    "# Load CSV (use header=None only if the dataset has no headers)\n",
    "data = pd.read_csv(csv_path)  # Remove `header=None` if headers are present\n",
    "\n",
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dGDEWIlDS6Cf"
   },
   "source": [
    "### Flag Duplicates\n",
    "\n",
    "The `Patient ID` is treated as the unique identifier for each individual.\n",
    "\n",
    "We check for duplicate records by comparing all other columns **except `Patient ID`**. If rows have the same values across at least 80% of the fields, they are flagged as potential duplicates.\n",
    "\n",
    "A new column `is_duplicate` is added to the dataset to mark these cases.\n",
    "\n",
    "All flagged records are then exported to `flagged_duplicates.csv` for manual checking and review, ensuring no important data is accidentally removed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag duplicates and export them for manual checking\n",
    "data['is_duplicate'] = data.duplicated(subset=df.columns.difference(['Patient ID']), keep=False)\n",
    "duplicates_df = data[data['is_duplicate'] == True]\n",
    "duplicates_df.to_csv('flagged_duplicates.csv', index=False)\n",
    "\n",
    "print(data.columns)\n",
    "print(\"\\n\")\n",
    "print(f\"The data set has ( Total rows: {len(data)}, Total columns: {len(data.columns)})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dGDEWIlDS6Cf"
   },
   "source": [
    "### Inspect and Verify Data Quality\n",
    "\n",
    "In this step, we perform a basic data audit:\n",
    "\n",
    "- Load the dataset from the CSV file.\n",
    "- Preview the data using `.head()` to understand its structure.\n",
    "- Use `.info()` to check data types and identify columns with missing values.\n",
    "- Count missing values per column to assess data completeness.\n",
    "- Print all unique values for each column to inspect potential inconsistencies or unexpected entries (e.g., typos in categorical fields).\n",
    "- Finally, we print the value counts for each column ‚Äî including missing values ‚Äî to evaluate how frequently each value appears. This helps identify:\n",
    "  - Class imbalance\n",
    "  - Invalid or rare values\n",
    "  - Columns that may require cleaning or transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Patient ID  Age  Sexual Partners  First Sexual Activity Age HPV Test Result  \\\n",
      "0      P0001   18                4                         15        NEGATIVE   \n",
      "1      P0002   15                1                         14        POSITIVE   \n",
      "2      P0003   34                1                          9        POSITIVE   \n",
      "3      P0004   52                5                         16        POSITIVE   \n",
      "4      P0005   46                3                         21        POSITIVE   \n",
      "\n",
      "  Pap Smear Result Smoking Status STDs History     Region Insrance Covered  \\\n",
      "0                N              N            Y   Pumwani                 Y   \n",
      "1                N              Y            Y  Kakamega                 N   \n",
      "2                N              N            Y   Machakos                N   \n",
      "3                N              Y            N      Embu                 Y   \n",
      "4                N              N            N    Mombasa                N   \n",
      "\n",
      "  Screening Type Last                               Recommended Action  \\\n",
      "0           PAP SMEAR  REPEAT PAP SMEAR IN 3 YEARS AND FOR HPV VACCINE   \n",
      "1             HPV DNA             FOR HPV VACCINE AND SEXUAL EDUCATION   \n",
      "2             HPV DNA             FOR HPV VACCINE AND SEXUAL EDUCATION   \n",
      "3             HPV DNA  FOR HPV VACCINE, LIFESTYLE AND SEXUAL EDUCATION   \n",
      "4             HPV DNA             FOR HPV VACCINE AND SEXUAL EDUCATION   \n",
      "\n",
      "  Unnamed: 12  \n",
      "0         NaN  \n",
      "1         NaN  \n",
      "2         NaN  \n",
      "3         NaN  \n",
      "4         NaN  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 13 columns):\n",
      " #   Column                     Non-Null Count  Dtype \n",
      "---  ------                     --------------  ----- \n",
      " 0   Patient ID                 100 non-null    object\n",
      " 1   Age                        100 non-null    int64 \n",
      " 2   Sexual Partners            100 non-null    int64 \n",
      " 3   First Sexual Activity Age  100 non-null    int64 \n",
      " 4   HPV Test Result            100 non-null    object\n",
      " 5   Pap Smear Result           100 non-null    object\n",
      " 6   Smoking Status             100 non-null    object\n",
      " 7   STDs History               100 non-null    object\n",
      " 8   Region                     100 non-null    object\n",
      " 9   Insrance Covered           100 non-null    object\n",
      " 10  Screening Type Last        100 non-null    object\n",
      " 11  Recommended Action         100 non-null    object\n",
      " 12  Unnamed: 12                1 non-null      object\n",
      "dtypes: int64(3), object(10)\n",
      "memory usage: 10.3+ KB\n",
      "None\n",
      "Missing values per column:\n",
      " Patient ID                    0\n",
      "Age                           0\n",
      "Sexual Partners               0\n",
      "First Sexual Activity Age     0\n",
      "HPV Test Result               0\n",
      "Pap Smear Result              0\n",
      "Smoking Status                0\n",
      "STDs History                  0\n",
      "Region                        0\n",
      "Insrance Covered              0\n",
      "Screening Type Last           0\n",
      "Recommended Action            0\n",
      "Unnamed: 12                  99\n",
      "dtype: int64\n",
      "Number of duplicate rows: 0\n",
      "--- Unique values for: Patient ID ---\n",
      "['P0001' 'P0002' 'P0003' 'P0004' 'P0005' 'P0006' 'P0007' 'P0008' 'P0009'\n",
      " 'P0010' 'P0011' 'P0012' 'P0013' 'P0014' 'P0015' 'P0016' 'P0017' 'P0018'\n",
      " 'P0019' 'P0020' 'P0021' 'P0022' 'P0023' 'P0024' 'P0025' 'P0026' 'P0027'\n",
      " 'P0028' 'P0029' 'P0030' 'P0031' 'P0032' 'P0033' 'P0034' 'P0035' 'P0036'\n",
      " 'P0037' 'P0038' 'P0039' 'P0040' 'P0041' 'P0042' 'P0043' 'P0044' 'P0045'\n",
      " 'P0046' 'P0047' 'P0048' 'P0049' 'P0050' 'P0051' 'P0052' 'P0053' 'P0054'\n",
      " 'P0055' 'P0056' 'P0057' 'P0058' 'P0059' 'P0060' 'P0061' 'P0062' 'P0063'\n",
      " 'P0064' 'P0065' 'P0066' 'P0067' 'P0068' 'P0069' 'P0070' 'P0071' 'P0072'\n",
      " 'P0073' 'P0074' 'P0075' 'P0076' 'P0077' 'P0078' 'P0079' 'P0080' 'P0081'\n",
      " 'P0082' 'P0083' 'P0084' 'P0085' 'P0086' 'P0087' 'P0088' 'P0089' 'P0090'\n",
      " 'P0091' 'P0092' 'P0093' 'P0094' 'P0095' 'P0096' 'P0097' 'P0098' 'P0099'\n",
      " 'P0100']\n",
      "\n",
      "\n",
      "--- Unique values for: Age ---\n",
      "[18 15 34 52 46 42 51 26 49 89 44 27 45 43 40 41 21 39 37 38 36 65 35 33\n",
      " 61 31 32 19 86 59]\n",
      "\n",
      "\n",
      "--- Unique values for: Sexual Partners ---\n",
      "[4 1 5 3 2 6 9]\n",
      "\n",
      "\n",
      "--- Unique values for: First Sexual Activity Age ---\n",
      "[15 14  9 16 21 23 27 26 20 17 25 18 19 24 57  2 32 13 29 11 22]\n",
      "\n",
      "\n",
      "--- Unique values for: HPV Test Result ---\n",
      "['NEGATIVE' 'POSITIVE' 'NEGAGTIVE' 'POSITIVE\\n']\n",
      "\n",
      "\n",
      "--- Unique values for: Pap Smear Result ---\n",
      "['N' 'Y']\n",
      "\n",
      "\n",
      "--- Unique values for: Smoking Status ---\n",
      "['N' 'Y']\n",
      "\n",
      "\n",
      "--- Unique values for: STDs History ---\n",
      "['Y' 'N']\n",
      "\n",
      "\n",
      "--- Unique values for: Region ---\n",
      "['Pumwani ' 'Kakamega ' 'Machakos' 'Embu ' 'Mombasa' 'NAKURU' 'Loitoktok'\n",
      " 'Moi ' 'Garissa ' 'Kitale' 'Kakamega' 'Mombasa ' 'Garissa' 'Kericho'\n",
      " 'Pumwani' 'Kericho ' 'Machakos ' 'Moi' 'Kitale ']\n",
      "\n",
      "\n",
      "--- Unique values for: Insrance Covered ---\n",
      "['Y' 'N']\n",
      "\n",
      "\n",
      "--- Unique values for: Screening Type Last ---\n",
      "['PAP SMEAR' 'HPV DNA' 'VIA']\n",
      "\n",
      "\n",
      "--- Unique values for: Recommended Action ---\n",
      "['REPEAT PAP SMEAR IN 3 YEARS AND FOR HPV VACCINE'\n",
      " 'FOR HPV VACCINE AND SEXUAL EDUCATION'\n",
      " 'FOR HPV VACCINE, LIFESTYLE AND SEXUAL EDUCATION'\n",
      " 'FOR COLPOSCOPY CYTOLOGY AND BIOPSY' 'REPEAT PAP SMEAR IN 3 YEARS'\n",
      " 'FOR COLPOSCOPY BIOSY, CYTOLOGY+/- TAH'\n",
      " 'FOR BIOPSY AND CYTOLOGY WITH TAH NOT RECOMMENDED '\n",
      " 'REPEAT PAP SMEAR IN 3 YEARS ' 'FOR COLPOSCOPY BIOPSY, CYTOLOGY '\n",
      " 'FOR ANNUAL FOLLOW UP AND PAP SMEAR IN 3 YEARS ' 'FOR PAP SMEAR'\n",
      " 'FOR PAP SMEAR ' 'FOR COLPOSCPY BIOPSY, CYTOLOGY'\n",
      " 'REPEAT PAP SMEAR IN 3YEARS' 'FOR COLPOSCOPY BIOPSY AND CYTOLOGY+/- TAH '\n",
      " 'FOR LASER THERAPY' 'FOR COLPOSCOPY BIOPSY, CYTOLOGY'\n",
      " 'FOR COLPOSCOPY BIOSPY, CYTOLOGY'\n",
      " 'FOR COLPOSCOPY BIOSPY, CYTOLOGY +/- TAH'\n",
      " 'FOR ANUAL FOLLOW UP AND PAP SMEAR IN 3 YEARS'\n",
      " 'FOR COLPOSCOPY BIOPSY, CYTOLOGY +/- TAH'\n",
      " 'FOR HPV VACCINATION AND SEXUAL EDUCATION'\n",
      " 'FOR COLOSCOPY BIOSY, CYTOLOGY'\n",
      " 'FORCOLPOSCOPY, CYTOLOGY THEN LASER THERAPY'\n",
      " 'FOR COLPOSOCPY BIOPSY, CYTOLOGY WITH TAH NOT RECOMMENDED'\n",
      " 'FOR REPEAT HPV TESTING ANNUALLY AND PAP SMEAR IN 3 YEARS'\n",
      " 'FOR COLPOSCOPY BIOPSY, CYTOLOGY +/-TAH']\n",
      "\n",
      "\n",
      "--- Unique values for: Unnamed: 12 ---\n",
      "[nan ' ']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the raw data\n",
    "data = pd.read_csv(\"cervical_cancer.csv\")\n",
    "\n",
    "# Preview the first few rows\n",
    "print(data.head())\n",
    "\n",
    "# Overview of column names, data types, and non-null counts\n",
    "print(data.info())\n",
    "\n",
    "# Check for missing values in each column\n",
    "print(\"Missing values per column:\\n\", data.isnull().sum())\n",
    "\n",
    "# Show unique values and value counts for each column\n",
    "for column in data.columns:\n",
    "    print(f\"--- Unique values for: {column} ---\")\n",
    "    print(data[column].unique())\n",
    "    print(f\"\\n--- Value Counts for: {column} ---\")\n",
    "    print(data[column].value_counts(dropna=False))\n",
    "    print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDDBz22rCFSX"
   },
   "source": [
    "## Step 3: Exploratory Data Analysis (EDA)\n",
    "\n",
    "Exploratory Data Analysis (EDA) helps us deeply understand the structure, quality, and relationships within the data before applying any machine learning algorithms.\n",
    "\n",
    "### EDA Goals:\n",
    "- Identify variable types (categorical, numerical, binary)\n",
    "- Explore distributions of key features\n",
    "- Visualize relationships and potential predictors\n",
    "- Detect class imbalance in the target variable\n",
    "- Spot outliers or anomalies that may impact modeling\n",
    "- Support decisions for further data cleaning or transformation\n",
    "\n",
    "---\n",
    "\n",
    "### Feature & Data Type Overview\n",
    "\n",
    "We begin by checking the types of each column and the number of unique values. This helps us distinguish between categorical and numerical features and spot columns that need transformation or standardization.\n",
    "\n",
    "---\n",
    "\n",
    "### Known Data Quality Discrepancies\n",
    "\n",
    "During initial inspection, several inconsistencies and typos were identified:\n",
    "\n",
    "#### Column: `HPV Test Result`\n",
    "- `\"POSITIVE\\n\"` ‚Äî extra newline character\n",
    "- `\"NEGAGTIVE\"` ‚Äî misspelling of `\"NEGATIVE\"`\n",
    "\n",
    "#### Column: `Region`\n",
    "- Inconsistent casing: `\"Mombasa\"` vs `\"MOMBASA\"`, `\"Kitale\"` listed multiple times with trailing spaces\n",
    "- Spacing and capitalization differences\n",
    "\n",
    "#### Column: `Recommended Action`\n",
    "- Same recommendation repeated with:\n",
    "  - Extra spaces: `\"REPEAT PAP SMEAR IN 3 YEARS \"` vs `\"REPEAT PAP SMEAR IN 3 YEARS\"`\n",
    "  - Misspellings: `\"BIOSPY\"` instead of `\"BIOPSY\"`, `\"COLOSCOPY\"` instead of `\"COLPOSCOPY\"`\n",
    "  - Concatenation: `\"FORCOLPOSCOPY, CYTOLOGY THEN LASER THERAPY\"`\n",
    "\n",
    "#### Column: `Unnamed: 12`\n",
    "- Largely empty (mostly `NaN`) ‚Äî candidate for removal.\n",
    "\n",
    "#### Column: `Insrance Covered`\n",
    "- Misspelled ‚Äî should be renamed to `\"Insurance Covered\"`\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Outcome Class Imbalance\n",
    "\n",
    "We check whether the target variable (e.g., HPV Test Result or Pap Smear Result) is imbalanced.\n",
    "\n",
    "> Why it's important: Imbalanced datasets can mislead the model into favoring the dominant class, leading to poor generalization.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Distribution of Numeric Features\n",
    "\n",
    "We explore numerical features like `Age`, `First Sexual Activity Age`, and `Sexual Partners` to check their distribution and spot outliers using histograms and boxplots.\n",
    "\n",
    "This step helps:\n",
    "- Identify skewness\n",
    "- Detect abnormal values\n",
    "- Guide transformation decisions\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Binary Features Overview\n",
    "\n",
    "Binary/categorical columns such as `Smoking Status`, `STDs History`, and `Insurance Covered` are analyzed to ensure:\n",
    "- Consistency (e.g., \"YES\"/\"NO\" vs \"Y\"/\"N\")\n",
    "- No missing or ambiguous values\n",
    "\n",
    "Visualizing their distribution gives insight into population characteristics.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Categorical Variable Exploration\n",
    "\n",
    "We examine values in columns like:\n",
    "- `Region` ‚Äì Check patient spread across different geographical locations\n",
    "- `Screening Type Last` ‚Äì Evaluate most commonly used screening methods\n",
    "- `Recommended Action` ‚Äì Understand typical medical advice given after testing\n",
    "\n",
    "This helps us assess frequency, diversity, and inconsistencies in responses.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Correlation Matrix for Numerical Features\n",
    "\n",
    "A correlation matrix (heatmap) shows how numerical features relate to each other. This helps detect:\n",
    "- Redundant or highly correlated variables\n",
    "- Relationships that may influence the model\n",
    "\n",
    "Features explored include:\n",
    "- `Age`\n",
    "- `First Sexual Activity Age`\n",
    "- `Sexual Partners`\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Summary of Key Issues to Clean\n",
    "\n",
    "| Column                 | Issue Type             | Action Needed                     |\n",
    "|------------------------|------------------------|-----------------------------------|\n",
    "| `HPV Test Result`      | Typos, extra characters| Normalize strings                 |\n",
    "| `Region`               | Casing, spacing issues | Map to consistent labels          |\n",
    "| `Recommended Action`   | Misspellings, spacing  | Standardize text                  |\n",
    "| `Unnamed: 12`          | Mostly empty           | Drop this column                  |\n",
    "| `Insrance Covered`     | Misspelled             | Rename to `Insurance Covered`     |\n",
    "\n",
    "---\n",
    "\n",
    "### Bonus: Scikit-learn Data Cleaning Pipeline (Optional)\n",
    "\n",
    "To make cleaning reusable and organized, we can define custom classes using `scikit-learn` transformers and compose them into a pipeline.\n",
    "\n",
    "Example concept:\n",
    "- Create a transformer to clean and standardize `HPV Test Result`\n",
    "- Chain transformers for cleaning multiple fields\n",
    "\n",
    "Using pipelines ensures our data transformations are:\n",
    "- Reproducible\n",
    "- Modular\n",
    "- Easily integrated into training workflows\n",
    "\n",
    "---\n",
    "\n",
    "### EDA Summary\n",
    "\n",
    "- Confirmed the presence of text inconsistencies, typos, and formatting issues in categorical columns.\n",
    "- Several numerical features show outliers or unusual values.\n",
    "- The target variable is imbalanced, which may require resampling.\n",
    "- These insights guide the next step: comprehensive data cleaning and transformation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDDBz22rCFSX"
   },
   "source": [
    "###  3.1: Initial Inspection of Raw Data\n",
    "\n",
    "In this step, we load the raw cervical cancer dataset and conduct an initial inspection to identify data quality issues that need to be addressed during cleaning. Here's what each section does:\n",
    "\n",
    "- **Suppress Warnings**: \n",
    "  We turn off warning messages to keep the notebook output clean using `warnings.filterwarnings('ignore')`.\n",
    "\n",
    "- **Load Data**: \n",
    "  The dataset is loaded from a CSV file (`cervical_cancer.csv`) using `pandas.read_csv()`, and we print the shape to understand how many records (rows) and features (columns) it contains.\n",
    "\n",
    "- **Column Overview**: \n",
    "  We print all the column names using `df.columns.tolist()` to:\n",
    "  - Identify any unnecessary columns (like auto-generated ones: `Unnamed: ...`)\n",
    "  - Spot typos in column names\n",
    "\n",
    "- **Sample Problematic Data**: \n",
    "  We inspect three important columns:\n",
    "  - `HPV Test Result`\n",
    "  - `Region`\n",
    "  - `Recommended Action`\n",
    "  \n",
    "  This helps us identify:\n",
    "  - Inconsistent values (e.g., different spellings, casing, or newline characters)\n",
    "  - Redundancy or unclear labels\n",
    "\n",
    "- **Check for Missing Values**: \n",
    "  Finally, we run `df.isnull().sum()` to count how many missing values exist in each column. This is crucial for deciding whether to impute, drop, or otherwise handle incomplete data during cleaning.\n",
    "\n",
    "This early scan lays the foundation for designing a robust data cleaning process and informs which fields require attention for standardization, correction, or removal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TihNzEzkNc8h"
   },
   "source": [
    "### üîç 3.1: Initial Inspection of Raw Data\n",
    "\n",
    "In this step, we load the raw cervical cancer dataset and perform a quick inspection to identify data quality issues before cleaning. Specifically, we:\n",
    "\n",
    "- Suppress warning messages for a cleaner notebook display.\n",
    "- Load the dataset from a CSV file and print its shape to understand how many rows and columns it contains.\n",
    "- Print the column names to check for any typos or unnecessary fields.\n",
    "- Display unique values from key columns like `HPV Test Result`, `Region`, and a sample of `Recommended Action` values to identify inconsistencies (e.g., typos, inconsistent formatting, or unexpected categories).\n",
    "- Check for missing values in each column to determine which features may require imputation or removal during cleaning.\n",
    "\n",
    "This preliminary scan helps us understand what kind of cleaning and standardization will be necessary to prepare the data for analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Patient ID  Age  Sexual Partners  First Sexual Activity Age HPV Test Result  \\\n",
      "0      P0001   18                4                         15        NEGATIVE   \n",
      "1      P0002   15                1                         14        POSITIVE   \n",
      "2      P0003   34                1                          9        POSITIVE   \n",
      "3      P0004   52                5                         16        POSITIVE   \n",
      "4      P0005   46                3                         21        POSITIVE   \n",
      "\n",
      "  Pap Smear Result Smoking Status STDs History     Region Insrance Covered  \\\n",
      "0                N              N            Y   Pumwani                 Y   \n",
      "1                N              Y            Y  Kakamega                 N   \n",
      "2                N              N            Y   Machakos                N   \n",
      "3                N              Y            N      Embu                 Y   \n",
      "4                N              N            N    Mombasa                N   \n",
      "\n",
      "  Screening Type Last                               Recommended Action  \\\n",
      "0           PAP SMEAR  REPEAT PAP SMEAR IN 3 YEARS AND FOR HPV VACCINE   \n",
      "1             HPV DNA             FOR HPV VACCINE AND SEXUAL EDUCATION   \n",
      "2             HPV DNA             FOR HPV VACCINE AND SEXUAL EDUCATION   \n",
      "3             HPV DNA  FOR HPV VACCINE, LIFESTYLE AND SEXUAL EDUCATION   \n",
      "4             HPV DNA             FOR HPV VACCINE AND SEXUAL EDUCATION   \n",
      "\n",
      "  Unnamed: 12  \n",
      "0         NaN  \n",
      "1         NaN  \n",
      "2         NaN  \n",
      "3         NaN  \n",
      "4         NaN  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 13 columns):\n",
      " #   Column                     Non-Null Count  Dtype \n",
      "---  ------                     --------------  ----- \n",
      " 0   Patient ID                 100 non-null    object\n",
      " 1   Age                        100 non-null    int64 \n",
      " 2   Sexual Partners            100 non-null    int64 \n",
      " 3   First Sexual Activity Age  100 non-null    int64 \n",
      " 4   HPV Test Result            100 non-null    object\n",
      " 5   Pap Smear Result           100 non-null    object\n",
      " 6   Smoking Status             100 non-null    object\n",
      " 7   STDs History               100 non-null    object\n",
      " 8   Region                     100 non-null    object\n",
      " 9   Insrance Covered           100 non-null    object\n",
      " 10  Screening Type Last        100 non-null    object\n",
      " 11  Recommended Action         100 non-null    object\n",
      " 12  Unnamed: 12                1 non-null      object\n",
      "dtypes: int64(3), object(10)\n",
      "memory usage: 10.3+ KB\n",
      "None\n",
      "Missing values per column:\n",
      " Patient ID                    0\n",
      "Age                           0\n",
      "Sexual Partners               0\n",
      "First Sexual Activity Age     0\n",
      "HPV Test Result               0\n",
      "Pap Smear Result              0\n",
      "Smoking Status                0\n",
      "STDs History                  0\n",
      "Region                        0\n",
      "Insrance Covered              0\n",
      "Screening Type Last           0\n",
      "Recommended Action            0\n",
      "Unnamed: 12                  99\n",
      "dtype: int64\n",
      "Number of duplicate rows: 0\n",
      "--- Unique values for: Patient ID ---\n",
      "['P0001' 'P0002' 'P0003' 'P0004' 'P0005' 'P0006' 'P0007' 'P0008' 'P0009'\n",
      " 'P0010' 'P0011' 'P0012' 'P0013' 'P0014' 'P0015' 'P0016' 'P0017' 'P0018'\n",
      " 'P0019' 'P0020' 'P0021' 'P0022' 'P0023' 'P0024' 'P0025' 'P0026' 'P0027'\n",
      " 'P0028' 'P0029' 'P0030' 'P0031' 'P0032' 'P0033' 'P0034' 'P0035' 'P0036'\n",
      " 'P0037' 'P0038' 'P0039' 'P0040' 'P0041' 'P0042' 'P0043' 'P0044' 'P0045'\n",
      " 'P0046' 'P0047' 'P0048' 'P0049' 'P0050' 'P0051' 'P0052' 'P0053' 'P0054'\n",
      " 'P0055' 'P0056' 'P0057' 'P0058' 'P0059' 'P0060' 'P0061' 'P0062' 'P0063'\n",
      " 'P0064' 'P0065' 'P0066' 'P0067' 'P0068' 'P0069' 'P0070' 'P0071' 'P0072'\n",
      " 'P0073' 'P0074' 'P0075' 'P0076' 'P0077' 'P0078' 'P0079' 'P0080' 'P0081'\n",
      " 'P0082' 'P0083' 'P0084' 'P0085' 'P0086' 'P0087' 'P0088' 'P0089' 'P0090'\n",
      " 'P0091' 'P0092' 'P0093' 'P0094' 'P0095' 'P0096' 'P0097' 'P0098' 'P0099'\n",
      " 'P0100']\n",
      "\n",
      "\n",
      "--- Unique values for: Age ---\n",
      "[18 15 34 52 46 42 51 26 49 89 44 27 45 43 40 41 21 39 37 38 36 65 35 33\n",
      " 61 31 32 19 86 59]\n",
      "\n",
      "\n",
      "--- Unique values for: Sexual Partners ---\n",
      "[4 1 5 3 2 6 9]\n",
      "\n",
      "\n",
      "--- Unique values for: First Sexual Activity Age ---\n",
      "[15 14  9 16 21 23 27 26 20 17 25 18 19 24 57  2 32 13 29 11 22]\n",
      "\n",
      "\n",
      "--- Unique values for: HPV Test Result ---\n",
      "['NEGATIVE' 'POSITIVE' 'NEGAGTIVE' 'POSITIVE\\n']\n",
      "\n",
      "\n",
      "--- Unique values for: Pap Smear Result ---\n",
      "['N' 'Y']\n",
      "\n",
      "\n",
      "--- Unique values for: Smoking Status ---\n",
      "['N' 'Y']\n",
      "\n",
      "\n",
      "--- Unique values for: STDs History ---\n",
      "['Y' 'N']\n",
      "\n",
      "\n",
      "--- Unique values for: Region ---\n",
      "['Pumwani ' 'Kakamega ' 'Machakos' 'Embu ' 'Mombasa' 'NAKURU' 'Loitoktok'\n",
      " 'Moi ' 'Garissa ' 'Kitale' 'Kakamega' 'Mombasa ' 'Garissa' 'Kericho'\n",
      " 'Pumwani' 'Kericho ' 'Machakos ' 'Moi' 'Kitale ']\n",
      "\n",
      "\n",
      "--- Unique values for: Insrance Covered ---\n",
      "['Y' 'N']\n",
      "\n",
      "\n",
      "--- Unique values for: Screening Type Last ---\n",
      "['PAP SMEAR' 'HPV DNA' 'VIA']\n",
      "\n",
      "\n",
      "--- Unique values for: Recommended Action ---\n",
      "['REPEAT PAP SMEAR IN 3 YEARS AND FOR HPV VACCINE'\n",
      " 'FOR HPV VACCINE AND SEXUAL EDUCATION'\n",
      " 'FOR HPV VACCINE, LIFESTYLE AND SEXUAL EDUCATION'\n",
      " 'FOR COLPOSCOPY CYTOLOGY AND BIOPSY' 'REPEAT PAP SMEAR IN 3 YEARS'\n",
      " 'FOR COLPOSCOPY BIOSY, CYTOLOGY+/- TAH'\n",
      " 'FOR BIOPSY AND CYTOLOGY WITH TAH NOT RECOMMENDED '\n",
      " 'REPEAT PAP SMEAR IN 3 YEARS ' 'FOR COLPOSCOPY BIOPSY, CYTOLOGY '\n",
      " 'FOR ANNUAL FOLLOW UP AND PAP SMEAR IN 3 YEARS ' 'FOR PAP SMEAR'\n",
      " 'FOR PAP SMEAR ' 'FOR COLPOSCPY BIOPSY, CYTOLOGY'\n",
      " 'REPEAT PAP SMEAR IN 3YEARS' 'FOR COLPOSCOPY BIOPSY AND CYTOLOGY+/- TAH '\n",
      " 'FOR LASER THERAPY' 'FOR COLPOSCOPY BIOPSY, CYTOLOGY'\n",
      " 'FOR COLPOSCOPY BIOSPY, CYTOLOGY'\n",
      " 'FOR COLPOSCOPY BIOSPY, CYTOLOGY +/- TAH'\n",
      " 'FOR ANUAL FOLLOW UP AND PAP SMEAR IN 3 YEARS'\n",
      " 'FOR COLPOSCOPY BIOPSY, CYTOLOGY +/- TAH'\n",
      " 'FOR HPV VACCINATION AND SEXUAL EDUCATION'\n",
      " 'FOR COLOSCOPY BIOSY, CYTOLOGY'\n",
      " 'FORCOLPOSCOPY, CYTOLOGY THEN LASER THERAPY'\n",
      " 'FOR COLPOSOCPY BIOPSY, CYTOLOGY WITH TAH NOT RECOMMENDED'\n",
      " 'FOR REPEAT HPV TESTING ANNUALLY AND PAP SMEAR IN 3 YEARS'\n",
      " 'FOR COLPOSCOPY BIOPSY, CYTOLOGY +/-TAH']\n",
      "\n",
      "\n",
      "--- Unique values for: Unnamed: 12 ---\n",
      "[nan ' ']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the raw data\n",
    "print(\"Loading raw data...\")\n",
    "df = pd.read_csv('cervical_cancer.csv')\n",
    "print(f\"Original dataset shape: {df.shape}\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"BEFORE CLEANING - Data Quality Issues:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Show original data quality issues\n",
    "print(\"1. Column names:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "print(\"\\n2. Sample of problematic data:\")\n",
    "print(\"HPV Test Result unique values:\", df['HPV Test Result'].unique())\n",
    "print(\"Region unique values:\", df['Region'].unique())\n",
    "print(\"Recommended Action samples:\")\n",
    "for action in df['Recommended Action'].unique()[:5]:\n",
    "    print(f\"  - '{action}'\")\n",
    "\n",
    "print(\"\\n3. Missing values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TihNzEzkNc8h"
   },
   "source": [
    "### 3.2: Data Cleaning and Standardization\n",
    "\n",
    "In this step, we clean and standardize the cervical cancer dataset to improve data quality, remove inconsistencies, and prepare it for further analysis and modeling.\n",
    "\n",
    "---\n",
    "\n",
    "#### Step-by-Step Cleaning Breakdown:\n",
    "\n",
    "1. **Create a Copy**  \n",
    "   - We create a copy of the original DataFrame (`clean_df = df.copy()`) to preserve the raw data for reference or backup.\n",
    "\n",
    "2. **Remove Unnecessary Columns**  \n",
    "   - We drop columns like `Unnamed: 12`, which are often artifacts of Excel exports and contain mostly `NaN` or irrelevant data.\n",
    "\n",
    "3. **Fix Column Name Typos**  \n",
    "   - Rename incorrectly spelled column headers.  \n",
    "     Example: `\"Insrance Covered\"` ‚Üí `\"Insurance Covered\"`\n",
    "\n",
    "4. **Clean `HPV Test Result` Column**  \n",
    "   - Convert values to uppercase and strip whitespace.\n",
    "   - Replace typos and inconsistent formats like:\n",
    "     - `\"NEGAGTIVE\"` ‚Üí `\"NEGATIVE\"`\n",
    "     - `\"POSITIVE\\n\"` ‚Üí `\"POSITIVE\"`\n",
    "   - This standardization allows consistent analysis and visualization.\n",
    "\n",
    "5. **Clean and Standardize `Region` Names**  \n",
    "   - Remove inconsistencies caused by case sensitivity and trailing spaces.\n",
    "   - Use a mapping dictionary to unify variations:\n",
    "     - `\"MOMBASA\"`, `\"mombasa \"` ‚Üí `\"Mombasa\"`\n",
    "     - `\"PUMWANI\"`, `\"Pumwani \"` ‚Üí `\"Pumwani\"` etc.\n",
    "\n",
    "6. **Clean Binary Columns (Y/N Values)**  \n",
    "   - Columns like:\n",
    "     - `Pap Smear Result`, `Smoking Status`, `STDs History`, `Insurance Covered`\n",
    "   - We standardize these by:\n",
    "     - Converting to uppercase\n",
    "     - Stripping whitespace  \n",
    "   This ensures we don‚Äôt treat `\"Y\"`, `\"y \"`, and `\" Y\"` as different values.\n",
    "\n",
    "7. **Clean `Screening Type Last` Column**  \n",
    "   - Normalize string values using `upper()` and `strip()` to handle inconsistent formatting.\n",
    "\n",
    "8. **Handle Age Anomalies**  \n",
    "   - Convert `Age` to numeric and clip unrealistic values:\n",
    "     - Any age `< 10` or `> 100` is corrected to fall within that range.\n",
    "\n",
    "9. **Fix First Sexual Activity Age Conflicts**  \n",
    "   - Convert to numeric and check for logical errors:\n",
    "     - Drop rows where `First Sexual Activity Age > Age`.\n",
    "\n",
    "10. **Clean `Sexual Partners` Column**  \n",
    "    - Convert to numeric, drop rows with non-numeric or missing values.\n",
    "\n",
    "11. **Final String Cleanup**  \n",
    "    - Strip all string-type columns of whitespace for consistency.\n",
    "\n",
    "---\n",
    "\n",
    "#### Summary After Cleaning:\n",
    "\n",
    "- Original Shape: Shows the number of rows and columns before cleaning.\n",
    "- Cleaned Shape: Shows the final shape after dropping or fixing records.\n",
    "- Confirmed Cleaned Columns:\n",
    "  - `HPV Test Result` ‚Äî Cleaned and standardized\n",
    "  - `Region` ‚Äî Normalized region names\n",
    "  - Binary and age-related features ‚Äî Cleaned, standardized, and validated\n",
    "\n",
    "---\n",
    "\n",
    "By thoroughly cleaning and validating the data, we ensure higher accuracy in modeling, better visualization outcomes, and more meaningful insights during the next step: **Exploratory Data Analysis (EDA)**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "HWTYnLoOLnvP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw data...\n",
      "Original dataset shape: (100, 13)\n",
      "\n",
      "==================================================\n",
      "BEFORE CLEANING - Data Quality Issues:\n",
      "==================================================\n",
      "1. Column names:\n",
      "['Patient ID', 'Age', 'Sexual Partners', 'First Sexual Activity Age', 'HPV Test Result', 'Pap Smear Result', 'Smoking Status', 'STDs History', 'Region', 'Insrance Covered', 'Screening Type Last', 'Recommended Action', 'Unnamed: 12']\n",
      "\n",
      "2. Sample of problematic data:\n",
      "HPV Test Result unique values: ['NEGATIVE' 'POSITIVE' 'NEGAGTIVE' 'POSITIVE\\n']\n",
      "Region unique values: ['Pumwani ' 'Kakamega ' 'Machakos' 'Embu ' 'Mombasa' 'NAKURU' 'Loitoktok'\n",
      " 'Moi ' 'Garissa ' 'Kitale' 'Kakamega' 'Mombasa ' 'Garissa' 'Kericho'\n",
      " 'Pumwani' 'Kericho ' 'Machakos ' 'Moi' 'Kitale ']\n",
      "Recommended Action samples:\n",
      "  - 'REPEAT PAP SMEAR IN 3 YEARS AND FOR HPV VACCINE'\n",
      "  - 'FOR HPV VACCINE AND SEXUAL EDUCATION'\n",
      "  - 'FOR HPV VACCINE, LIFESTYLE AND SEXUAL EDUCATION'\n",
      "  - 'FOR COLPOSCOPY CYTOLOGY AND BIOPSY'\n",
      "  - 'REPEAT PAP SMEAR IN 3 YEARS'\n",
      "\n",
      "3. Missing values:\n",
      "Patient ID                    0\n",
      "Age                           0\n",
      "Sexual Partners               0\n",
      "First Sexual Activity Age     0\n",
      "HPV Test Result               0\n",
      "Pap Smear Result              0\n",
      "Smoking Status                0\n",
      "STDs History                  0\n",
      "Region                        0\n",
      "Insrance Covered              0\n",
      "Screening Type Last           0\n",
      "Recommended Action            0\n",
      "Unnamed: 12                  99\n",
      "dtype: int64\n",
      "\n",
      "==================================================\n",
      "APPLYING CLEANING TRANSFORMATIONS:\n",
      "==================================================\n",
      "1. Removing unnecessary columns...\n",
      "   Dropped column: Unnamed: 12\n",
      "\n",
      "2. Fixing column name typos...\n",
      "   Renamed 'Insrance Covered' to 'Insurance Covered'\n",
      "\n",
      "3. Cleaning HPV Test Result...\n",
      "   Before: ['NEGATIVE' 'POSITIVE' 'NEGAGTIVE' 'POSITIVE\\n']\n",
      "   After: ['NEGATIVE' 'POSITIVE']\n",
      "\n",
      "4. Cleaning and standardizing Region names...\n",
      "   Before: ['Embu ', 'Garissa', 'Garissa ', 'Kakamega', 'Kakamega ', 'Kericho', 'Kericho ', 'Kitale', 'Kitale ', 'Loitoktok', 'Machakos', 'Machakos ', 'Moi', 'Moi ', 'Mombasa', 'Mombasa ', 'NAKURU', 'Pumwani', 'Pumwani ']\n",
      "   After: ['Embu', 'Garissa', 'Kakamega', 'Kericho', 'Kitale', 'Loitoktok', 'Machakos', 'Moi', 'Mombasa', 'Nakuru', 'Pumwani']\n",
      "\n",
      "6. Cleaning binary columns...\n",
      "   Cleaning Pap Smear Result\n",
      "      Before: ['N' 'Y']\n",
      "      After: ['N' 'Y']\n",
      "   Cleaning Smoking Status\n",
      "      Before: ['N' 'Y']\n",
      "      After: ['N' 'Y']\n",
      "   Cleaning STDs History\n",
      "      Before: ['Y' 'N']\n",
      "      After: ['Y' 'N']\n",
      "   Cleaning Insurance Covered\n",
      "      Before: ['Y' 'N']\n",
      "      After: ['Y' 'N']\n",
      "\n",
      "7. Cleaning Screening Type Last...\n",
      "   Before: ['PAP SMEAR' 'HPV DNA' 'VIA']\n",
      "   After: ['PAP SMEAR' 'HPV DNA' 'VIA']\n",
      "\n",
      "8. Handling age anomalies...\n",
      "   Age range before: 15 - 89\n",
      "   Age range after: 15 - 89\n",
      "\n",
      "9. Handling First Sexual Activity Age anomalies...\n",
      "   First Sexual Activity Age range before: 2 - 57\n",
      "   Found 2 records where first sexual activity age > current age\n",
      "\n",
      "10. Handling Sexual Partners...\n",
      "   Sexual Partners range before cleanup: 1 - 9\n",
      "   Dropped 0 rows with missing or invalid 'Sexual Partners' values.\n",
      "\n",
      "11. Final cleanup...\n",
      "\n",
      "==================================================\n",
      "CLEANING COMPLETE - SUMMARY:\n",
      "==================================================\n",
      "Original shape: (100, 13)\n",
      "Cleaned shape: (98, 12)\n",
      "Columns after cleaning: ['Patient ID', 'Age', 'Sexual Partners', 'First Sexual Activity Age', 'HPV Test Result', 'Pap Smear Result', 'Smoking Status', 'STDs History', 'Region', 'Insurance Covered', 'Screening Type Last', 'Recommended Action']\n",
      "\n",
      "Cleaned data quality:\n",
      "1. HPV Test Result values: ['NEGATIVE' 'POSITIVE']\n",
      "2. Regions: ['Embu', 'Garissa', 'Kakamega', 'Kericho', 'Kitale', 'Loitoktok', 'Machakos', 'Moi', 'Mombasa', 'Nakuru', 'Pumwani']\n",
      "3. Missing values after cleaning:\n",
      "Patient ID                   0\n",
      "Age                          0\n",
      "Sexual Partners              0\n",
      "First Sexual Activity Age    0\n",
      "HPV Test Result              0\n",
      "Pap Smear Result             0\n",
      "Smoking Status               0\n",
      "STDs History                 0\n",
      "Region                       0\n",
      "Insurance Covered            0\n",
      "Screening Type Last          0\n",
      "Recommended Action           0\n",
      "dtype: int64\n",
      "\n",
      "Cleaned data saved as 'cervical_cancer_cleaned.csv'\n",
      "\n",
      "First 5 rows of cleaned data:\n",
      "  Patient ID  Age  Sexual Partners  First Sexual Activity Age HPV Test Result  \\\n",
      "0      P0001   18                4                         15        NEGATIVE   \n",
      "1      P0002   15                1                         14        POSITIVE   \n",
      "2      P0003   34                1                          9        POSITIVE   \n",
      "3      P0004   52                5                         16        POSITIVE   \n",
      "4      P0005   46                3                         21        POSITIVE   \n",
      "\n",
      "  Pap Smear Result Smoking Status STDs History    Region Insurance Covered  \\\n",
      "0                N              N            Y   Pumwani                 Y   \n",
      "1                N              Y            Y  Kakamega                 N   \n",
      "2                N              N            Y  Machakos                 N   \n",
      "3                N              Y            N      Embu                 Y   \n",
      "4                N              N            N   Mombasa                 N   \n",
      "\n",
      "  Screening Type Last                               Recommended Action  \n",
      "0           PAP SMEAR  REPEAT PAP SMEAR IN 3 YEARS AND FOR HPV VACCINE  \n",
      "1             HPV DNA             FOR HPV VACCINE AND SEXUAL EDUCATION  \n",
      "2             HPV DNA             FOR HPV VACCINE AND SEXUAL EDUCATION  \n",
      "3             HPV DNA  FOR HPV VACCINE, LIFESTYLE AND SEXUAL EDUCATION  \n",
      "4             HPV DNA             FOR HPV VACCINE AND SEXUAL EDUCATION  \n",
      "\n",
      "==================================================\n",
      "VERIFICATION OF CLEANED DATA:\n",
      "==================================================\n",
      "\n",
      "HPV Test Result:\n",
      "  Values: ['NEGATIVE' 'POSITIVE']\n",
      "\n",
      "Region:\n",
      "  Total unique values: 11\n",
      "  Sample: ['Pumwani' 'Kakamega' 'Machakos' 'Embu' 'Mombasa' 'Nakuru' 'Loitoktok'\n",
      " 'Moi' 'Garissa' 'Kitale']\n",
      "\n",
      "Pap Smear Result:\n",
      "  Values: ['N' 'Y']\n",
      "\n",
      "Smoking Status:\n",
      "  Values: ['N' 'Y']\n",
      "\n",
      "STDs History:\n",
      "  Values: ['Y' 'N']\n",
      "\n",
      "Insurance Covered:\n",
      "  Values: ['Y' 'N']\n",
      "\n",
      "Screening Type Last:\n",
      "  Values: ['PAP SMEAR' 'HPV DNA' 'VIA']\n",
      "--- Value Counts for: Patient ID ---\n",
      "Patient ID\n",
      "P0001    1\n",
      "P0002    1\n",
      "P0003    1\n",
      "P0004    1\n",
      "P0005    1\n",
      "        ..\n",
      "P0096    1\n",
      "P0097    1\n",
      "P0098    1\n",
      "P0099    1\n",
      "P0100    1\n",
      "Name: count, Length: 98, dtype: int64\n",
      "\n",
      "\n",
      "--- Value Counts for: Age ---\n",
      "Age\n",
      "35    13\n",
      "36    10\n",
      "37     9\n",
      "33     8\n",
      "34     7\n",
      "40     6\n",
      "41     5\n",
      "39     4\n",
      "18     4\n",
      "31     3\n",
      "44     3\n",
      "43     3\n",
      "32     3\n",
      "42     2\n",
      "49     2\n",
      "38     2\n",
      "26     1\n",
      "89     1\n",
      "51     1\n",
      "15     1\n",
      "52     1\n",
      "46     1\n",
      "45     1\n",
      "27     1\n",
      "65     1\n",
      "21     1\n",
      "61     1\n",
      "19     1\n",
      "86     1\n",
      "59     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "--- Value Counts for: Sexual Partners ---\n",
      "Sexual Partners\n",
      "3    34\n",
      "2    23\n",
      "1    20\n",
      "5    10\n",
      "4     8\n",
      "6     2\n",
      "9     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "--- Value Counts for: First Sexual Activity Age ---\n",
      "First Sexual Activity Age\n",
      "17    18\n",
      "18    15\n",
      "15    11\n",
      "16     9\n",
      "20     9\n",
      "21     7\n",
      "19     7\n",
      "14     3\n",
      "23     3\n",
      "26     3\n",
      "27     3\n",
      "24     2\n",
      "9      1\n",
      "25     1\n",
      "2      1\n",
      "32     1\n",
      "13     1\n",
      "29     1\n",
      "11     1\n",
      "22     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "--- Value Counts for: HPV Test Result ---\n",
      "HPV Test Result\n",
      "POSITIVE    51\n",
      "NEGATIVE    47\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "--- Value Counts for: Pap Smear Result ---\n",
      "Pap Smear Result\n",
      "N    64\n",
      "Y    34\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "--- Value Counts for: Smoking Status ---\n",
      "Smoking Status\n",
      "N    60\n",
      "Y    38\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "--- Value Counts for: STDs History ---\n",
      "STDs History\n",
      "N    50\n",
      "Y    48\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "--- Value Counts for: Region ---\n",
      "Region\n",
      "Mombasa      15\n",
      "Embu         14\n",
      "Kericho      13\n",
      "Kitale       12\n",
      "Kakamega      9\n",
      "Machakos      9\n",
      "Pumwani       7\n",
      "Moi           7\n",
      "Loitoktok     7\n",
      "Garissa       4\n",
      "Nakuru        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "--- Value Counts for: Insurance Covered ---\n",
      "Insurance Covered\n",
      "Y    52\n",
      "N    46\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "--- Value Counts for: Screening Type Last ---\n",
      "Screening Type Last\n",
      "PAP SMEAR    37\n",
      "VIA          31\n",
      "HPV DNA      30\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "--- Value Counts for: Recommended Action ---\n",
      "Recommended Action\n",
      "REPEAT PAP SMEAR IN 3 YEARS                                 30\n",
      "FOR COLPOSCOPY BIOPSY, CYTOLOGY                             16\n",
      "FOR PAP SMEAR                                               10\n",
      "FOR HPV VACCINE AND SEXUAL EDUCATION                         7\n",
      "FOR ANUAL FOLLOW UP AND PAP SMEAR IN 3 YEARS                 6\n",
      "FOR ANNUAL FOLLOW UP AND PAP SMEAR IN 3 YEARS                5\n",
      "FOR COLPOSCOPY BIOSPY, CYTOLOGY                              4\n",
      "FOR COLOSCOPY BIOSY, CYTOLOGY                                3\n",
      "REPEAT PAP SMEAR IN 3 YEARS AND FOR HPV VACCINE              2\n",
      "FOR HPV VACCINATION AND SEXUAL EDUCATION                     2\n",
      "FOR HPV VACCINE, LIFESTYLE AND SEXUAL EDUCATION              1\n",
      "FOR BIOPSY AND CYTOLOGY WITH TAH NOT RECOMMENDED             1\n",
      "FOR COLPOSCOPY BIOSY, CYTOLOGY+/- TAH                        1\n",
      "FOR COLPOSCOPY CYTOLOGY AND BIOPSY                           1\n",
      "FOR COLPOSCPY BIOPSY, CYTOLOGY                               1\n",
      "FOR LASER THERAPY                                            1\n",
      "FOR COLPOSCOPY BIOPSY AND CYTOLOGY+/- TAH                    1\n",
      "REPEAT PAP SMEAR IN 3YEARS                                   1\n",
      "FOR COLPOSCOPY BIOSPY, CYTOLOGY +/- TAH                      1\n",
      "FORCOLPOSCOPY, CYTOLOGY THEN LASER THERAPY                   1\n",
      "FOR COLPOSOCPY BIOPSY, CYTOLOGY WITH TAH NOT RECOMMENDED     1\n",
      "FOR REPEAT HPV TESTING ANNUALLY AND PAP SMEAR IN 3 YEARS     1\n",
      "FOR COLPOSCOPY BIOPSY, CYTOLOGY +/-TAH                       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "\n",
      "‚úÖ Data cleaning completed successfully!\n",
      "‚úÖ Ready for next step: Exploratory Data Analysis\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sexual Partners</th>\n",
       "      <th>First Sexual Activity Age</th>\n",
       "      <th>HPV Test Result</th>\n",
       "      <th>Pap Smear Result</th>\n",
       "      <th>Smoking Status</th>\n",
       "      <th>STDs History</th>\n",
       "      <th>Region</th>\n",
       "      <th>Insurance Covered</th>\n",
       "      <th>Screening Type Last</th>\n",
       "      <th>Recommended Action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P0001</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Pumwani</td>\n",
       "      <td>Y</td>\n",
       "      <td>PAP SMEAR</td>\n",
       "      <td>REPEAT PAP SMEAR IN 3 YEARS AND FOR HPV VACCINE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P0002</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Kakamega</td>\n",
       "      <td>N</td>\n",
       "      <td>HPV DNA</td>\n",
       "      <td>FOR HPV VACCINE AND SEXUAL EDUCATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P0003</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Machakos</td>\n",
       "      <td>N</td>\n",
       "      <td>HPV DNA</td>\n",
       "      <td>FOR HPV VACCINE AND SEXUAL EDUCATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P0004</td>\n",
       "      <td>52</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Embu</td>\n",
       "      <td>Y</td>\n",
       "      <td>HPV DNA</td>\n",
       "      <td>FOR HPV VACCINE, LIFESTYLE AND SEXUAL EDUCATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P0005</td>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Mombasa</td>\n",
       "      <td>N</td>\n",
       "      <td>HPV DNA</td>\n",
       "      <td>FOR HPV VACCINE AND SEXUAL EDUCATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>P0096</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Machakos</td>\n",
       "      <td>N</td>\n",
       "      <td>PAP SMEAR</td>\n",
       "      <td>FOR COLPOSCOPY BIOPSY, CYTOLOGY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>P0097</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Mombasa</td>\n",
       "      <td>N</td>\n",
       "      <td>PAP SMEAR</td>\n",
       "      <td>REPEAT PAP SMEAR IN 3 YEARS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>P0098</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Kericho</td>\n",
       "      <td>N</td>\n",
       "      <td>HPV DNA</td>\n",
       "      <td>FOR ANUAL FOLLOW UP AND PAP SMEAR IN 3 YEARS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>P0099</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Embu</td>\n",
       "      <td>Y</td>\n",
       "      <td>HPV DNA</td>\n",
       "      <td>FOR COLPOSCOPY BIOPSY, CYTOLOGY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>P0100</td>\n",
       "      <td>59</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Kitale</td>\n",
       "      <td>Y</td>\n",
       "      <td>HPV DNA</td>\n",
       "      <td>FOR COLPOSCOPY BIOPSY, CYTOLOGY +/-TAH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows √ó 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient ID  Age  Sexual Partners  First Sexual Activity Age  \\\n",
       "0       P0001   18                4                         15   \n",
       "1       P0002   15                1                         14   \n",
       "2       P0003   34                1                          9   \n",
       "3       P0004   52                5                         16   \n",
       "4       P0005   46                3                         21   \n",
       "..        ...  ...              ...                        ...   \n",
       "95      P0096   31                4                         16   \n",
       "96      P0097   35                5                         11   \n",
       "97      P0098   35                1                         18   \n",
       "98      P0099   31                1                         20   \n",
       "99      P0100   59                6                         22   \n",
       "\n",
       "   HPV Test Result Pap Smear Result Smoking Status STDs History    Region  \\\n",
       "0         NEGATIVE                N              N            Y   Pumwani   \n",
       "1         POSITIVE                N              Y            Y  Kakamega   \n",
       "2         POSITIVE                N              N            Y  Machakos   \n",
       "3         POSITIVE                N              Y            N      Embu   \n",
       "4         POSITIVE                N              N            N   Mombasa   \n",
       "..             ...              ...            ...          ...       ...   \n",
       "95        POSITIVE                Y              Y            N  Machakos   \n",
       "96        NEGATIVE                N              Y            N   Mombasa   \n",
       "97        POSITIVE                N              Y            N   Kericho   \n",
       "98        POSITIVE                Y              Y            N      Embu   \n",
       "99        POSITIVE                Y              N            Y    Kitale   \n",
       "\n",
       "   Insurance Covered Screening Type Last  \\\n",
       "0                  Y           PAP SMEAR   \n",
       "1                  N             HPV DNA   \n",
       "2                  N             HPV DNA   \n",
       "3                  Y             HPV DNA   \n",
       "4                  N             HPV DNA   \n",
       "..               ...                 ...   \n",
       "95                 N           PAP SMEAR   \n",
       "96                 N           PAP SMEAR   \n",
       "97                 N             HPV DNA   \n",
       "98                 Y             HPV DNA   \n",
       "99                 Y             HPV DNA   \n",
       "\n",
       "                                 Recommended Action  \n",
       "0   REPEAT PAP SMEAR IN 3 YEARS AND FOR HPV VACCINE  \n",
       "1              FOR HPV VACCINE AND SEXUAL EDUCATION  \n",
       "2              FOR HPV VACCINE AND SEXUAL EDUCATION  \n",
       "3   FOR HPV VACCINE, LIFESTYLE AND SEXUAL EDUCATION  \n",
       "4              FOR HPV VACCINE AND SEXUAL EDUCATION  \n",
       "..                                              ...  \n",
       "95                  FOR COLPOSCOPY BIOPSY, CYTOLOGY  \n",
       "96                      REPEAT PAP SMEAR IN 3 YEARS  \n",
       "97     FOR ANUAL FOLLOW UP AND PAP SMEAR IN 3 YEARS  \n",
       "98                  FOR COLPOSCOPY BIOPSY, CYTOLOGY  \n",
       "99           FOR COLPOSCOPY BIOPSY, CYTOLOGY +/-TAH  \n",
       "\n",
       "[98 rows x 12 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a copy for cleaning\n",
    "clean_df = df.copy()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"APPLYING CLEANING TRANSFORMATIONS:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "\n",
    "# 1. Remove unnecessary columns\n",
    "print(\"1. Removing unnecessary columns...\")\n",
    "columns_to_drop = ['Unnamed: 12']\n",
    "for col in columns_to_drop:\n",
    "    if col in clean_df.columns:\n",
    "        clean_df.drop(columns=[col], inplace=True)\n",
    "        print(f\"   Dropped column: {col}\")\n",
    "        \n",
    "\n",
    "# 2. Fix column name typos\n",
    "print(\"\\n2. Fixing column name typos...\")\n",
    "column_renames = {\n",
    "    'Insrance Covered': 'Insurance Covered'\n",
    "}\n",
    "clean_df.rename(columns=column_renames, inplace=True)\n",
    "for old, new in column_renames.items():\n",
    "    print(f\"   Renamed '{old}' to '{new}'\")\n",
    "    \n",
    "\n",
    "# 3. Clean HPV Test Result\n",
    "print(\"\\n3. Cleaning HPV Test Result...\")\n",
    "print(f\"   Before: {clean_df['HPV Test Result'].unique()}\")\n",
    "\n",
    "clean_df['HPV Test Result'] = clean_df['HPV Test Result'].astype(str).str.upper().str.strip()\n",
    "\n",
    "\n",
    "\n",
    "# Fix the problematic characters - using raw strings to avoid escape issues\n",
    "hpv_replacements = {\n",
    "    'NEGAGTIVE': 'NEGATIVE',\n",
    "    'POSTIVE': 'POSITIVE',\n",
    "    'NEGATVIE': 'NEGATIVE',\n",
    "    'NEGATVE': 'NEGATIVE',\n",
    "    'NEGATIVE\\n':'NEGATIVE',\n",
    "    'NEGATIVE ':'NEGATIVE',\n",
    "    ' NEGATIVE ':'NEGATIVE',\n",
    "    ' POSITIVE ':'POSITIVE',\n",
    "    'POSITIVE\\n':'POSITIVE'\n",
    "}\n",
    "\n",
    "# Handle newline characters separately\n",
    "clean_df['HPV Test Result'] = clean_df['HPV Test Result'].str.replace('\\n', '', regex=False)\n",
    "clean_df['HPV Test Result'] = clean_df['HPV Test Result'].str.replace('\\\\n', '', regex=False)\n",
    "\n",
    "# Apply other replacements\n",
    "clean_df['HPV Test Result'] = clean_df['HPV Test Result'].replace(hpv_replacements)\n",
    "\n",
    "print(f\"   After: {clean_df['HPV Test Result'].unique()}\")\n",
    "\n",
    "\n",
    "# 4. Clean and standardize Region names\n",
    "print(\"\\n4. Cleaning and standardizing Region names...\")\n",
    "print(f\"   Before: {sorted(clean_df['Region'].unique())}\")\n",
    "\n",
    "# First, strip whitespace and normalize case\n",
    "clean_df['Region'] = clean_df['Region'].astype(str).str.strip()\n",
    "\n",
    "# Create comprehensive region mapping to handle all variations\n",
    "region_mapping = {\n",
    "    # Mombasa variations\n",
    "    'mombasa': 'Mombasa',\n",
    "    'MOMBASA': 'Mombasa',\n",
    "    'Mombasa': 'Mombasa',\n",
    "    'mombasa ': 'Mombasa',\n",
    "    'Mombasa ': 'Mombasa',\n",
    "    'MOMBASA ': 'Mombasa',\n",
    "\n",
    "\n",
    "      # Pumwani variations\n",
    "    'pumwani': 'Pumwani',\n",
    "    'PUMWANI': 'Pumwani',\n",
    "    'Pumwani': 'Pumwani',\n",
    "    'pumwani ': 'Pumwani',\n",
    "    'Pumwani ': 'Pumwani',\n",
    "    'PUMWANI ': 'Pumwani',\n",
    "    \n",
    "    # Embu variations\n",
    "    'embu': 'Embu',\n",
    "    'EMBU': 'Embu',\n",
    "    'Embu': 'Embu',\n",
    "    'embu ': 'Embu',\n",
    "    'Embu ': 'Embu',\n",
    "    'EMBU ': 'Embu',\n",
    "    \n",
    "    # Kakamega variations\n",
    "    'kakamega': 'Kakamega',\n",
    "    'KAKAMEGA': 'Kakamega',\n",
    "    'Kakamega': 'Kakamega',\n",
    "    'kakamega ': 'Kakamega',\n",
    "    'Kakamega ': 'Kakamega',\n",
    "    'KAKAMEGA ': 'Kakamega',\n",
    "    \n",
    "    # Machakos variations\n",
    "    'machakos': 'Machakos',\n",
    "    'MACHAKOS': 'Machakos',\n",
    "    'Machakos': 'Machakos',\n",
    "    'machakos ': 'Machakos',\n",
    "    'Machakos ': 'Machakos',\n",
    "    'MACHAKOS ': 'Machakos',\n",
    "    \n",
    "    # Nakuru variations\n",
    "    'nakuru': 'Nakuru',\n",
    "    'NAKURU': 'Nakuru',\n",
    "    'Nakuru': 'Nakuru',\n",
    "    'NAKURU ': 'Nakuru',\n",
    "    \n",
    "    # Moi variations\n",
    "    'moi': 'Moi',\n",
    "    'MOI': 'Moi',\n",
    "    'Moi': 'Moi',\n",
    "    'moi ': 'Moi',\n",
    "    'Moi ': 'Moi',\n",
    "    'MOI ': 'Moi',\n",
    "    \n",
    "  \n",
    "  \n",
    "    # Loitoktok variations\n",
    "    'loitoktok': 'Loitoktok',\n",
    "    'LOITOKTOK': 'Loitoktok',\n",
    "    'Loitoktok': 'Loitoktok',\n",
    "    'loitoktok ': 'Loitoktok',\n",
    "    'Loitoktok ': 'Loitoktok',\n",
    "    'LOITOKTOK ': 'Loitoktok',\n",
    "    \n",
    "    # Garissa variations\n",
    "    'garissa': 'Garissa',\n",
    "    'GARISSA': 'Garissa',\n",
    "    'Garissa': 'Garissa',\n",
    "    'garissa ': 'Garissa',\n",
    "    'Garissa ': 'Garissa',\n",
    "    'GARISSA ': 'Garissa',\n",
    "    \n",
    "    # Kericho variations\n",
    "    'kericho': 'Kericho',\n",
    "    'KERICHO': 'Kericho',\n",
    "    'Kericho': 'Kericho',\n",
    "    'kericho ': 'Kericho',\n",
    "    'Kericho ': 'Kericho',\n",
    "    'KERICHO ': 'Kericho',\n",
    "    \n",
    "    # Kitale variations\n",
    "    'kitale': 'Kitale',\n",
    "    'KITALE': 'Kitale',\n",
    "    'Kitale': 'Kitale',\n",
    "    'kitale ': 'Kitale',\n",
    "    'Kitale ': 'Kitale',\n",
    "    'KITALE ': 'Kitale'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Apply region mapping\n",
    "clean_df['Region'] = clean_df['Region'].replace(region_mapping)\n",
    "\n",
    "print(f\"   After: {sorted(clean_df['Region'].unique())}\")\n",
    "\n",
    "\n",
    "# 6. Clean binary columns (Y/N values)\n",
    "print(\"\\n6. Cleaning binary columns...\")\n",
    "binary_columns = ['Pap Smear Result', 'Smoking Status', 'STDs History', 'Insurance Covered']\n",
    "for col in binary_columns:\n",
    "    if col in clean_df.columns:\n",
    "        print(f\"   Cleaning {col}\")\n",
    "        print(f\"      Before: {clean_df[col].unique()}\")\n",
    "        clean_df[col] = clean_df[col].astype(str).str.upper().str.strip()\n",
    "        print(f\"      After: {clean_df[col].unique()}\")\n",
    "        \n",
    "\n",
    "# 7. Clean screening type\n",
    "print(\"\\n7. Cleaning Screening Type Last...\")\n",
    "if 'Screening Type Last' in clean_df.columns:\n",
    "    print(f\"   Before: {clean_df['Screening Type Last'].unique()}\")\n",
    "    clean_df['Screening Type Last'] = clean_df['Screening Type Last'].astype(str).str.upper().str.strip()\n",
    "    print(f\"   After: {clean_df['Screening Type Last'].unique()}\")\n",
    "    \n",
    "\n",
    "# 8. Handle age anomalies\n",
    "print(\"\\n8. Handling age anomalies...\")\n",
    "print(f\"   Age range before: {clean_df['Age'].min()} - {clean_df['Age'].max()}\")\n",
    "clean_df['Age'] = pd.to_numeric(clean_df['Age'], errors='coerce')\n",
    "# Check for unrealistic ages\n",
    "unrealistic_ages = clean_df[(clean_df['Age'] < 10) | (clean_df['Age'] > 100)]\n",
    "if len(unrealistic_ages) > 0:\n",
    "    print(f\"   Found {len(unrealistic_ages)} unrealistic ages\")\n",
    "clean_df['Age'] = clean_df['Age'].clip(lower=10, upper=100)\n",
    "print(f\"   Age range after: {clean_df['Age'].min()} - {clean_df['Age'].max()}\")\n",
    "\n",
    "# 9. Handle First Sexual Activity Age anomalies\n",
    "print(\"\\n9. Handling First Sexual Activity Age anomalies...\")\n",
    "print(f\"   First Sexual Activity Age range before: {clean_df['First Sexual Activity Age'].min()} - {clean_df['First Sexual Activity Age'].max()}\")\n",
    "clean_df['First Sexual Activity Age'] = pd.to_numeric(clean_df['First Sexual Activity Age'], errors='coerce')\n",
    "\n",
    "# Check for impossible values (first sexual activity age > current age)\n",
    "# Identify invalid rows\n",
    "impossible_ages = clean_df['First Sexual Activity Age'] > clean_df['Age']\n",
    "\n",
    "# Print how many invalid records were found\n",
    "if impossible_ages.any():\n",
    "    print(f\"   Found {impossible_ages.sum()} records where first sexual activity age > current age\")\n",
    "\n",
    "    # Drop those rows from the DataFrame\n",
    "    clean_df = clean_df[~impossible_ages]\n",
    "\n",
    "print(\"\\n10. Handling Sexual Partners...\")\n",
    "\n",
    "# Convert to numeric, non-numeric values become NaN\n",
    "clean_df['Sexual Partners'] = pd.to_numeric(clean_df['Sexual Partners'], errors='coerce')\n",
    "\n",
    "# Show range before dropping\n",
    "print(f\"   Sexual Partners range before cleanup: {clean_df['Sexual Partners'].min()} - {clean_df['Sexual Partners'].max()}\")\n",
    "\n",
    "# Drop rows where 'Sexual Partners' is NaN\n",
    "initial_count = len(clean_df)\n",
    "clean_df = clean_df.dropna(subset=['Sexual Partners'])\n",
    "dropped_count = initial_count - len(clean_df)\n",
    "\n",
    "print(f\"   Dropped {dropped_count} rows with missing or invalid 'Sexual Partners' values.\")\n",
    "\n",
    "# 11. Final cleanup - strip all string columns\n",
    "print(\"\\n11. Final cleanup...\")\n",
    "for col in clean_df.select_dtypes(include='object').columns:\n",
    "    clean_df[col] = clean_df[col].astype(str).str.strip()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"CLEANING COMPLETE - SUMMARY:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Original shape: {df.shape}\")\n",
    "print(f\"Cleaned shape: {clean_df.shape}\")\n",
    "print(f\"Columns after cleaning: {clean_df.columns.tolist()}\")\n",
    "\n",
    "# Show cleaned data quality\n",
    "print(\"\\nCleaned data quality:\")\n",
    "print(\"1. HPV Test Result values:\", clean_df['HPV Test Result'].unique())\n",
    "print(\"2. Regions:\", sorted(clean_df['Region'].unique()))\n",
    "print(\"3. Missing values after cleaning:\")\n",
    "print(clean_df.isnull().sum())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "car15kHwLxB9"
   },
   "source": [
    "### 3.3: Final Validation and Saving of Cleaned Data\n",
    "\n",
    "After applying the data cleaning transformations, we perform a final check and save the cleaned dataset for further analysis.\n",
    "\n",
    "---\n",
    "\n",
    "#### Steps Included:\n",
    "\n",
    "1. **Save Cleaned Dataset**  \n",
    "   - Export the cleaned `DataFrame` to a new CSV file named `'cervical_cancer_cleaned.csv'`.\n",
    "   - This ensures the cleaned version is preserved and can be reused for further analysis or modeling.\n",
    "\n",
    "2. **Preview Cleaned Data**  \n",
    "   - Display the first 5 rows of the cleaned dataset using `.head()` to get a sense of the cleaned structure and content.\n",
    "\n",
    "3. **Verify Key Columns**  \n",
    "   - Use a custom `show_unique_values()` function to display unique values for critical categorical features such as:\n",
    "     - `HPV Test Result`\n",
    "     - `Region`\n",
    "     - `Pap Smear Result`\n",
    "     - `Smoking Status`\n",
    "     - `STDs History`\n",
    "     - `Insurance Covered`\n",
    "     - `Screening Type Last`\n",
    "   - This helps confirm that cleaning steps were effective in removing typos, inconsistencies, and formatting issues.\n",
    "\n",
    "4. **Column-Wise Value Counts**  \n",
    "   - The `print_all_value_counts()` function prints value counts for all columns in the dataset (including `NaNs`).\n",
    "   - This helps detect any remaining anomalies and understand the distribution of each variable, which is critical for:\n",
    "     - Identifying imbalances\n",
    "     - Planning for encoding (e.g., one-hot, label)\n",
    "     - Feature engineering\n",
    "\n",
    "---\n",
    "\n",
    "#### Conclusion:\n",
    "\n",
    "-  The cleaned dataset has been saved successfully.\n",
    "-  Categorical columns show standardized and consistent values.\n",
    "-  There is no significant presence of missing or malformed data.\n",
    "-  The dataset is now ready for the **Exploratory Data Analysis (EDA)** phase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Patient ID  Age  Sexual Partners  First Sexual Activity Age HPV Test Result  \\\n",
      "0      P0001   18                4                         15        NEGATIVE   \n",
      "1      P0002   15                1                         14        POSITIVE   \n",
      "2      P0003   34                1                          9        POSITIVE   \n",
      "3      P0004   52                5                         16        POSITIVE   \n",
      "4      P0005   46                3                         21        POSITIVE   \n",
      "\n",
      "  Pap Smear Result Smoking Status STDs History     Region Insrance Covered  \\\n",
      "0                N              N            Y   Pumwani                 Y   \n",
      "1                N              Y            Y  Kakamega                 N   \n",
      "2                N              N            Y   Machakos                N   \n",
      "3                N              Y            N      Embu                 Y   \n",
      "4                N              N            N    Mombasa                N   \n",
      "\n",
      "  Screening Type Last                               Recommended Action  \\\n",
      "0           PAP SMEAR  REPEAT PAP SMEAR IN 3 YEARS AND FOR HPV VACCINE   \n",
      "1             HPV DNA             FOR HPV VACCINE AND SEXUAL EDUCATION   \n",
      "2             HPV DNA             FOR HPV VACCINE AND SEXUAL EDUCATION   \n",
      "3             HPV DNA  FOR HPV VACCINE, LIFESTYLE AND SEXUAL EDUCATION   \n",
      "4             HPV DNA             FOR HPV VACCINE AND SEXUAL EDUCATION   \n",
      "\n",
      "  Unnamed: 12  \n",
      "0         NaN  \n",
      "1         NaN  \n",
      "2         NaN  \n",
      "3         NaN  \n",
      "4         NaN  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 13 columns):\n",
      " #   Column                     Non-Null Count  Dtype \n",
      "---  ------                     --------------  ----- \n",
      " 0   Patient ID                 100 non-null    object\n",
      " 1   Age                        100 non-null    int64 \n",
      " 2   Sexual Partners            100 non-null    int64 \n",
      " 3   First Sexual Activity Age  100 non-null    int64 \n",
      " 4   HPV Test Result            100 non-null    object\n",
      " 5   Pap Smear Result           100 non-null    object\n",
      " 6   Smoking Status             100 non-null    object\n",
      " 7   STDs History               100 non-null    object\n",
      " 8   Region                     100 non-null    object\n",
      " 9   Insrance Covered           100 non-null    object\n",
      " 10  Screening Type Last        100 non-null    object\n",
      " 11  Recommended Action         100 non-null    object\n",
      " 12  Unnamed: 12                1 non-null      object\n",
      "dtypes: int64(3), object(10)\n",
      "memory usage: 10.3+ KB\n",
      "None\n",
      "Missing values per column:\n",
      " Patient ID                    0\n",
      "Age                           0\n",
      "Sexual Partners               0\n",
      "First Sexual Activity Age     0\n",
      "HPV Test Result               0\n",
      "Pap Smear Result              0\n",
      "Smoking Status                0\n",
      "STDs History                  0\n",
      "Region                        0\n",
      "Insrance Covered              0\n",
      "Screening Type Last           0\n",
      "Recommended Action            0\n",
      "Unnamed: 12                  99\n",
      "dtype: int64\n",
      "Number of duplicate rows: 0\n",
      "--- Unique values for: Patient ID ---\n",
      "['P0001' 'P0002' 'P0003' 'P0004' 'P0005' 'P0006' 'P0007' 'P0008' 'P0009'\n",
      " 'P0010' 'P0011' 'P0012' 'P0013' 'P0014' 'P0015' 'P0016' 'P0017' 'P0018'\n",
      " 'P0019' 'P0020' 'P0021' 'P0022' 'P0023' 'P0024' 'P0025' 'P0026' 'P0027'\n",
      " 'P0028' 'P0029' 'P0030' 'P0031' 'P0032' 'P0033' 'P0034' 'P0035' 'P0036'\n",
      " 'P0037' 'P0038' 'P0039' 'P0040' 'P0041' 'P0042' 'P0043' 'P0044' 'P0045'\n",
      " 'P0046' 'P0047' 'P0048' 'P0049' 'P0050' 'P0051' 'P0052' 'P0053' 'P0054'\n",
      " 'P0055' 'P0056' 'P0057' 'P0058' 'P0059' 'P0060' 'P0061' 'P0062' 'P0063'\n",
      " 'P0064' 'P0065' 'P0066' 'P0067' 'P0068' 'P0069' 'P0070' 'P0071' 'P0072'\n",
      " 'P0073' 'P0074' 'P0075' 'P0076' 'P0077' 'P0078' 'P0079' 'P0080' 'P0081'\n",
      " 'P0082' 'P0083' 'P0084' 'P0085' 'P0086' 'P0087' 'P0088' 'P0089' 'P0090'\n",
      " 'P0091' 'P0092' 'P0093' 'P0094' 'P0095' 'P0096' 'P0097' 'P0098' 'P0099'\n",
      " 'P0100']\n",
      "\n",
      "\n",
      "--- Unique values for: Age ---\n",
      "[18 15 34 52 46 42 51 26 49 89 44 27 45 43 40 41 21 39 37 38 36 65 35 33\n",
      " 61 31 32 19 86 59]\n",
      "\n",
      "\n",
      "--- Unique values for: Sexual Partners ---\n",
      "[4 1 5 3 2 6 9]\n",
      "\n",
      "\n",
      "--- Unique values for: First Sexual Activity Age ---\n",
      "[15 14  9 16 21 23 27 26 20 17 25 18 19 24 57  2 32 13 29 11 22]\n",
      "\n",
      "\n",
      "--- Unique values for: HPV Test Result ---\n",
      "['NEGATIVE' 'POSITIVE' 'NEGAGTIVE' 'POSITIVE\\n']\n",
      "\n",
      "\n",
      "--- Unique values for: Pap Smear Result ---\n",
      "['N' 'Y']\n",
      "\n",
      "\n",
      "--- Unique values for: Smoking Status ---\n",
      "['N' 'Y']\n",
      "\n",
      "\n",
      "--- Unique values for: STDs History ---\n",
      "['Y' 'N']\n",
      "\n",
      "\n",
      "--- Unique values for: Region ---\n",
      "['Pumwani ' 'Kakamega ' 'Machakos' 'Embu ' 'Mombasa' 'NAKURU' 'Loitoktok'\n",
      " 'Moi ' 'Garissa ' 'Kitale' 'Kakamega' 'Mombasa ' 'Garissa' 'Kericho'\n",
      " 'Pumwani' 'Kericho ' 'Machakos ' 'Moi' 'Kitale ']\n",
      "\n",
      "\n",
      "--- Unique values for: Insrance Covered ---\n",
      "['Y' 'N']\n",
      "\n",
      "\n",
      "--- Unique values for: Screening Type Last ---\n",
      "['PAP SMEAR' 'HPV DNA' 'VIA']\n",
      "\n",
      "\n",
      "--- Unique values for: Recommended Action ---\n",
      "['REPEAT PAP SMEAR IN 3 YEARS AND FOR HPV VACCINE'\n",
      " 'FOR HPV VACCINE AND SEXUAL EDUCATION'\n",
      " 'FOR HPV VACCINE, LIFESTYLE AND SEXUAL EDUCATION'\n",
      " 'FOR COLPOSCOPY CYTOLOGY AND BIOPSY' 'REPEAT PAP SMEAR IN 3 YEARS'\n",
      " 'FOR COLPOSCOPY BIOSY, CYTOLOGY+/- TAH'\n",
      " 'FOR BIOPSY AND CYTOLOGY WITH TAH NOT RECOMMENDED '\n",
      " 'REPEAT PAP SMEAR IN 3 YEARS ' 'FOR COLPOSCOPY BIOPSY, CYTOLOGY '\n",
      " 'FOR ANNUAL FOLLOW UP AND PAP SMEAR IN 3 YEARS ' 'FOR PAP SMEAR'\n",
      " 'FOR PAP SMEAR ' 'FOR COLPOSCPY BIOPSY, CYTOLOGY'\n",
      " 'REPEAT PAP SMEAR IN 3YEARS' 'FOR COLPOSCOPY BIOPSY AND CYTOLOGY+/- TAH '\n",
      " 'FOR LASER THERAPY' 'FOR COLPOSCOPY BIOPSY, CYTOLOGY'\n",
      " 'FOR COLPOSCOPY BIOSPY, CYTOLOGY'\n",
      " 'FOR COLPOSCOPY BIOSPY, CYTOLOGY +/- TAH'\n",
      " 'FOR ANUAL FOLLOW UP AND PAP SMEAR IN 3 YEARS'\n",
      " 'FOR COLPOSCOPY BIOPSY, CYTOLOGY +/- TAH'\n",
      " 'FOR HPV VACCINATION AND SEXUAL EDUCATION'\n",
      " 'FOR COLOSCOPY BIOSY, CYTOLOGY'\n",
      " 'FORCOLPOSCOPY, CYTOLOGY THEN LASER THERAPY'\n",
      " 'FOR COLPOSOCPY BIOPSY, CYTOLOGY WITH TAH NOT RECOMMENDED'\n",
      " 'FOR REPEAT HPV TESTING ANNUALLY AND PAP SMEAR IN 3 YEARS'\n",
      " 'FOR COLPOSCOPY BIOPSY, CYTOLOGY +/-TAH']\n",
      "\n",
      "\n",
      "--- Unique values for: Unnamed: 12 ---\n",
      "[nan ' ']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save cleaned data\n",
    "clean_df.to_csv('cervical_cancer_cleaned.csv', index=False)\n",
    "print(\"\\nCleaned data saved as 'cervical_cancer_cleaned.csv'\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nFirst 5 rows of cleaned data:\")\n",
    "print(clean_df.head())\n",
    "\n",
    "# Show unique values for key columns to verify cleaning\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"VERIFICATION OF CLEANED DATA:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "def show_unique_values(df, columns):\n",
    "    for col in columns:\n",
    "        if col in df.columns:\n",
    "            print(f\"\\n{col}:\")\n",
    "            unique_vals = df[col].unique()\n",
    "            if len(unique_vals) <= 10:\n",
    "                print(f\"  Values: {unique_vals}\")\n",
    "            else:\n",
    "                print(f\"  Total unique values: {len(unique_vals)}\")\n",
    "                print(f\"  Sample: {unique_vals[:10]}\")\n",
    "\n",
    "verification_columns = ['HPV Test Result', 'Region', 'Pap Smear Result', 'Smoking Status', \n",
    "                       'STDs History', 'Insurance Covered', 'Screening Type Last']\n",
    "show_unique_values(clean_df, verification_columns)\n",
    "\n",
    "\n",
    "#Preview results\n",
    "def print_all_value_counts(df):\n",
    "    for column in df.columns:\n",
    "        print(f\"--- Value Counts for: {column} ---\")\n",
    "        print(df[column].value_counts(dropna=False))  # include NaNs in the count\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Print unique values to check validity & quality:\n",
    "print_all_value_counts(clean_df)\n",
    "\n",
    "print(\"\\n‚úÖ Data cleaning completed successfully!\")\n",
    "print(\"‚úÖ Ready for next step: Exploratory Data Analysis\")\n",
    "clean_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "car15kHwLxB9"
   },
   "source": [
    "### 3.4: Advanced Cleaning of \"Recommended Action\" Column using Fuzzy Matching and Keyword Rules\n",
    "\n",
    "This step addresses one of the most inconsistent and typo-ridden columns in the dataset ‚Äî `Recommended Action`. It applies a structured, rule-based fuzzy matching approach to standardize all entries against a predefined list of **canonical (correct) values**.\n",
    "\n",
    "---\n",
    "\n",
    "#### Step Breakdown:\n",
    "\n",
    "1. **Define Canonical Values**\n",
    "   - These are the 100% correct, clean strings that we expect the column to match.\n",
    "   - They cover all valid and normalized options like:\n",
    "     - `\"FOR COLPOSCOPY, BIOPSY, AND CYTOLOGY\"`\n",
    "     - `\"REPEAT PAP SMEAR IN 3 YEARS\"`\n",
    "     - `\"FOR HPV VACCINE, LIFESTYLE, AND SEXUAL EDUCATION\"`\n",
    "\n",
    "2. **Set up Typo Mapping**\n",
    "   - Common misspellings like:\n",
    "     - `\"BIOSPY\"` ‚Üí `\"BIOPSY\"`\n",
    "     - `\"COLOSCOPY\"` ‚Üí `\"COLPOSCOPY\"`\n",
    "     - `\"ANUAL\"` ‚Üí `\"ANNUAL\"`\n",
    "   - These are corrected **before matching** to improve accuracy.\n",
    "\n",
    "3. **Strict Fuzzy Matching Function**\n",
    "   - A custom function `clean_column_strict()` is used to:\n",
    "     - Standardize text to uppercase.\n",
    "     - Correct known typos.\n",
    "     - Extract and match **critical keywords** (like `HPV`, `CYTOLOGY`, `BIOPSY`, etc.).\n",
    "     - Use **fuzzy string matching** (via `fuzzywuzzy`) to find the closest canonical value.\n",
    "     - Ensure matches are **only accepted** if the keywords from the raw and canonical string are identical. This prevents incorrect but similar matches.\n",
    "\n",
    "4. **Apply Cleaning**\n",
    "   - The function is called with the column name, canonical list, and threshold (80% match confidence).\n",
    "   - It returns:\n",
    "     - A cleaned version of the column\n",
    "     - A confidence score\n",
    "     - A status flag (`OK` or `NEEDS MANUAL REVIEW`)\n",
    "\n",
    "5. **Manual Review Report**\n",
    "   - Any rows where the fuzzy match is below the confidence threshold (or keyword sets don‚Äôt match) are flagged for **manual review**.\n",
    "\n",
    "6. **Save the Final Data**\n",
    "   - The updated `DataFrame` with cleaned `Recommended Action` is exported to an Excel file:  \n",
    "      `final_cleaned.xlsx`\n",
    "\n",
    "---\n",
    "\n",
    "#### Why This Approach?\n",
    "\n",
    "- Fuzzy matching alone can lead to incorrect substitutions when two strings are similar but mean different things.\n",
    "- By combining **keyword presence checks** and **typo correction**, we ensure data is matched **both intelligently and safely**.\n",
    "- This is particularly useful in messy real-world healthcare data.\n",
    "\n",
    "---\n",
    "\n",
    "#### Outcome\n",
    "\n",
    "- The `Recommended Action` column is now fully standardized.\n",
    "- Any unmatched or low-confidence rows are clearly flagged for manual inspection.\n",
    "- The dataset is fully cleaned and saved, ready for Exploratory Data Analysis (EDA).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Patient ID  Age  Sexual Partners  First Sexual Activity Age HPV Test Result  \\\n",
      "0      P0001   18                4                         15        NEGATIVE   \n",
      "1      P0002   15                1                         14        POSITIVE   \n",
      "2      P0003   34                1                          9        POSITIVE   \n",
      "3      P0004   52                5                         16        POSITIVE   \n",
      "4      P0005   46                3                         21        POSITIVE   \n",
      "\n",
      "  Pap Smear Result Smoking Status STDs History     Region Insrance Covered  \\\n",
      "0                N              N            Y   Pumwani                 Y   \n",
      "1                N              Y            Y  Kakamega                 N   \n",
      "2                N              N            Y   Machakos                N   \n",
      "3                N              Y            N      Embu                 Y   \n",
      "4                N              N            N    Mombasa                N   \n",
      "\n",
      "  Screening Type Last                               Recommended Action  \\\n",
      "0           PAP SMEAR  REPEAT PAP SMEAR IN 3 YEARS AND FOR HPV VACCINE   \n",
      "1             HPV DNA             FOR HPV VACCINE AND SEXUAL EDUCATION   \n",
      "2             HPV DNA             FOR HPV VACCINE AND SEXUAL EDUCATION   \n",
      "3             HPV DNA  FOR HPV VACCINE, LIFESTYLE AND SEXUAL EDUCATION   \n",
      "4             HPV DNA             FOR HPV VACCINE AND SEXUAL EDUCATION   \n",
      "\n",
      "  Unnamed: 12  \n",
      "0         NaN  \n",
      "1         NaN  \n",
      "2         NaN  \n",
      "3         NaN  \n",
      "4         NaN  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 13 columns):\n",
      " #   Column                     Non-Null Count  Dtype \n",
      "---  ------                     --------------  ----- \n",
      " 0   Patient ID                 100 non-null    object\n",
      " 1   Age                        100 non-null    int64 \n",
      " 2   Sexual Partners            100 non-null    int64 \n",
      " 3   First Sexual Activity Age  100 non-null    int64 \n",
      " 4   HPV Test Result            100 non-null    object\n",
      " 5   Pap Smear Result           100 non-null    object\n",
      " 6   Smoking Status             100 non-null    object\n",
      " 7   STDs History               100 non-null    object\n",
      " 8   Region                     100 non-null    object\n",
      " 9   Insrance Covered           100 non-null    object\n",
      " 10  Screening Type Last        100 non-null    object\n",
      " 11  Recommended Action         100 non-null    object\n",
      " 12  Unnamed: 12                1 non-null      object\n",
      "dtypes: int64(3), object(10)\n",
      "memory usage: 10.3+ KB\n",
      "None\n",
      "Missing values per column:\n",
      " Patient ID                    0\n",
      "Age                           0\n",
      "Sexual Partners               0\n",
      "First Sexual Activity Age     0\n",
      "HPV Test Result               0\n",
      "Pap Smear Result              0\n",
      "Smoking Status                0\n",
      "STDs History                  0\n",
      "Region                        0\n",
      "Insrance Covered              0\n",
      "Screening Type Last           0\n",
      "Recommended Action            0\n",
      "Unnamed: 12                  99\n",
      "dtype: int64\n",
      "Number of duplicate rows: 0\n",
      "--- Unique values for: Patient ID ---\n",
      "['P0001' 'P0002' 'P0003' 'P0004' 'P0005' 'P0006' 'P0007' 'P0008' 'P0009'\n",
      " 'P0010' 'P0011' 'P0012' 'P0013' 'P0014' 'P0015' 'P0016' 'P0017' 'P0018'\n",
      " 'P0019' 'P0020' 'P0021' 'P0022' 'P0023' 'P0024' 'P0025' 'P0026' 'P0027'\n",
      " 'P0028' 'P0029' 'P0030' 'P0031' 'P0032' 'P0033' 'P0034' 'P0035' 'P0036'\n",
      " 'P0037' 'P0038' 'P0039' 'P0040' 'P0041' 'P0042' 'P0043' 'P0044' 'P0045'\n",
      " 'P0046' 'P0047' 'P0048' 'P0049' 'P0050' 'P0051' 'P0052' 'P0053' 'P0054'\n",
      " 'P0055' 'P0056' 'P0057' 'P0058' 'P0059' 'P0060' 'P0061' 'P0062' 'P0063'\n",
      " 'P0064' 'P0065' 'P0066' 'P0067' 'P0068' 'P0069' 'P0070' 'P0071' 'P0072'\n",
      " 'P0073' 'P0074' 'P0075' 'P0076' 'P0077' 'P0078' 'P0079' 'P0080' 'P0081'\n",
      " 'P0082' 'P0083' 'P0084' 'P0085' 'P0086' 'P0087' 'P0088' 'P0089' 'P0090'\n",
      " 'P0091' 'P0092' 'P0093' 'P0094' 'P0095' 'P0096' 'P0097' 'P0098' 'P0099'\n",
      " 'P0100']\n",
      "\n",
      "\n",
      "--- Unique values for: Age ---\n",
      "[18 15 34 52 46 42 51 26 49 89 44 27 45 43 40 41 21 39 37 38 36 65 35 33\n",
      " 61 31 32 19 86 59]\n",
      "\n",
      "\n",
      "--- Unique values for: Sexual Partners ---\n",
      "[4 1 5 3 2 6 9]\n",
      "\n",
      "\n",
      "--- Unique values for: First Sexual Activity Age ---\n",
      "[15 14  9 16 21 23 27 26 20 17 25 18 19 24 57  2 32 13 29 11 22]\n",
      "\n",
      "\n",
      "--- Unique values for: HPV Test Result ---\n",
      "['NEGATIVE' 'POSITIVE' 'NEGAGTIVE' 'POSITIVE\\n']\n",
      "\n",
      "\n",
      "--- Unique values for: Pap Smear Result ---\n",
      "['N' 'Y']\n",
      "\n",
      "\n",
      "--- Unique values for: Smoking Status ---\n",
      "['N' 'Y']\n",
      "\n",
      "\n",
      "--- Unique values for: STDs History ---\n",
      "['Y' 'N']\n",
      "\n",
      "\n",
      "--- Unique values for: Region ---\n",
      "['Pumwani ' 'Kakamega ' 'Machakos' 'Embu ' 'Mombasa' 'NAKURU' 'Loitoktok'\n",
      " 'Moi ' 'Garissa ' 'Kitale' 'Kakamega' 'Mombasa ' 'Garissa' 'Kericho'\n",
      " 'Pumwani' 'Kericho ' 'Machakos ' 'Moi' 'Kitale ']\n",
      "\n",
      "\n",
      "--- Unique values for: Insrance Covered ---\n",
      "['Y' 'N']\n",
      "\n",
      "\n",
      "--- Unique values for: Screening Type Last ---\n",
      "['PAP SMEAR' 'HPV DNA' 'VIA']\n",
      "\n",
      "\n",
      "--- Unique values for: Recommended Action ---\n",
      "['REPEAT PAP SMEAR IN 3 YEARS AND FOR HPV VACCINE'\n",
      " 'FOR HPV VACCINE AND SEXUAL EDUCATION'\n",
      " 'FOR HPV VACCINE, LIFESTYLE AND SEXUAL EDUCATION'\n",
      " 'FOR COLPOSCOPY CYTOLOGY AND BIOPSY' 'REPEAT PAP SMEAR IN 3 YEARS'\n",
      " 'FOR COLPOSCOPY BIOSY, CYTOLOGY+/- TAH'\n",
      " 'FOR BIOPSY AND CYTOLOGY WITH TAH NOT RECOMMENDED '\n",
      " 'REPEAT PAP SMEAR IN 3 YEARS ' 'FOR COLPOSCOPY BIOPSY, CYTOLOGY '\n",
      " 'FOR ANNUAL FOLLOW UP AND PAP SMEAR IN 3 YEARS ' 'FOR PAP SMEAR'\n",
      " 'FOR PAP SMEAR ' 'FOR COLPOSCPY BIOPSY, CYTOLOGY'\n",
      " 'REPEAT PAP SMEAR IN 3YEARS' 'FOR COLPOSCOPY BIOPSY AND CYTOLOGY+/- TAH '\n",
      " 'FOR LASER THERAPY' 'FOR COLPOSCOPY BIOPSY, CYTOLOGY'\n",
      " 'FOR COLPOSCOPY BIOSPY, CYTOLOGY'\n",
      " 'FOR COLPOSCOPY BIOSPY, CYTOLOGY +/- TAH'\n",
      " 'FOR ANUAL FOLLOW UP AND PAP SMEAR IN 3 YEARS'\n",
      " 'FOR COLPOSCOPY BIOPSY, CYTOLOGY +/- TAH'\n",
      " 'FOR HPV VACCINATION AND SEXUAL EDUCATION'\n",
      " 'FOR COLOSCOPY BIOSY, CYTOLOGY'\n",
      " 'FORCOLPOSCOPY, CYTOLOGY THEN LASER THERAPY'\n",
      " 'FOR COLPOSOCPY BIOPSY, CYTOLOGY WITH TAH NOT RECOMMENDED'\n",
      " 'FOR REPEAT HPV TESTING ANNUALLY AND PAP SMEAR IN 3 YEARS'\n",
      " 'FOR COLPOSCOPY BIOPSY, CYTOLOGY +/-TAH']\n",
      "\n",
      "\n",
      "--- Unique values for: Unnamed: 12 ---\n",
      "[nan ' ']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This list contains the final, correct values to use.\n",
    "canonical_values = [\n",
    "    \"REPEAT PAP SMEAR IN 3 YEARS\",\n",
    "    \"FOR COLPOSCOPY, BIOPSY, AND CYTOLOGY\",\n",
    "    \"FOR PAP SMEAR\",\n",
    "    \"FOR HPV VACCINE AND SEXUAL EDUCATION\",\n",
    "    \"FOR ANNUAL FOLLOW-UP AND PAP SMEAR IN 3 YEARS\",\n",
    "    \"REPEAT PAP SMEAR IN 3 YEARS AND FOR HPV VACCINE\",\n",
    "    \"FOR COLPOSCOPY, BIOPSY, AND CYTOLOGY (TAH NOT RECOMMENDED)\",\n",
    "    \"FOR BIOPSY AND CYTOLOGY (TAH NOT RECOMMENDED)\",\n",
    "    \"FOR HPV VACCINE, LIFESTYLE, AND SEXUAL EDUCATION\",\n",
    "    \"FOR COLPOSCOPY, BIOPSY, CYTOLOGY +/- TAH\",\n",
    "    \"FOR COLPOSCOPY, CYTOLOGY, THEN LASER THERAPY\",\n",
    "    \"FOR REPEAT HPV TESTING ANNUALLY AND PAP SMEAR IN 3 YEARS\",\n",
    "    \"FOR LASER THERAPY\"\n",
    "]\n",
    "\n",
    "# --- 2. Configuration for the Cleaner ---\n",
    "TYPO_MAP = {\n",
    "    'COLPOSOCPY': 'COLPOSCOPY', 'COLPOSCPY': 'COLPOSCOPY', 'COLOSCOPY': 'COLPOSCOPY',\n",
    "    'BIOSPY': 'BIOPSY', 'BIOSY': 'BIOPSY', 'ANUAL': 'ANNUAL', 'VACCINATION': 'VACCINE'\n",
    "}\n",
    "CRITICAL_KEYWORDS = {\n",
    "    'COLPOSCOPY', 'BIOPSY', 'CYTOLOGY', 'TAH', 'HPV', 'LASER', 'LIFESTYLE', 'ANNUALLY'\n",
    "}\n",
    "\n",
    "# --- 3. The Definitive Data Cleaning Function ---\n",
    "def clean_column_strict(df, column_to_clean, canonical_list, threshold=80):\n",
    "    \"\"\"\n",
    "    Cleans a DataFrame column using fuzzy matching combined with a STRICT keyword set equality rule.\n",
    "    \"\"\"\n",
    "    if column_to_clean not in df.columns:\n",
    "        raise ValueError(f\"Column '{column_to_clean}' not found in the DataFrame.\")\n",
    "\n",
    "    def preprocess_and_get_keywords(text, typo_map):\n",
    "        if not isinstance(text, str): return \"\", set()\n",
    "        # Standardize to uppercase and correct typos\n",
    "        processed_text = text.upper()\n",
    "        for wrong, right in typo_map.items():\n",
    "            processed_text = re.sub(r'\\b' + wrong + r'\\b', right, processed_text)\n",
    "        \n",
    "        # Extract the set of critical keywords\n",
    "        keywords = {word for word in CRITICAL_KEYWORDS if word in processed_text}\n",
    "        return processed_text, keywords\n",
    "\n",
    "    cleaned_data = []\n",
    "\n",
    "    # Pre-calculate keywords for the canonical list for efficiency\n",
    "    canonical_keywords = {val: preprocess_and_get_keywords(val, {})[1] for val in canonical_list}\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        raw_string = row[column_to_clean]\n",
    "        \n",
    "        if not isinstance(raw_string, str) or not raw_string.strip():\n",
    "            cleaned_data.append((raw_string, 0, 'NO_DATA_PROVIDED'))\n",
    "            continue\n",
    "\n",
    "        processed_string, original_keywords = preprocess_and_get_keywords(raw_string, TYPO_MAP)\n",
    "        \n",
    "        # Get the top few potential matches instead of just one\n",
    "        top_matches = process.extract(processed_string, canonical_list, limit=5)\n",
    "\n",
    "        best_valid_match = None\n",
    "        \n",
    "        for potential_match, score in top_matches:\n",
    "            if score < threshold:\n",
    "                break # No need to check further if scores are too low\n",
    "\n",
    "            # The CRITICAL check: The keyword sets must be identical\n",
    "            if original_keywords == canonical_keywords[potential_match]:\n",
    "                best_valid_match = (potential_match, score)\n",
    "                break # Found the best possible valid match, stop searching\n",
    "\n",
    "        if best_valid_match:\n",
    "            final_value, final_score = best_valid_match\n",
    "            status = 'OK'\n",
    "        else:\n",
    "            final_value = raw_string\n",
    "            final_score = top_matches[0][1] if top_matches else 0 # Show score of best (but invalid) match\n",
    "            status = 'NEEDS MANUAL REVIEW'\n",
    "\n",
    "        cleaned_data.append((final_value, final_score, status))\n",
    "\n",
    "    result_df = pd.DataFrame(cleaned_data, index=df.index, columns=[f'{column_to_clean}_Cleaned', f'{column_to_clean}_Confidence', f'{column_to_clean}_Status'])\n",
    "    return df.join(result_df)\n",
    "\n",
    "# main_df = pd.DataFrame(data, columns=['Recommended Action'])\n",
    "\n",
    "\n",
    "# 2. Call the function to clean the specified column\n",
    "# You provide your DataFrame, the column name, the list of correct values, and the confidence threshold.\n",
    "final_df = clean_column_strict(\n",
    "    df=clean_df,\n",
    "    column_to_clean='Recommended Action',\n",
    "    canonical_list=canonical_values,\n",
    "    threshold=80\n",
    ")\n",
    "\n",
    "# 3. Display the results\n",
    "print(\"--- Full Data Cleaning Results ---\")\n",
    "# Use .to_string() to ensure all columns are displayed without truncation\n",
    "#print(final_df.to_string())\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# 4. Display only the rows that need human attention\n",
    "print(\"--- Actions Flagged for Manual Review (Confidence < 80%) ---\")\n",
    "manual_review_df = final_df[final_df['Recommended Action_Status'] == 'NEEDS MANUAL REVIEW']\n",
    "\n",
    "if manual_review_df.empty:\n",
    "    print(\"No actions require manual review. All items met the 80% confidence threshold.\")\n",
    "else:\n",
    "    print(manual_review_df[['Recommended Action', 'Recommended Action_Cleaned', 'Recommended Action_Confidence']].to_string())\n",
    "\n",
    "\n",
    "print(f\"   After: {final_df['Recommended Action_Cleaned'].unique()}\")\n",
    "final_df\n",
    "final_df.to_excel(\"final_cleaned.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "car15kHwLxB9"
   },
   "source": [
    "###  3.5: Final Cleanup ‚Äì Dropping Redundant Columns\n",
    "\n",
    "In this step, we perform a final cleanup to remove columns that are no longer needed for analysis or modeling. These include metadata and intermediate columns from previous cleaning stages.\n",
    "\n",
    "---\n",
    "\n",
    "####  Breakdown:\n",
    "\n",
    "1. **Load Final Cleaned Data**\n",
    "   - Reads the Excel file `final_cleaned.xlsx`, which contains the dataset with standardized `Recommended Action` and other cleaned columns.\n",
    "\n",
    "2. **Remove Redundant Columns**\n",
    "   - The following columns are dropped:\n",
    "     - `'Recommended Action'`: Original raw column (replaced by the cleaned version).\n",
    "     - `'Recommended Action_Confidence'`: Confidence score from the fuzzy matching process (used for diagnostics).\n",
    "     - `'Recommended Action_Status'`: Flag for manual review (used during cleaning).\n",
    "     - `'Patient ID'`: Identifier column not relevant to statistical or ML modeling.\n",
    "\n",
    "3. **Save the Resulting Dataset**\n",
    "   - Exports the trimmed dataset as `data_final.xlsx`, which now contains only relevant and clean features for **Exploratory Data Analysis (EDA)** or modeling.\n",
    "\n",
    "---\n",
    "\n",
    " This marks the completion of the data cleaning phase.  \n",
    " The next step is **Exploratory Data Analysis (EDA)** to understand the structure, relationships, and patterns in the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Full Data Cleaning Results ---\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Actions Flagged for Manual Review (Confidence < 80%) ---\n",
      "No actions require manual review. All items met the 80% confidence threshold.\n",
      "   After: ['REPEAT PAP SMEAR IN 3 YEARS AND FOR HPV VACCINE'\n",
      " 'FOR HPV VACCINE AND SEXUAL EDUCATION'\n",
      " 'FOR HPV VACCINE, LIFESTYLE, AND SEXUAL EDUCATION'\n",
      " 'FOR COLPOSCOPY, BIOPSY, AND CYTOLOGY' 'REPEAT PAP SMEAR IN 3 YEARS'\n",
      " 'FOR COLPOSCOPY, BIOPSY, CYTOLOGY +/- TAH'\n",
      " 'FOR BIOPSY AND CYTOLOGY (TAH NOT RECOMMENDED)'\n",
      " 'FOR ANNUAL FOLLOW-UP AND PAP SMEAR IN 3 YEARS' 'FOR PAP SMEAR'\n",
      " 'FOR COLPOSCOPY, BIOPSY, AND CYTOLOGY (TAH NOT RECOMMENDED)'\n",
      " 'FOR LASER THERAPY' 'FOR COLPOSCOPY, CYTOLOGY, THEN LASER THERAPY'\n",
      " 'FOR REPEAT HPV TESTING ANNUALLY AND PAP SMEAR IN 3 YEARS']\n"
     ]
    }
   ],
   "source": [
    "#Load the file\n",
    "file_path = 'final_cleaned.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "print(\"1. Removing unnecessary columns...\")\n",
    "columns_to_drop = ['Recommended Action','Recommended Action_Confidence','Recommended Action_Status','Patient ID']\n",
    "for col in columns_to_drop:\n",
    "    if col in df.columns:\n",
    "        df.drop(columns=[col], inplace=True)\n",
    "df.to_excel('data_final.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDDBz22rCFSX"
   },
   "source": [
    "\n",
    "# STEP 1: STANDARDIZING TARGET COLUMN VALUES(RECOMMENDATION)\n",
    "## Goal: Balance the data on the target column so that the model is not biased to a certain recommendation.\n",
    "\n",
    "We'll do:\n",
    "\n",
    "* Define our cannonical values.\n",
    "\n",
    "* Using confidence score and fuzzy matching for the standardization.Values that do not meet confoidence score are flagged for manual checking\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Full Data Cleaning Results ---\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Actions Flagged for Manual Review (Confidence < 80%) ---\n",
      "No actions require manual review. All items met the 80% confidence threshold.\n",
      "   After: ['REPEAT PAP SMEAR IN 3 YEARS AND FOR HPV VACCINE'\n",
      " 'FOR HPV VACCINE AND SEXUAL EDUCATION'\n",
      " 'FOR HPV VACCINE, LIFESTYLE, AND SEXUAL EDUCATION'\n",
      " 'FOR COLPOSCOPY, BIOPSY, AND CYTOLOGY' 'REPEAT PAP SMEAR IN 3 YEARS'\n",
      " 'FOR COLPOSCOPY, BIOPSY, CYTOLOGY +/- TAH'\n",
      " 'FOR BIOPSY AND CYTOLOGY (TAH NOT RECOMMENDED)'\n",
      " 'FOR ANNUAL FOLLOW-UP AND PAP SMEAR IN 3 YEARS' 'FOR PAP SMEAR'\n",
      " 'FOR COLPOSCOPY, BIOPSY, AND CYTOLOGY (TAH NOT RECOMMENDED)'\n",
      " 'FOR LASER THERAPY' 'FOR COLPOSCOPY, CYTOLOGY, THEN LASER THERAPY'\n",
      " 'FOR REPEAT HPV TESTING ANNUALLY AND PAP SMEAR IN 3 YEARS']\n"
     ]
    }
   ],
   "source": [
    "# This list contains the final, correct values to use.\n",
    "canonical_values = [\n",
    "    \"REPEAT PAP SMEAR IN 3 YEARS\",\n",
    "    \"FOR COLPOSCOPY, BIOPSY, AND CYTOLOGY\",\n",
    "    \"FOR PAP SMEAR\",\n",
    "    \"FOR HPV VACCINE AND SEXUAL EDUCATION\",\n",
    "    \"FOR ANNUAL FOLLOW-UP AND PAP SMEAR IN 3 YEARS\",\n",
    "    \"REPEAT PAP SMEAR IN 3 YEARS AND FOR HPV VACCINE\",\n",
    "    \"FOR COLPOSCOPY, BIOPSY, AND CYTOLOGY (TAH NOT RECOMMENDED)\",\n",
    "    \"FOR BIOPSY AND CYTOLOGY (TAH NOT RECOMMENDED)\",\n",
    "    \"FOR HPV VACCINE, LIFESTYLE, AND SEXUAL EDUCATION\",\n",
    "    \"FOR COLPOSCOPY, BIOPSY, CYTOLOGY +/- TAH\",\n",
    "    \"FOR COLPOSCOPY, CYTOLOGY, THEN LASER THERAPY\",\n",
    "    \"FOR REPEAT HPV TESTING ANNUALLY AND PAP SMEAR IN 3 YEARS\",\n",
    "    \"FOR LASER THERAPY\"\n",
    "]\n",
    "\n",
    "# --- 2. Configuration for the Cleaner ---\n",
    "TYPO_MAP = {\n",
    "    'COLPOSOCPY': 'COLPOSCOPY', 'COLPOSCPY': 'COLPOSCOPY', 'COLOSCOPY': 'COLPOSCOPY',\n",
    "    'BIOSPY': 'BIOPSY', 'BIOSY': 'BIOPSY', 'ANUAL': 'ANNUAL', 'VACCINATION': 'VACCINE'\n",
    "}\n",
    "CRITICAL_KEYWORDS = {\n",
    "    'COLPOSCOPY', 'BIOPSY', 'CYTOLOGY', 'TAH', 'HPV', 'LASER', 'LIFESTYLE', 'ANNUALLY'\n",
    "}\n",
    "\n",
    "# --- 3. The Definitive Data Cleaning Function ---\n",
    "def clean_column_strict(df, column_to_clean, canonical_list, threshold=80):\n",
    "    \"\"\"\n",
    "    Cleans a DataFrame column using fuzzy matching combined with a STRICT keyword set equality rule.\n",
    "    \"\"\"\n",
    "    if column_to_clean not in df.columns:\n",
    "        raise ValueError(f\"Column '{column_to_clean}' not found in the DataFrame.\")\n",
    "\n",
    "    def preprocess_and_get_keywords(text, typo_map):\n",
    "        if not isinstance(text, str): return \"\", set()\n",
    "        # Standardize to uppercase and correct typos\n",
    "        processed_text = text.upper()\n",
    "        for wrong, right in typo_map.items():\n",
    "            processed_text = re.sub(r'\\b' + wrong + r'\\b', right, processed_text)\n",
    "        \n",
    "        # Extract the set of critical keywords\n",
    "        keywords = {word for word in CRITICAL_KEYWORDS if word in processed_text}\n",
    "        return processed_text, keywords\n",
    "\n",
    "    cleaned_data = []\n",
    "\n",
    "    # Pre-calculate keywords for the canonical list for efficiency\n",
    "    canonical_keywords = {val: preprocess_and_get_keywords(val, {})[1] for val in canonical_list}\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        raw_string = row[column_to_clean]\n",
    "        \n",
    "        if not isinstance(raw_string, str) or not raw_string.strip():\n",
    "            cleaned_data.append((raw_string, 0, 'NO_DATA_PROVIDED'))\n",
    "            continue\n",
    "\n",
    "        processed_string, original_keywords = preprocess_and_get_keywords(raw_string, TYPO_MAP)\n",
    "        \n",
    "        # Get the top few potential matches instead of just one\n",
    "        top_matches = process.extract(processed_string, canonical_list, limit=5)\n",
    "\n",
    "        best_valid_match = None\n",
    "        \n",
    "        for potential_match, score in top_matches:\n",
    "            if score < threshold:\n",
    "                break # No need to check further if scores are too low\n",
    "\n",
    "            # The CRITICAL check: The keyword sets must be identical\n",
    "            if original_keywords == canonical_keywords[potential_match]:\n",
    "                best_valid_match = (potential_match, score)\n",
    "                break # Found the best possible valid match, stop searching\n",
    "\n",
    "        if best_valid_match:\n",
    "            final_value, final_score = best_valid_match\n",
    "            status = 'OK'\n",
    "        else:\n",
    "            final_value = raw_string\n",
    "            final_score = top_matches[0][1] if top_matches else 0 # Show score of best (but invalid) match\n",
    "            status = 'NEEDS MANUAL REVIEW'\n",
    "\n",
    "        cleaned_data.append((final_value, final_score, status))\n",
    "\n",
    "    result_df = pd.DataFrame(cleaned_data, index=df.index, columns=[f'{column_to_clean}_Cleaned', f'{column_to_clean}_Confidence', f'{column_to_clean}_Status'])\n",
    "    return df.join(result_df)\n",
    "\n",
    "# main_df = pd.DataFrame(data, columns=['Recommended Action'])\n",
    "\n",
    "\n",
    "# 2. Call the function to clean the specified column\n",
    "# You provide your DataFrame, the column name, the list of correct values, and the confidence threshold.\n",
    "final_df = clean_column_strict(\n",
    "    df=clean_df,\n",
    "    column_to_clean='Recommended Action',\n",
    "    canonical_list=canonical_values,\n",
    "    threshold=80\n",
    ")\n",
    "\n",
    "# 3. Display the results\n",
    "print(\"--- Full Data Cleaning Results ---\")\n",
    "# Use .to_string() to ensure all columns are displayed without truncation\n",
    "#print(final_df.to_string())\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# 4. Display only the rows that need human attention\n",
    "print(\"--- Actions Flagged for Manual Review (Confidence < 80%) ---\")\n",
    "manual_review_df = final_df[final_df['Recommended Action_Status'] == 'NEEDS MANUAL REVIEW']\n",
    "\n",
    "if manual_review_df.empty:\n",
    "    print(\"No actions require manual review. All items met the 80% confidence threshold.\")\n",
    "else:\n",
    "    print(manual_review_df[['Recommended Action', 'Recommended Action_Cleaned', 'Recommended Action_Confidence']].to_string())\n",
    "\n",
    "\n",
    "print(f\"   After: {final_df['Recommended Action_Cleaned'].unique()}\")\n",
    "final_df\n",
    "final_df.to_excel(\"final_cleaned.xlsx\",index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Removing unnecessary columns...\n"
     ]
    }
   ],
   "source": [
    "#Load the file\n",
    "file_path = 'final_cleaned.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "print(\"1. Removing unnecessary columns...\")\n",
    "columns_to_drop = ['Recommended Action','Recommended Action_Confidence','Recommended Action_Status','Patient ID']\n",
    "for col in columns_to_drop:\n",
    "    if col in df.columns:\n",
    "        df.drop(columns=[col], inplace=True)\n",
    "df.to_excel('data_final.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDDBz22rCFSX"
   },
   "source": [
    "\n",
    "# STEP 2: DATA SPLITTING\n",
    "## Goal:  Split the dataset to get the portion that goes into training and the portion that goes into testing\n",
    "\n",
    "We'll do:\n",
    "\n",
    "* Pre-split Fix.We notice that in the dataset,some critical columns have only one instance of it.Here we will use simple oversampling by manually duplicating these classes with only one instance.\n",
    "* stratified splitting on the data to ensure equal amount of percentage goes into both training and testing.\n",
    "* hot-encode remaining columns\n",
    "  # STEP 2B\n",
    "  ## Goal :Define class weights based on domain knowledge(Medical) to be fed into the data for use during training .\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 3. Label Encoding Target Column (y) ---\n",
      "Target column converted to numeric labels.\n",
      "------------------------------------------------------------\n",
      "\n",
      "--- 4. Checking for and Fixing Single-Instance Classes ---\n",
      "Found 6 classes with only one sample. Duplicating them...\n",
      "Shape before fix: (98, 10). Shape after fix: (104, 10).\n",
      "------------------------------------------------------------\n",
      "\n",
      "--- 5. Splitting Data into Training and Testing Sets ---\n",
      "Data successfully split.\n",
      "Training set size: 83 rows\n",
      "Test set size: 21 rows\n",
      "------------------------------------------------------------\n",
      "\n",
      "--- 6. One-Hot Encoding Categorical Features ---\n",
      "Identified Numeric Features: ['Age', 'Sexual Partners', 'First Sexual Activity Age']\n",
      "Identified Categorical Features: ['HPV Test Result', 'Pap Smear Result', 'Smoking Status', 'STDs History', 'Region', 'Insurance Covered', 'Screening Type Last']\n",
      "\n",
      "Features have been successfully encoded.\n",
      "Shape of processed training features: (83, 27)\n",
      "Shape of processed testing features: (21, 27)\n",
      "------------------------------------------------------------\n",
      "\n",
      "--- 5. Manually Defining Class Weights Based on Clinical Importance ---\n",
      "Class Label Mapping:\n",
      "{'FOR ANNUAL FOLLOW-UP AND PAP SMEAR IN 3 YEARS': np.int64(0), 'FOR BIOPSY AND CYTOLOGY (TAH NOT RECOMMENDED)': np.int64(1), 'FOR COLPOSCOPY, BIOPSY, AND CYTOLOGY': np.int64(2), 'FOR COLPOSCOPY, BIOPSY, AND CYTOLOGY (TAH NOT RECOMMENDED)': np.int64(3), 'FOR COLPOSCOPY, BIOPSY, CYTOLOGY +/- TAH': np.int64(4), 'FOR COLPOSCOPY, CYTOLOGY, THEN LASER THERAPY': np.int64(5), 'FOR HPV VACCINE AND SEXUAL EDUCATION': np.int64(6), 'FOR HPV VACCINE, LIFESTYLE, AND SEXUAL EDUCATION': np.int64(7), 'FOR LASER THERAPY': np.int64(8), 'FOR PAP SMEAR': np.int64(9), 'FOR REPEAT HPV TESTING ANNUALLY AND PAP SMEAR IN 3 YEARS': np.int64(10), 'REPEAT PAP SMEAR IN 3 YEARS': np.int64(11), 'REPEAT PAP SMEAR IN 3 YEARS AND FOR HPV VACCINE': np.int64(12)}\n",
      "\n",
      "Custom Weights Defined:\n",
      "{np.int64(12): 1.0, np.int64(6): 1.2, np.int64(2): 20.0, np.int64(8): 30.0, np.int64(4): 25.0, np.int64(11): 10.0, np.int64(9): 5.0, np.int64(0): 20.0, np.int64(7): 1.5, np.int64(5): 25.0, np.int64(10): 25.0, np.int64(3): 20.0, np.int64(1): 20.0}\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Load Your Data ---\n",
    "# Let's create a sample DataFrame that mimics your situation\n",
    "\n",
    "data = pd.read_excel('data_final.xlsx')\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "\n",
    "# --- 2. DEFINE TARGET and SEPARATE X and y ---\n",
    "target_column = 'Recommended Action_Cleaned'\n",
    "y = df[target_column]\n",
    "X = df.drop(columns=[target_column])\n",
    "\n",
    "\n",
    "# --- 3. PRE-SPLIT STEP: LABEL ENCODE THE TARGET COLUMN ---\n",
    "# This is required so that the 'stratify' parameter can work with numeric labels.\n",
    "print(\"\\n--- 3. Label Encoding Target Column (y) ---\")\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "print(\"Target column converted to numeric labels.\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "\n",
    "# --- 4. PRE-SPLIT STEP: HANDLE SINGLE-INSTANCE CLASSES for STRATIFICATION ---\n",
    "# Stratify needs at least 2 members per class. We duplicate the singletons.\n",
    "print(\"\\n--- 4. Checking for and Fixing Single-Instance Classes ---\")\n",
    "class_counts = pd.Series(y_encoded).value_counts()\n",
    "single_instance_classes = class_counts[class_counts < 2].index\n",
    "\n",
    "X_fixed = X.copy()\n",
    "y_fixed = y_encoded.copy()\n",
    "\n",
    "if len(single_instance_classes) > 0:\n",
    "    print(f\"Found {len(single_instance_classes)} classes with only one sample. Duplicating them...\")\n",
    "    \n",
    "    indices_to_duplicate = pd.Series(y_encoded).isin(single_instance_classes)\n",
    "    \n",
    "    X_to_duplicate = X[indices_to_duplicate]\n",
    "    y_to_duplicate = y_encoded[indices_to_duplicate]\n",
    "    \n",
    "    X_fixed = pd.concat([X, X_to_duplicate], ignore_index=True)\n",
    "    y_fixed = pd.concat([pd.Series(y_encoded), pd.Series(y_to_duplicate)], ignore_index=True).values\n",
    "else:\n",
    "    print(\"No single-instance classes found that would break stratification.\")\n",
    "\n",
    "print(f\"Shape before fix: {X.shape}. Shape after fix: {X_fixed.shape}.\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "    \n",
    "# --- 5. SPLIT THE DATA (CRITICAL LEAKAGE-PREVENTION STEP) ---\n",
    "# We split the 'fixed' data. X_fixed STILL CONTAINS THE TEXT/CATEGORICAL COLUMNS.\n",
    "print(\"\\n--- 5. Splitting Data into Training and Testing Sets ---\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_fixed, y_fixed, \n",
    "    test_size=0.2,       # 20% for testing\n",
    "    random_state=42,     # For reproducibility\n",
    "    stratify=y_fixed     # Ensure class distribution is similar\n",
    ")\n",
    "print(\"Data successfully split.\")\n",
    "print(f\"Training set size: {len(X_train)} rows\")\n",
    "print(f\"Test set size: {len(X_test)} rows\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "\n",
    "# --- 6. ONE-HOT ENCODE THE FEATURE COLUMNS (POST-SPLIT) ---\n",
    "# We learn the encoding schema ONLY from the training data to prevent data leakage.\n",
    "print(\"\\n--- 6. One-Hot Encoding Categorical Features ---\")\n",
    "# Automatically identify which columns are numeric and which are categorical from the training set\n",
    "numeric_features = X_train.select_dtypes(include='number').columns\n",
    "categorical_features = X_train.select_dtypes(include='object').columns\n",
    "\n",
    "print(f\"Identified Numeric Features: {list(numeric_features)}\")\n",
    "print(f\"Identified Categorical Features: {list(categorical_features)}\")\n",
    "\n",
    "# Create the encoder\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "# FIT the encoder ONLY on the TRAINING data's categorical columns\n",
    "encoder.fit(X_train[categorical_features])\n",
    "\n",
    "# TRANSFORM both the training and testing data's categorical columns\n",
    "X_train_encoded = pd.DataFrame(\n",
    "    encoder.transform(X_train[categorical_features]),\n",
    "    columns=encoder.get_feature_names_out(categorical_features),\n",
    "    index=X_train.index\n",
    ")\n",
    "X_test_encoded = pd.DataFrame(\n",
    "    encoder.transform(X_test[categorical_features]),\n",
    "    columns=encoder.get_feature_names_out(categorical_features),\n",
    "    index=X_test.index\n",
    ")\n",
    "\n",
    "# Reset index on all parts to ensure clean concatenation\n",
    "X_train_numeric_reset = X_train[numeric_features].reset_index(drop=True)\n",
    "X_test_numeric_reset = X_test[numeric_features].reset_index(drop=True)\n",
    "X_train_encoded_reset = X_train_encoded.reset_index(drop=True)\n",
    "X_test_encoded_reset = X_test_encoded.reset_index(drop=True)\n",
    "\n",
    "# Combine encoded categorical columns with the original numeric columns\n",
    "X_train_processed = pd.concat([X_train_numeric_reset, X_train_encoded_reset], axis=1)\n",
    "X_test_processed = pd.concat([X_test_numeric_reset, X_test_encoded_reset], axis=1)\n",
    "\n",
    "print(\"\\nFeatures have been successfully encoded.\")\n",
    "print(f\"Shape of processed training features: {X_train_processed.shape}\")\n",
    "print(f\"Shape of processed testing features: {X_test_processed.shape}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "print(\"\\n--- 5. Manually Defining Class Weights Based on Clinical Importance ---\")\n",
    "\n",
    "# First, let's create a mapping from class names to their encoded labels for clarity\n",
    "label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(\"Class Label Mapping:\")\n",
    "print(label_mapping)\n",
    "\n",
    "# ===================================================================================\n",
    "# THIS IS WHERE YOU APPLY YOUR DOMAIN KNOWLEDGE.\n",
    "# You create the dictionary from scratch. Higher weight = higher penalty for getting it wrong.\n",
    "# You MUST provide a weight for every class label present in y_train.\n",
    "# ===================================================================================\n",
    "manual_weights_dict = {\n",
    "    label_mapping['REPEAT PAP SMEAR IN 3 YEARS AND FOR HPV VACCINE']: 1.0, # Majority/common class\n",
    "    label_mapping['FOR HPV VACCINE AND SEXUAL EDUCATION']: 1.2, # Slightly less common\n",
    "    label_mapping['FOR COLPOSCOPY, BIOPSY, AND CYTOLOGY']: 20.0, # IMPORTANT - High penalty\n",
    "    label_mapping['FOR LASER THERAPY']: 30.0, # CRITICALLY IMPORTANT - Very high penalty\n",
    "    label_mapping['FOR COLPOSCOPY, BIOPSY, CYTOLOGY +/- TAH']: 25.0, # IMPORTANT - High penalty\n",
    "    label_mapping[\"REPEAT PAP SMEAR IN 3 YEARS\"]:10.0,\n",
    "    label_mapping[\"FOR PAP SMEAR\"]:5.0,\n",
    "    label_mapping[\"FOR ANNUAL FOLLOW-UP AND PAP SMEAR IN 3 YEARS\"]:20.0,\n",
    "    label_mapping[\"FOR HPV VACCINE, LIFESTYLE, AND SEXUAL EDUCATION\"]:1.5,\n",
    "    label_mapping[\"FOR COLPOSCOPY, CYTOLOGY, THEN LASER THERAPY\"] :25.0,\n",
    "    label_mapping[\"FOR REPEAT HPV TESTING ANNUALLY AND PAP SMEAR IN 3 YEARS\"]:25.0,\n",
    "    label_mapping['FOR COLPOSCOPY, BIOPSY, AND CYTOLOGY (TAH NOT RECOMMENDED)']: 20.0,\n",
    "    label_mapping['FOR BIOPSY AND CYTOLOGY (TAH NOT RECOMMENDED)']: 20.0\n",
    "}\n",
    "\n",
    "print(\"\\nCustom Weights Defined:\")\n",
    "print(manual_weights_dict)\n",
    "print(\"-\" * 60)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDDBz22rCFSX"
   },
   "source": [
    "\n",
    "# STEP 3: Random Forest Classifier\n",
    "## Goal: Understand the features which have more influence on the target column. The columns with the most correlation will then be used to train the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# --- Stage A: Calculate Feature Importance and Select Features (on training data) ---\n",
    "print(\"\\n--- A. Calculating Feature Importance on Training Data ONLY ---\")\n",
    "\n",
    "# We train a preliminary RandomForest model to get feature importances.\n",
    "# It's good practice to use the class weights here too so the importance calculation\n",
    "# is not biased towards features that are only useful for the majority class.\n",
    "feature_selector_model = RandomForestClassifier(\n",
    "    random_state=42,\n",
    "    class_weight=manual_weights_dict\n",
    ")\n",
    "feature_selector_model.fit(X_train_processed, y_train)\n",
    "\n",
    "# Get the importance scores\n",
    "importances = feature_selector_model.feature_importances_\n",
    "feature_names = X_train_processed.columns\n",
    "importance_df = pd.DataFrame({'feature': feature_names, 'importance': importances}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "print(\"Top 8 most important features (learned from training data):\")\n",
    "print(importance_df.head(8))\n",
    "\n",
    "# --- Stage B: Perform the Feature Selection ---\n",
    "print(\"\\n--- B. Selecting Features Based on Importance ---\")\n",
    "\n",
    "# We can use a threshold (e.g., select features with importance > 0.01)\n",
    "# Or we can use a helper like SelectFromModel to automatically select them.\n",
    "# 'threshold=\"median\"' will select all features with importance greater than the median.\n",
    "selector = SelectFromModel(feature_selector_model, threshold='median', prefit=True)\n",
    "\n",
    "# Use the selector to get the final versions of our datasets\n",
    "X_train_final = selector.transform(X_train_processed)\n",
    "X_test_final = selector.transform(X_test_processed) # Apply same transformation to test set\n",
    "\n",
    "print(f\"\\nOriginal number of features: {X_train_processed.shape[1]}\")\n",
    "print(f\"Number of features selected: {X_train_final.shape[1]}\")\n",
    "print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "uC_dGuzYnPax",
    "outputId": "bacf49e2-1b61-416d-9bc6-c1b22e7e921a"
   },
   "outputs": [],
   "source": [
    "# 1\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check class balance for HPV\n",
    "sns.countplot(data=clean_df, x='HPV Test Result')\n",
    "plt.title('HPV Test Result Distribution')\n",
    "plt.show()\n",
    "\n",
    "# Check class balance for Pap Smear\n",
    "sns.countplot(data=clean_df, x='Pap Smear Result')\n",
    "plt.title('Pap Smear Result Distribution')\n",
    "plt.show()\n",
    "\n",
    "# Age distribution\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.histplot(data=clean_df, x='Age', bins=20, kde=True)\n",
    "plt.title('Age Distribution')\n",
    "plt.show()\n",
    "\n",
    "# Correlation matrix for numeric columns\n",
    "numeric_cols = clean_df.select_dtypes(include=['int64', 'float64']).columns\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(clean_df[numeric_cols].corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JiGEIbeAo8gk"
   },
   "source": [
    "In Exploratory Data Analysis (EDA), We focus on key target variables.\n",
    "\n",
    "In cervical cancer prediction, we treat this as a binary classification:\n",
    "\n",
    "Does this patient show signs that are likely to lead to cervical cancer?\n",
    "\n",
    "We use:\n",
    "\n",
    "Recommended Action ‚Üí Could be used as proxy for diagnosis\n",
    "HPV Test Result\n",
    "Pap Smear Result\n",
    "Screening Type Last\n",
    "\n",
    "We‚Äôll use these to understand who‚Äôs at risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 884
    },
    "id": "JA5KE39WlKeh",
    "outputId": "91ed067d-b1a8-4aa4-a643-4625f1be3d71"
   },
   "outputs": [],
   "source": [
    "# 2.Show distributions of key category values defined above\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set visual style\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# HPV Test Result distribution\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(data=clean_df, x='HPV Test Result', palette='Set2')\n",
    "plt.title('Distribution of HPV Test Results')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Pap Smear Result distribution\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(data=clean_df, x='Pap Smear Result', palette='Set3')\n",
    "plt.title('Distribution of Pap Smear Results')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Recommended Action distribution (top 10)\n",
    "plt.figure(figsize=(10,6))\n",
    "top_actions = clean_df['Recommended Action'].value_counts().nlargest(10)\n",
    "sns.barplot(y=top_actions.index, x=top_actions.values, palette='coolwarm')\n",
    "plt.title('Top 10 Recommended Actions')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Recommended Action')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 672
    },
    "id": "mjaeT-M4o50m",
    "outputId": "35bc3a21-4ff1-4f5e-e519-495854655d80"
   },
   "outputs": [],
   "source": [
    "# List of important numerical features\n",
    "num_features = ['Age', 'Sexual Partners', 'First Sexual Activity Age']\n",
    "\n",
    "# Plot histograms\n",
    "clean_df[num_features].hist(bins=20, figsize=(12, 6), color='skyblue')\n",
    "plt.suptitle('Distribution of Key Numeric Features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Heatmap to check which features are correlated with others.\n",
    "\n",
    "# only numerical columns\n",
    "numeric_cols = clean_df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(clean_df[numeric_cols].corr(), annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Between Numerical Features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6SmiHmNpBsXX"
   },
   "source": [
    "# STEP 3: Modeling and Pre-Training Phase\n",
    "\n",
    "##  Goal:\n",
    "Build and evaluate a predictive model using your **cleaned**, **preprocessed** dataset.  \n",
    "This phase helps us learn patterns from the data and **predict High Risk patients** based on clinical features.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary Table of Key Steps\n",
    "\n",
    "| Step                        | What it Means                                                                 | What You Do                                                   |\n",
    "|-----------------------------|-------------------------------------------------------------------------------|---------------------------------------------------------------|\n",
    "| 1. Feature & Target Selection | Choose what we want to predict (target) and the data used to predict it (features). | `X = datav_clean[features]` <br> `y = datav_clean['High Risk']` |\n",
    "| 2. Train-Test Splitting    | Split the dataset into training and test sets for fair model evaluation.    | `train_test_split(X, y, test_size=0.2, random_state=0)`       |\n",
    "| 3. Scaling / Encoding (if needed) | Standardize numeric values to a common scale (important for some models like logistic regression). | `StandardScaler()` or `MinMaxScaler()` if model needs it      |\n",
    "| 4. Model Selection         | Choose a model suitable for classification.                                 | `DecisionTreeClassifier()`, `LogisticRegression()`, etc.      |\n",
    "| 5. Model Training         | Feed the training data into the model so it can learn patterns.            | `model.fit(X_train, y_train)`                                 |\n",
    "| 6. Evaluation              | Check the model‚Äôs accuracy, precision, recall, etc. using test data.        | `confusion_matrix`, `classification_report`, `accuracy_score` |\n",
    "| 7. Interpretation          | Understand feature importance and model behavior.                          | `model.feature_importances_` or tree plots                    |\n",
    "\n",
    "---\n",
    "\n",
    "## Output of This Phase:\n",
    "- A trained and evaluated model that can predict if a patient is **High Risk** for cervical cancer.\n",
    "- Metrics to judge how well the model performs.\n",
    "- A ranked list of which features are most important in making predictions (e.g., age, smoking, screening type).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Clean messy strings (e.g., \" yes \" ‚Üí \"YES\")\n",
    "\n",
    "#Maps them to numbers\n",
    "#Prepares the dataframe to work seamlessly with your existing risk-flagging logic.\n",
    "\n",
    "# Ensure all relevant columns in clean_df are encoded before making a copy\n",
    "clean_df\n",
    "\n",
    "clean_df['Pap Smear Result'] = clean_df['Pap Smear Result'].astype(str).str.upper().str.strip().replace({\n",
    "    'N': 0, 'Y': 1\n",
    "})\n",
    "\n",
    "clean_df['Smoking Status'] = clean_df['Smoking Status'].astype(str).str.upper().str.strip().replace({\n",
    "    'N': 0, 'Y': 1, 'TRUE': 1, 'FALSE': 0\n",
    "})\n",
    "\n",
    "clean_df['STDs History'] = clean_df['STDs History'].astype(str).str.upper().str.strip().replace({\n",
    "    'N': 0, 'Y': 1, 'TRUE': 1, 'FALSE': 0\n",
    "})\n",
    "\n",
    "clean_df['Insurance Covered'] = clean_df['Insurance Covered'].astype(str).str.upper().str.strip().replace({\n",
    "    'N': 0, 'Y': 1\n",
    "})\n",
    "\n",
    "clean_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Because the cervical cancer dataset doesn‚Äôt contain a direct diagnosis column like \"has cancer = yes/no\", \n",
    "#we are creating a new feature called High Risk. \n",
    "# we use real clinical clues (like positive test results or medical recommendations) to determine whether a patient is high risk.\n",
    "# This new High Risk column becomes your true target ‚Äî better than using only HPV Test Result\n",
    "\n",
    "# 1. Make a fresh copy\n",
    "datav = clean_df.copy()\n",
    "\n",
    "# 2. Encode relevant binary columns. 'YES' = 1 (indicating presence)'NO' = 0 (indicating absence)\n",
    "datav['HPV Test Result'] = datav['HPV Test Result'].map({'NEGATIVE': 0, 'POSITIVE': 1})\n",
    "\n",
    "# 3. Handle Screening Type Last ‚Üí create new binary feature: Screening Type Suspicious, first clean this column:\n",
    "# Replace missing values (NaN) with 'UNKNOWN'\n",
    "# Standardize capitalization (so 'hpv', 'HPV ', 'Hpv' all become 'HPV')\n",
    "\n",
    "#Remove leading/trailing spaces\n",
    "datav['Screening Type Last'] = datav['Screening Type Last'].fillna('UNKNOWN').str.upper().str.strip()\n",
    "datav['Screening Type Suspicious'] = datav['Screening Type Last'].apply(\n",
    "    lambda x: 1 if any(word in x for word in ['COLPOSCOPY', 'PAP', 'HPV']) else 0\n",
    ")\n",
    "\n",
    "# 4. Create HIGH RISK target variable ie\n",
    "# We are flagging a patient as high risk if any of these are true:\n",
    "\n",
    "# Their HPV test is positive\n",
    "# Their Pap smear is abnormal\n",
    "# Their last screening type was serious (like HPV or Colposcopy)\n",
    "# Their doctor recommended a follow-up action like biopsy or colposcopy\n",
    "\n",
    "datav['High Risk'] = 0  # default\n",
    "\n",
    "# High risk if HPV positive AND Pap Smear positive\n",
    "datav.loc[(datav['HPV Test Result'] == 1) & (datav['Pap Smear Result'] == 1), 'High Risk'] = 1\n",
    "\n",
    "# OR if Recommended Action includes serious follow-up\n",
    "datav['High Risk'] = datav.apply(\n",
    "    lambda row: 1 if 'BIOPSY' in row['Recommended Action'].upper() or 'COLPOSCOPY' in row['Recommended Action'].upper() else row['High Risk'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# OR if Screening Type is suspicious\n",
    "datav.loc[datav['Screening Type Suspicious'] == 1, 'High Risk'] = 1\n",
    "\n",
    "# ‚úÖ Done\n",
    "print(\"High Risk class distribution:\")\n",
    "print(datav['High Risk'].value_counts())\n",
    "\n",
    "print(datav['Screening Type Suspicious'].value_counts())\n",
    "\n",
    "datav\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding.\n",
    "#Here we encode the Region,screening Type Last to binary. \n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Screening Type Last': ['Pap Smear', 'HPV DNA Test', 'Co-testing', 'Pap Smear'],\n",
    "    'Region': ['Nairobi', 'Kisumu', 'Mombasa', 'Nairobi'],\n",
    "    'Screening Type Last':['PAP SMEAR','HPV DNA'],\n",
    "    'Recommended Action':\n",
    "})\n",
    "\n",
    "# Apply one-hot encoding\n",
    "df_encoded = pd.get_dummies(df, columns=['Screening Type Last', 'Region'])\n",
    "print(df_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop some columns\n",
    "#Region\n",
    "#Reason to drop:\n",
    "#This column is likely categorical geographic data (e.g., \"Central\", \"Nairobi\", \"Unknown\") and:\n",
    "#It doesn‚Äôt directly indicate a person‚Äôs biological or clinical risk\n",
    "#Might introduce location-based bias (e.g., model predicts higher risk just because someone is from a certain place)\n",
    "#Can skew the model especially with small or uneven sample sizes per region\n",
    "\n",
    "#Screening Type Last\n",
    "#Reason to drop:\n",
    "#You already extracted useful info from this column into a binary feature called:Screening Type Suspicious\n",
    "\n",
    "#This feature captures whether the last screening method was highly diagnostic (e.g., HPV test, Pap smear, or Colposcopy). Keeping both would introduce redundancy.\n",
    "#Drop to avoid duplication and multicollinearity\n",
    "\n",
    "#Recommended Action\n",
    "#Reason to drop:\n",
    "#You already used this column to build your target variable High Risk, based on whether the action was ‚Äúbiopsy‚Äù or ‚Äúcolposcopy‚Äù.\n",
    "#Keeping this column in the features would leak information that was already used to define the target ‚Äî this is called data leakage in machine learning.\n",
    "#Drop to prevent data leakage\n",
    "\n",
    "#Insurance Covered\n",
    "#Reason to drop:\n",
    "#While important socially, it:\n",
    "#Doesn‚Äôt represent actual clinical or biological risk\n",
    "#Could lead the model to predict based on financial access rather than medical condition\n",
    "#Introduces ethical concerns (e.g., model assumes uninsured = low risk, which is false)\n",
    "#Drop for ethical, clinical, and fairness reasons\n",
    "\n",
    "# List of columns to drop\n",
    "cols_to_drop = [\n",
    "    'Region',\n",
    "    'Screening Type Last',\n",
    "    'Recommended Action',\n",
    "    'Insurance Covered'\n",
    "]\n",
    "\n",
    "# Drop them from the cleaned dataset\n",
    "datav_clean = datav.drop(columns=cols_to_drop)\n",
    "\n",
    "# Optional: confirm the updated columns\n",
    "print(\"Remaining columns after drop:\")\n",
    "print(datav_clean.columns)\n",
    "datav_clean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6SmiHmNpBsXX"
   },
   "source": [
    "# STEP 4 Modeling Phase-Decision Tree Classifier\n",
    "\n",
    "## Why Decision Tree?\n",
    "We're using a Decision Tree model (CART) to classify patients as **High Risk** or **Not High Risk** based on medical and behavioral features.\n",
    "\n",
    "---\n",
    "\n",
    "## Advantages of Decision Trees\n",
    "- **Low computational cost**: Trees are logarithmic in complexity, making them scalable for large datasets.\n",
    "- **White-box model**: Easy to interpret and visualize. We can trace how decisions are made.\n",
    "- **Minimal data preparation**: No need to normalize, scale, or encode dummy variables for numerical trees.\n",
    "\n",
    "---\n",
    "\n",
    "## Disadvantages of Decision Trees\n",
    "- **Overfitting**: Trees may perfectly fit training data but perform poorly on new data. (We can use pruning or switch to Random Forests.)\n",
    "- **Instability**: Small data changes can lead to completely different trees.\n",
    "- **Class ambiguity**: Trees struggle if many examples have identical features but different labels (noisy/conflicting data).\n",
    "\n",
    "---\n",
    "\n",
    "##  Data Check Before Modeling\n",
    "To verify if identical inputs have different outputs (inconsistent cases), we can run this loop:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w1P4plxo3eJm"
   },
   "outputs": [],
   "source": [
    "# Train & Evaluate a Decision Tree Classifier 1. Splitting the data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define features and target\n",
    "features = [\n",
    "    'Age', \n",
    "    'Sexual Partners', \n",
    "    'First Sexual Activity Age',\n",
    "    'Smoking Status',\n",
    "    'STDs History',\n",
    "    'Screening Type Suspicious'\n",
    "]\n",
    "\n",
    "X = datav_clean[features]\n",
    "y = datav_clean['High Risk']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "97jI8hdKMZqR"
   },
   "outputs": [],
   "source": [
    "#Train, Evaluate, and Interpret a Decision Tree Model\n",
    "# 1. Train the Model\n",
    "#Now that you've split your data into training and testing sets, you're ready to train a DecisionTreeClassifier.\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize the model\n",
    "dtree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train (fit) the model on training data\n",
    "dtree.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mDvoOWXLGgcF"
   },
   "outputs": [],
   "source": [
    "#Make Predictions\n",
    "# Once trained, predict on the test data and evaluate performance.\n",
    "# Predict on the test set\n",
    "y_pred = dtree.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_RHs07-bPYFe"
   },
   "source": [
    "## Model from ScikitLearn\n",
    "\n",
    "\n",
    "*   Uses CART algorithm, meaning that each leaf can only have two children. aka binary trees\n",
    "*   ID3 algorithm could produce nodes with more than 2 children\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s3YhzKY737GH"
   },
   "outputs": [],
   "source": [
    "#Evaluate the Model\n",
    "#We'll use accuracy, confusion matrix, and classification report to assess how well your model performs.\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Accuracy\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\n Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Precision, Recall, F1-score\n",
    "print(\"\\n Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Not High Risk\", \"High Risk\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning (Grid Search)\n",
    "#  Train using GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "# Define model and grid\n",
    "param_grid = {\n",
    "    'max_depth': [4, 5, 6, 7, 8, 9, 10, 11],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=DecisionTreeClassifier(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    scoring=make_scorer(f1_score),\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Extract best model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the Best Model, this is after the grid search and prediction:\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Not High Risk\", \"High Risk\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IUcAIkyBfjlz"
   },
   "outputs": [],
   "source": [
    "# Visualize the Tree \n",
    "# This helps you understand the decision logic your model has learned.\n",
    "\n",
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plot_tree(\n",
    "    best_model,\n",
    "    feature_names=features,\n",
    "    class_names=['Not High Risk', 'High Risk'],\n",
    "    filled=True,\n",
    "    rounded=True\n",
    ")\n",
    "plt.title(\"First Decision Tree\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wnfzkNelQR73",
    "outputId": "048274f5-0594-4116-848b-20e71ce0ca5f"
   },
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "# See which features the tree considered most useful in classification.\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use best_model, not dtree\n",
    "feature_importances = pd.Series(best_model.feature_importances_, index=features)\n",
    "\n",
    "# Sort and plot\n",
    "feature_importances.sort_values(ascending=True).plot(\n",
    "    kind='barh',\n",
    "    title='Feature Importances',\n",
    "    figsize=(8, 5),\n",
    "    color='skyblue'\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Importance Score\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "567VG4dkRCkz"
   },
   "outputs": [],
   "source": [
    "#Pruning (To Prevent Overfitting)\n",
    "#(to do limit tree depth, minimum samples, etc.)\n",
    "\n",
    "# Create a pruned version of the tree\n",
    "dtree_pruned = DecisionTreeClassifier(\n",
    "    max_depth=3,               # limit depth to 3 levels (simpler tree)\n",
    "    min_samples_split=10,      # at least 10 samples to consider a split\n",
    "    random_state=42            # reproducibility\n",
    ")\n",
    "\n",
    "dtree_pruned.fit(X_train, y_train)  # Train on training set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with the pruned tree\n",
    "y_pred_pruned = dtree_pruned.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the pruned model\n",
    "print(\"Pruned Tree Accuracy:\", accuracy_score(y_test, y_pred_pruned))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred_pruned))\n",
    "print(classification_report(y_test, y_pred_pruned))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_RHs07-bPYFe"
   },
   "source": [
    "# Compare: Grid Search Model vs Pruned Tree\n",
    "* Evaluate both models on the same test data\n",
    "* Show accuracy, F1, confusion matrix, and classification report\n",
    "* Output the better final decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "# -------------------------------\n",
    "# Evaluate Best Grid Search Model\n",
    "# -------------------------------\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "print(\"Grid Search Model Evaluation\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_best))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_best))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_best))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_best))\n",
    "\n",
    "\n",
    "# ---------------------\n",
    "# Evaluate Pruned Model\n",
    "# ---------------------\n",
    "y_pred_pruned = dtree_pruned.predict(X_test)\n",
    "\n",
    "print(\"\\n Pruned Model Evaluation\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_pruned))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_pruned))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_pruned))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_pruned))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_RHs07-bPYFe"
   },
   "source": [
    "# Summary of Results\n",
    "\n",
    "| **Metric**           | **Grid Search Model**           | **Pruned Decision Tree**       |\n",
    "|----------------------|----------------------------------|---------------------------------|\n",
    "| **Accuracy**         | 0.95                             |    1.00                         |\n",
    "| **F1 Score**         | 0.9677                           |    1.00                         |\n",
    "| **Confusion Matrix** | 1 FN (missed class 0)            |    Perfect                      |\n",
    "| **Interpretability** | Moderate (depth may vary)        |    Simple (you control depth)   |\n",
    "| **Overfitting Risk** | Medium                           |    High (check generalizability) |\n",
    "\n",
    "---\n",
    "\n",
    "# Interpretation\n",
    "\n",
    "##  Why the Pruned Model is Better (for Now):\n",
    "\n",
    "* **Perfect performance on test set**: 100% accuracy and F1 score ‚Äî no false positives or negatives.\n",
    "* **Simpler model**: Easier to interpret and explain.\n",
    "* **Faster**: Less computational load.\n",
    "\n",
    "---\n",
    "\n",
    "# Disadvantage: Overfitting Risk\n",
    "\n",
    "Even though the pruned tree scores perfectly, keep in mind:\n",
    "\n",
    "* It may be **memorizing the training data**.\n",
    "* With a small test set (only 20 samples), this result may **not generalize** well to unseen patients.\n",
    "\n",
    "---\n",
    "\n",
    "# Final Steps\n",
    "\n",
    "**stick with the pruned tree**, because:\n",
    "\n",
    "* The **dataset is small**.\n",
    "* We need a **quick, interpretable model**.\n",
    "* Need a proof of concept**explain it to doctors or healthcare decision-makers**.\n",
    "\n",
    "---\n",
    "\n",
    "We compared a hyperparameter-tuned Decision Tree via Grid Search with a manually pruned version. Although both performed well, the pruned tree achieved perfect performance on our test set with fewer parameters and more interpretability. Due to our small dataset and the importance of explainability in medical predictions, we select the pruned model as our final classifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QfhcZWLnCoiH"
   },
   "source": [
    "## Final decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the Final Tree-pruned tree\n",
    "# imports are included first\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "#  Visualize the pruned decision tree\n",
    "dot_data = export_graphviz(\n",
    "    dtree_pruned,  # Make sure this is the correct pruned model variable\n",
    "    out_file=None,\n",
    "    feature_names=features,\n",
    "    class_names=[\"Not High Risk\", \"High Risk\"],\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    special_characters=True\n",
    ")\n",
    "\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"final_decision_tree_pruned\", format='png', cleanup=True)\n",
    "graph  # This will display the tree in Jupyter Notebook\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XLUQAuspRCoB"
   },
   "outputs": [],
   "source": [
    "# Save Your Model (Optional for deployment)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(dtree_pruned, 'final_cervical_risk_model.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZLLERVD2iYK"
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "After building, tuning, and evaluating our Decision Tree Classifier, here is the summary of our results:\n",
    "\n",
    "---\n",
    "\n",
    "## Optimal Model Parameters (from Grid Search)\n",
    "- **Criterion**: `entropy`\n",
    "- **Max Depth**: `4`\n",
    "- **Min Samples Leaf**: `2`\n",
    "- **Min Samples Split**: `6`\n",
    "\n",
    "These parameters were found using GridSearchCV and 5-fold cross-validation with F1 score as the evaluation metric.\n",
    "\n",
    "---\n",
    "\n",
    "## Final Model Performance\n",
    "- **Accuracy**: ~96%\n",
    "- **F1 Score**: ~0.97\n",
    "- **Confusion Matrix**: Very few false positives/negatives\n",
    "- **Interpretability**: High, due to controlled depth and pruned tree structure\n",
    "\n",
    "---\n",
    "\n",
    "##  Why This Model Works Well\n",
    "- Balances accuracy and generalizability.\n",
    "- Performs well on both training and test data.\n",
    "- Easy to interpret for healthcare professionals and stakeholders.\n",
    "- Ideal for small to medium medical datasets.\n",
    "\n",
    "---\n",
    "\n",
    "## Final Notes\n",
    "- While performance is excellent on this dataset, further evaluation on **larger or external datasets** is advised before clinical use.\n",
    "- Always ensure models are validated across populations and reviewed with domain experts before deployment.\n",
    "\n",
    "---\n",
    "\n",
    " **Next Steps for more interactive interface:**\n",
    "- Deploy the model for interactive predictions.\n",
    "- Integrate with a simple web app or API.\n",
    "- Explore ensemble methods (Random Forest, XGBoost) for more robustness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "car15kHwLxB9"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
